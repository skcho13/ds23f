[
  {
    "objectID": "contents/vis.html",
    "href": "contents/vis.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Python의 시각화 라이브러리는 다양하게 개발되어지고 있으며, 각기 특성이 달라 하나로만 쓰기 어려운 상황임\nR의 ggplot2라는 매우 강력한 시각화 도구와 비교하면 이에 상응할 만한 Python 시각화 도구는 찾기 어려움\n\n\n\nMatplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017"
  },
  {
    "objectID": "contents/vis.html#대표적-도구들",
    "href": "contents/vis.html#대표적-도구들",
    "title": "Data Visualization",
    "section": "",
    "text": "Matplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017"
  },
  {
    "objectID": "contents/vis.html#the-grammer-of-graphics",
    "href": "contents/vis.html#the-grammer-of-graphics",
    "title": "Data Visualization",
    "section": "The Grammer of Graphics",
    "text": "The Grammer of Graphics\nA coherent system for describing and building graphs\nSource: Fundamentals of Data Visualization by Claus O. Wilke\nAesthetics and types of data\n\n데이터의 값을 특정 aesthetics에 mapping\n\n데이터의 타입은 다음과 같이 나누어짐\n\ncontinuous / discrete\nquatitative / qualitative\ncategorical unordered (nominal) / categorical ordered (ordinal)\n\n성별, 지역 / 등급, 랭킹\nordinal: 등간격을 가정\n\n퀄리티 good, fair, poor는 등간격이라고 봐야하는가?\n랭킹은?\n선호도 1, 2, …, 8; continuous?\n임금 구간?\n\n\n\n데이터 타입에 따라 좀 더 적절한 aesthetic mapping이 있으며,\n같은 정보를 품고 있는 시각화라도 더 적절한 representation이 존재\nBertin’s Semiology of Graphics (1967)\nLevels of organization\n\nSource: Jake VanderPlas’ presentation at PyCon 2018\n\nCase 1\n예를 들어, 다음과 같이 1) 지역별로 2) 날짜에 따른 3) 온도의 변화를 나타낸다면,\n즉, x축의 위치에 날짜 정보를, y축의 위치에 온도 정보를, 색깔에 지역 정보를 할당했음.\n\n한편, 아래는 x축의 위치에 압축된 날짜 정보를, y축의 위치에 지역 정보를, 색깔에 압축된 온도 정보를 할당했음.\n\n\n\nCase 2\n다음은 GDP, mortality, population, region의 네 정보를 다른 방식으로 mapping한 결과임."
  },
  {
    "objectID": "contents/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "href": "contents/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "title": "Data Visualization",
    "section": "탐색적 (Exploratory) vs. 정보전달 (Communicative)",
    "text": "탐색적 (Exploratory) vs. 정보전달 (Communicative)"
  },
  {
    "objectID": "contents/vis.html#interative-plots",
    "href": "contents/vis.html#interative-plots",
    "title": "Data Visualization",
    "section": "Interative Plots",
    "text": "Interative Plots\nAltair\n\n\n\n\n\n\n\nPlotly"
  },
  {
    "objectID": "contents/pandas.html",
    "href": "contents/pandas.html",
    "title": "NumPy and pandas",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.precision = 2\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\nNumpy & pandas\nPython 언어는 수치 계산을 위해 디자인되지 않았기 때문에, 데이터 분석에 대한 효율적이고 빠른 계산이 요구되면서 C/C++이라는 언어로 구현된 NumPy (Numerical Python)가 탄생하였고, Python 생태계 안에 통합되었음. 기본적으로 Python 언어 안에 새로운 언어라고 볼 수 있음. 데이터 사이언스에서의 대부분의 계산은 NumPy의 ndarray (n-dimensioal array)와 수학적 operator들을 통해 계산됨.\n데이터 사이언스가 발전함에 따라 단일한 floating-point number들을 성분으로하는 array들의 계산에서 벗어나 칼럼별로 다른 데이터 타입(string, integer, object..)을 포함하는 tabular형태의 데이터를 효율적으로 처리해야 할 필요성이 나타났고, 이를 다룰 수 있는 새로운 언어를 NumPy 위에 개발한 것이 pandas임. 이는 기본적으로 Wes Mckinney에 의해 독자적으로 개발이 시작되었으며, 디자인적으로 불만족스러운 점이 지적되고는 있으나 데이터 사이언스의 기본적인 언어가 되었음.\nNumPy와 pandas에 대한 자세한 내용은 Python for Data Analysis by Wes MacKinney 참고\n특히, NumPy는 Ch.4 & appendices"
  },
  {
    "objectID": "contents/pandas.html#numpy",
    "href": "contents/pandas.html#numpy",
    "title": "NumPy and pandas",
    "section": "NumPy",
    "text": "NumPy\n\n수학적 symbolic 연산에 대한 구현이라고 볼 수 있으며,\n행렬(matrix) 또는 벡터(vector)를 ndarray (n-dimensional array)이라는 이름으로 구현함.\n\n사실상 정수(int)나 실수(float)의 한가지 타입으로 이루어짐.\n\n고차원의 arrays 가능\n\nSource: Medium.com\n\n\n가령, 다음과 같은 행렬 연산이 있다면,\n\\(\\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\begin{bmatrix}2 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2 \\\\ 4 \\end{bmatrix}\\)\n\n\nA = np.array([[1, 2],\n              [3, 4],\n              [5, 6]]) # 3x2 matrix\nX = np.array([[2],\n              [-1]]) # 2x1 matrix\n\nA @ X  # A * X : matrix multiplication\n\narray([[0],\n       [2],\n       [4]])\n\n\n\nA.dot(X)\n\narray([[0],\n       [2],\n       [4]])\n\n\nVector vs. Matrix\n\nprint(np.array([0, 2, 4])) # 1-dim matrix: vector\nprint(np.array([0, 2, 4]).reshape(3, 1)) # 3x1 matrix\n\n[0 2 4]\n[[0]\n [2]\n [4]]\n\n\n\narr = np.array([0, 2, 4])\narr.reshape(3, -1).T\n\narray([[0, 2, 4]])\n\n\n\nX2 = np.array([2, -1])\nA @ X2  # same as A.dot(X2)\n\narray([0, 2, 4])\n\n\n\nprint(A.shape)\nprint(A.ndim)\nprint(A.dtype)\n\n(3, 2)\n2\nint64\n\n\n\nA + A # element-wise addition\n\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n\n\n\n2 * A - 1 # braodcasting\n\narray([[ 1,  3],\n       [ 5,  7],\n       [ 9, 11]])\n\n\n\nnp.exp(A) # element-wise\n\narray([[  2.72,   7.39],\n       [ 20.09,  54.6 ],\n       [148.41, 403.43]])\n\n\n\nPython vs. NumPy\n\n2**31 + 1\n\n2147483649\n\n\n\na = np.array([2**31-1], dtype='int32')\na + 1\n\narray([-2147483648], dtype=int32)\n\n\n\nSource: Ch.4 in Python for Data Analysis (3e) by Wes McKinney"
  },
  {
    "objectID": "contents/pandas.html#pandas",
    "href": "contents/pandas.html#pandas",
    "title": "NumPy and pandas",
    "section": "pandas",
    "text": "pandas\nSeries & DataFrame\n\nSeries\n1개의 칼럼으로 이루어진 데이터 포멧 - DataFrame의 각 칼럼들을 Series로 이해할 수 있음\n\nSource: Practical Data Science\n\n\nDataFrame\n각 칼럼들이 한 가지 데이터 타입으로 이루어진 tabular형태 (2차원)의 데이터 포맷\n\n각 칼럼은 기본적으로 한 가지 데이터 타입인 것이 이상적이나, 다른 타입이 섞여 있을 수 있음\nNumPy의 2차원 array의 각 칼럼에 labels을 부여한 것으로 볼 수도 있으나, 여러 다른 기능들이 추가됨\nNumPy의 경우 고차원의 array를 다룰 수 있음: ndarray\n\n고차원의 DataFrame과 비슷한 것은 xarray가 존재\n\nLabels와 index를 제외한 데이터 값은 거의 NumPy ndarray로 볼 수 있음\n(pandas.array 존재)\n\n\nSource: Practical Data Science\n\n\nndarray &lt;&gt; DataFrame\n\ndf = pd.DataFrame(A, columns=[\"A1\", \"A2\"])\ndf\n\n   A1  A2\n0   1   2\n1   3   4\n2   5   6\n\n\n\n# 데이터 값들은 NumPy array\ndf.values # 또는 df.to_numpy()\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n\n\nColumns\nSeries로 추출\n\ns = df[\"A1\"] # A1 칼럼 선택\ns\n# DataFrame의 column 이름이 Series의 name으로 전환\n\n0    1\n1    3\n2    5\nName: A1, dtype: int64\n\n\n\ntype(s)\n\npandas.core.series.Series\n\n\n\n\n\n\n\n\nA DataFrame with a single column\n\n\n\n\n\ndf[[\"A1\"]] # double brackets\n\n\n\n\n\n\n\n\n\nIndex objects\n\nframe = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                     index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                     columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\nframe\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\n\n\n\nframe.index\n\nIndex(['Ohio', 'Colorado'], dtype='object', name='state')\n\n\n\nframe.columns # columns도 index object\n\nIndex(['one', 'two', 'three'], dtype='object', name='number')\n\n\n\n\n\n\n\n\nNote\n\n\n\n“number”: columns의 이름 “state”: index의 이름\nframe.columns.name #&gt; ‘number’\nframe.index.name #&gt; ‘state’\n\n\n\nMulti-Index object\nIndex는 여러 levels을 지닐 수 있음\n\nframe.stack() # stack()은 long form으로 변환\n# 2 levels의 index를 가진 Series\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\n# MultiIndex를 직접 구성\npd.DataFrame(np.arange(12).reshape((4, 3)),\n        index=pd.MultiIndex.from_arrays([[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]], names=[\"idx1\", \"idx2\"]),\n        columns=pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"], [\"Green\", \"Red\", \"Green\"]], names=[\"state\", \"color\"]))\n\nstate      Ohio     Colorado\ncolor     Green Red    Green\nidx1 idx2                   \na    1        0   1        2\n     2        3   4        5\nb    1        6   7        8\n     2        9  10       11\n\n\n\n\nTime Series\nIndex는 times series에 특화\n\nfb = pd.read_csv('data/fb_stock_prices_2018.csv', index_col='date', parse_dates=True)\nfb.head()\n\n             open   high    low  close    volume\ndate                                            \n2018-01-02 177.68 181.58 177.55 181.42  18151903\n2018-01-03 181.88 184.78 181.33 184.67  16886563\n2018-01-04 184.90 186.21 184.10 184.33  13880896\n2018-01-05 185.59 186.90 184.93 186.85  13574535\n2018-01-08 187.20 188.90 186.33 188.28  17994726\n\n\n\nfb.plot(kind='line', y=['high', 'low'], figsize=(7, 4), title='Facebook Stock 2018')\nplt.show()\n\n\n\n\nindex없이 분석 가능?\nindex의 활용은 강의 후반부에…\nIndex를 column으로 전환시켜 분석할 수 있음: .reset_index()\n\nfb.reset_index()\n\n          date   open   high    low  close    volume\n0   2018-01-02 177.68 181.58 177.55 181.42  18151903\n1   2018-01-03 181.88 184.78 181.33 184.67  16886563\n2   2018-01-04 184.90 186.21 184.10 184.33  13880896\n..         ...    ...    ...    ...    ...       ...\n248 2018-12-27 132.44 134.99 129.67 134.52  31202509\n249 2018-12-28 135.34 135.92 132.20 133.20  22627569\n250 2018-12-31 134.45 134.64 129.95 131.09  24625308\n\n[251 rows x 6 columns]\n\n\n반대로 column을 index로 전환: .set_index(\"column\")\n\nfb.reset_index().set_index(\"date\")\n\n             open   high    low  close    volume\ndate                                            \n2018-01-02 177.68 181.58 177.55 181.42  18151903\n2018-01-03 181.88 184.78 181.33 184.67  16886563\n2018-01-04 184.90 186.21 184.10 184.33  13880896\n...           ...    ...    ...    ...       ...\n2018-12-27 132.44 134.99 129.67 134.52  31202509\n2018-12-28 135.34 135.92 132.20 133.20  22627569\n2018-12-31 134.45 134.64 129.95 131.09  24625308\n\n[251 rows x 5 columns]\n\n\n\n\n\n\nDataFrame의 연산\nNumPy의 ndarray들이 연산되는 방식과 동일하게 series나 DataFrame들의 연산 가능함\n\ndf + 2 * df\n\n   A1  A2\n0   3   6\n1   9  12\n2  15  18\n\n\n\nnp.log(df)\n\n    A1   A2\n0 0.00 0.69\n1 1.10 1.39\n2 1.61 1.79\n\n\n사실 연산은 index를 align해서 시행됨\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\nnumber  one  two  three\nstate                  \nOhio      0    2      4\nFloria    6    8     10\n\n\n\n\nframe1 + frame2\n\n\n\nnumber    one  two  three\nstate                    \nColorado  NaN  NaN    NaN\nFloria    NaN  NaN    NaN\nOhio     0.00 3.00   6.00\n\n\n\n\n\n(참고) Mixed Data Type\n\ns = pd.Series([1, 2, \"3\"])\n\n\ns.dtype\n\ndtype('O')\n\n\n\ns + s\n\n0     2\n1     4\n2    33\ndtype: object\n\n\n\ns_int = s.astype(\"int\")\ns_int + s_int\n\n0    2\n1    4\n2    6\ndtype: int64\n\n\n\ns2 = pd.Series([1, 2, 3.1])\ns2.dtype\n\ndtype('float64')\n\n\n\ns2.astype(\"int\")\n\n0    1\n1    2\n2    3\ndtype: int64"
  },
  {
    "objectID": "contents/pandas.html#missing",
    "href": "contents/pandas.html#missing",
    "title": "NumPy and pandas",
    "section": "Missing",
    "text": "Missing\nNaN, NA, None\npandas에서는 missing을 명명하는데 R의 컨벤션을 따라 NA (not available)라 부름.\n대부분의 경우에서 NumPy object NaN(np.nan)을 NA을 나타내는데 사용됨.\nnp.nan은 실제로 floating-point의 특정 값으로 float64 데이터 타입임. Integer 또는 string type에서 약간 이상하게 작동될 수 있음.\nPython object인 None은 pandas에서 NA로 인식함.\n현재 NA라는 새로운 pandas object 실험중임\nNA의 handling에 대해서는 교재 참고\n.dropna(), .fillna(), .isna(), .notna()\n\nMckinney’s: 7.1 Handling Missing Data,\n\nMollin’s: 3.5 Handling duplicate, missing, or invalid data\n\nWorking with missing data\n\n\ns = pd.Series([1, 2, np.nan])\ns\n\n0   1.00\n1   2.00\n2    NaN\ndtype: float64\n\n\n\ns.astype(\"Int64\") # &lt;NA&gt;\n\n0       1\n1       2\n2    &lt;NA&gt;\ndtype: Int64\n\n\n\ns = pd.Series([\"a\", \"b\", np.nan])\ns\n\n0      a\n1      b\n2    NaN\ndtype: object\n\n\n\ns.astype(\"string\") # &lt;NA&gt;\n\n0       a\n1       b\n2    &lt;NA&gt;\ndtype: string\n\n\n\ns = pd.Series([1, 2, np.nan, None])\ns\n\n0   1.00\n1   2.00\n2    NaN\n3    NaN\ndtype: float64\n\n\n\ns.isna() # or s.isnull()\n\n0    False\n1    False\n2     True\n3     True\ndtype: bool\n\n\n\ns.notna() # or s.notnull()\n\n0     True\n1     True\n2    False\n3    False\ndtype: bool\n\n\n\n\n\n\n\n\nNote\n\n\n\nPython object인 None의 경우\nNone == None\n#&gt; True\nNumPy object인 np.nan의 경우\nnp.nan == np.nan\n#&gt; False"
  },
  {
    "objectID": "contents/pandas.html#attributes",
    "href": "contents/pandas.html#attributes",
    "title": "NumPy and pandas",
    "section": "Attributes",
    "text": "Attributes\n자주 사용되는 attributes;\nSeries objects: name, dtype, shape, index, values\nIndex objects: name, dtype, shape, values, is_unique\nDataFrame objects: dtype, shape, index, columns, values"
  },
  {
    "objectID": "contents/pandas.html#creating-dataframes",
    "href": "contents/pandas.html#creating-dataframes",
    "title": "NumPy and pandas",
    "section": "Creating DataFrames",
    "text": "Creating DataFrames\nDataFrame을 만드는 방식에 대해서는\nMckinney’s: 5.1 Introduction to pandas Data Structures"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균 / sk.cho@snu.ac.kr\n면담 시간: 수업 후\n수업시간: 월, 수 3:00 ~ 4:50PM\nWebsite: dgdavs.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "index.html#강의-정보",
    "href": "index.html#강의-정보",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균 / sk.cho@snu.ac.kr\n면담 시간: 수업 후\n수업시간: 월, 수 3:00 ~ 4:50PM\nWebsite: dgdavs.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n본 강의에서는 인터넷과 기술의 발전으로 풍부한 데이터들이 양산됨에 따라 그 안에 숨겨진 패턴을 찾고 분석하여 실증적 사실과 원리를 파악하는데 요구되는 기술들을 계발하는데 도움을 주고자 합니다. 이를 위해서는 1) 데이터 분석 툴을 자유자재로 다룰 수 있는 기술, 2) 주어진 데이터에 적절한 툴을 선택할 수 있는 판단력, 3) 파악한 패턴으로부터 현상의 본질을 추론할 수 있는 인과관계 추론의 원리들이 함께 필요합니다.\n수업은 크게 4부분으로 나뉨\n\n데이터 시각화와 탐색적 분석 (exploratory data analysis)\n모델링 (modelling)\n통계 (statistics)\n기술적 분석 (descriptive analysis)\n\n\n교재\n\n번역서: Pandas를 이용한 데이터 분석 실습 2/e\nHands-On Data Analysis with Pandas (2e) by Stefanie Molin: code in GitHub\nPython for Data Analysis (3e) by Wes McKinney: code in GitHub\n2판 번역서: 파이썬 라이브러리를 활용한 데이터 분석\nR for Data Science by Wickham & Grolemund; 2nd edition"
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (5%), 일반과제 (25%), 중간고사 (25%), 기말고사 (25%), 개별 프로젝트 (20%)"
  },
  {
    "objectID": "contents/intro.html",
    "href": "contents/intro.html",
    "title": "데이터 분석 및 시각화",
    "section": "",
    "text": "다양한 소스들로부터 데이터 생성: 전지구적 개인과 환경에 대한 상세한 정보 발생\n인터넷 & 통신 (SNS, 사진, 위치, 장소, 유동인구, 상품거래)\n사물인터넷 (IoT), CCTV\n스마트 팩토리, 파밍\n게놈프로젝트, 생체정보: 인류, 실시간\n의료서비스, 보건\n자율주행차량: 내부, 외부\n금융정보 및 흐름\n사회 지표, 설문 조사: 고용, 물류, 직업, 연봉, 만족도 조사, 우울\n\n\n\n\n\n\n\n\n\n초연결성, 투명성\n완전한 감시와 통제\n\n\n\n\n\n\n\n\n정보의 주권, 매매, 웹3(Web3)"
  },
  {
    "objectID": "contents/intro.html#미래-데이터의-중요성",
    "href": "contents/intro.html#미래-데이터의-중요성",
    "title": "데이터 분석 및 시각화",
    "section": "",
    "text": "다양한 소스들로부터 데이터 생성: 전지구적 개인과 환경에 대한 상세한 정보 발생\n인터넷 & 통신 (SNS, 사진, 위치, 장소, 유동인구, 상품거래)\n사물인터넷 (IoT), CCTV\n스마트 팩토리, 파밍\n게놈프로젝트, 생체정보: 인류, 실시간\n의료서비스, 보건\n자율주행차량: 내부, 외부\n금융정보 및 흐름\n사회 지표, 설문 조사: 고용, 물류, 직업, 연봉, 만족도 조사, 우울\n\n\n\n\n\n\n\n\n\n초연결성, 투명성\n완전한 감시와 통제\n\n\n\n\n\n\n\n\n정보의 주권, 매매, 웹3(Web3)"
  },
  {
    "objectID": "contents/intro.html#data-science",
    "href": "contents/intro.html#data-science",
    "title": "데이터 분석 및 시각화",
    "section": "Data Science",
    "text": "Data Science\n\n\n\n\n소프트웨어 개발\n. . .\n데이터에 기반한 분석 위해 작동하도록 프로그래밍을 하여 운영되도록 하는 일\n주로 전통적인 컴퓨터 사이언스의 커리큘럼에 의해 트레이닝\n\n유튜브의 영상 추천\n페이스북의 친구 매칭\n스팸메일 필터링\n자율주행\n\n\n\n\n\n\n데이터 분석\n. . .\n하나의 구체적인 질문에 답하고자 함\n다양한 소스의 정제되는 않은 데이터를 통합하거나 가공하는 기술이 요구\n\nDNA의 분석을 통해 특정 질병의 발병 인자를 탐색\n유동인구와 매출을 분석해 상권을 분석\n어떤 정책의 유효성을 분석에 정책결정에 공헌\n교통 흐름의 지연이 어떻게 발생하는지를 분석, 해결책 제시\n\n\n\n\n\n대부분의 경우 양쪽 모두에 걸쳐있음."
  },
  {
    "objectID": "contents/intro.html#data-analysis",
    "href": "contents/intro.html#data-analysis",
    "title": "데이터 분석 및 시각화",
    "section": "Data Analysis",
    "text": "Data Analysis\n\n\n\n오랜동안 여러 분야에서 각자의 방식을 개발\nComputer Science\nStatistics\nBiostatistics\nEconomics\nEpidemiology\nPolitical Science\nEngineering\n\n\n\n서로 다른 용어를 쓰기도 하며, 그 분야에서 필요로하는 방식에 초점을 맞춤.\n\n서로 의사소통이 거의 없었음.\n\nData Science라는 이름하에 통합되어가는 과정 중\n\n\n\n\n\n컴퓨터 사이언스의 경우, 주로 분류나 예측을 위한 이론과 툴들이 개발되는 반면,\n\n사회과학자들은 예측에는 관심이 없으며, 변수들 간의 진정한 관계 혹은 인과관계를 탐구\n현재 이 둘은 소위 cross-fertilization을 지향하며 같이 발전, 통합되어가고 있음.\n\n\n  Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\n\n\n본 강의에서는 분석의 기초를 적절한 밸런스를 갖춰 제시한 R for Data Science by Wickham & Grolemund의 전개 방식을 따르고자 함."
  },
  {
    "objectID": "contents/intro.html#데이터를-분석한다는-것은",
    "href": "contents/intro.html#데이터를-분석한다는-것은",
    "title": "데이터 분석 및 시각화",
    "section": "데이터를 분석한다는 것은?",
    "text": "데이터를 분석한다는 것은?\n\n예측 모델 vs. 관계/원인 분석\n\n\n\n\n\n예측 모델\n예측의 신속성과 정확성\nMachine Learning 강점\nAlgorithmic\n\n고양이인가 아닌가? 예측의 정확성\n개인화된 추천 목록: 유튜브, 넷플릭스\n시리의 답변\n비즈니스 분석\n\n\n\n\n\n\n관계/원인 분석\n현상 본질과 매커니즘 파악\nStatistical Models 강점 Parametric\n\nQ: 닭의 울음이 태양을 솟게 하는가?\n돈과 행복: 패턴 vs. 예외\n\n\n\n\n\n가난, 인종, 범죄\n임금 차별\n\n\n\n\n\n출산율의 감소\n\n\n\n\n\n\n\n\n\n. . .\n\n\n\n심리적 관성/편견 주의\n분석가의 책임의식\n두 가지는 서로 상보 관계!"
  },
  {
    "objectID": "contents/intro.html#데이터를-분석한다는-것은-1",
    "href": "contents/intro.html#데이터를-분석한다는-것은-1",
    "title": "데이터 분석 및 시각화",
    "section": "데이터를 분석한다는 것은?",
    "text": "데이터를 분석한다는 것은?\n전통적인 분류\n\n\n\n\n탐색적 분석 vs. 가설 검증\nexploratory vs. confirmatory\n\n탐색적 분석\n\n통찰 혹은 가설의 기초 제공\n끼워 맞추기? 오류에 빠지기 쉬움\n\n가설 검증\n\n진위의 확률을 높임\n탐색적 분석으로부터 온 가설은 재테스트\n\n\n\n\n\n관찰 vs. 실험 데이터\nobservational vs. experimental\n\n당근과 시력?\n커피의 효과?\n남녀의 임금 차별?\n\n\n  \n\n기술적 vs. 추론적 분석\ndescriptive vs. inferential\n\n연봉과 삶의 만족도와 관계\n두통약의 효능"
  },
  {
    "objectID": "contents/intro.html#통계적-사고-i",
    "href": "contents/intro.html#통계적-사고-i",
    "title": "데이터 분석 및 시각화",
    "section": "통계적 사고 I",
    "text": "통계적 사고 I\n\n\n\n\n남녀 임금의 차이\n\n\n\n\n\n\n\nConfounding\n\n\n\n머리가 길면 우울증도 높다?\n초등생이 발이 크면 독해력도 높다?\n\n\n\n\n\n\n\n\n\nSimpson’s paradox\n\n\n\n\nSource: The book of why by Judea Pearl"
  },
  {
    "objectID": "contents/intro.html#통계적-사고-ii",
    "href": "contents/intro.html#통계적-사고-ii",
    "title": "데이터 분석 및 시각화",
    "section": "통계적 사고 II",
    "text": "통계적 사고 II\n\n\n\n\n레몬과 괴혈병\n\n남녀 연봉 차이의 원인?\n\n직업 특성, 부서, 직급, 연령, 출산, 출세욕\n\n\n\n\n\n\n\n\n수집된 데이터의 성격\nSelection Bias\n\n\n\n노인에 관한 데이터: 누가 사망했는가?\n설문 데이터: 누가 참여했는가?\n회사 내에서의 만족도 조사: 샘플 속성의 변화\n코호트/특정세대의 특성: 그들의 특성인가?"
  },
  {
    "objectID": "contents/intro.html#데이터-시각화",
    "href": "contents/intro.html#데이터-시각화",
    "title": "데이터 분석 및 시각화",
    "section": "데이터 시각화",
    "text": "데이터 시각화\nData Visualization \n\n\n\n분석도구: 현미경, 연장도구\n강점이자 약점\n\n\n\n\n\n\n\n\n효과적/미적인 정보 전달 수단\n효과적이고 임팩트있도록 infographics \n\n\n\nInteractive\n\n\n\n\n\n\n\n\n  \n\n끝\nBack Home"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contents/notice.html#중간고사",
    "href": "contents/notice.html#중간고사",
    "title": "Notice",
    "section": "중간고사",
    "text": "중간고사"
  },
  {
    "objectID": "contents/notice.html#기말고사",
    "href": "contents/notice.html#기말고사",
    "title": "Notice",
    "section": "기말고사",
    "text": "기말고사"
  },
  {
    "objectID": "contents/notice.html#개별-프로젝트",
    "href": "contents/notice.html#개별-프로젝트",
    "title": "Notice",
    "section": "개별 프로젝트",
    "text": "개별 프로젝트"
  },
  {
    "objectID": "contents/inspection.html",
    "href": "contents/inspection.html",
    "title": "Inspecting data",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nimport plotly.express as px\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.precision = 2\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 8\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)"
  },
  {
    "objectID": "contents/inspection.html#useful-method",
    "href": "contents/inspection.html#useful-method",
    "title": "Inspecting data",
    "section": "Useful method",
    "text": "Useful method\n.head(), .tail(), .sample()\n.info(), .describe(),\n.value_counts(),\n.sort_values(), .nlargest(), .nsmallest()\nData: Tips\n일정기간 한 웨이터가 얻은 팁에 대한 데이터\n\n# load a dataset\ntips = sns.load_dataset(\"tips\")\ntips\n\n     total_bill  tip     sex smoker   day    time  size\n0         16.99 1.01  Female     No   Sun  Dinner     2\n1         10.34 1.66    Male     No   Sun  Dinner     3\n2         21.01 3.50    Male     No   Sun  Dinner     3\n3         23.68 3.31    Male     No   Sun  Dinner     2\n..          ...  ...     ...    ...   ...     ...   ...\n240       27.18 2.00  Female    Yes   Sat  Dinner     2\n241       22.67 2.00    Male    Yes   Sat  Dinner     2\n242       17.82 1.75    Male     No   Sat  Dinner     2\n243       18.78 3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]\n\n\n\n# DataFrame의 값들: ndarray\ntips.values # or tips.to_numpy()\n\narray([[16.99, 1.01, 'Female', ..., 'Sun', 'Dinner', 2],\n       [10.34, 1.66, 'Male', ..., 'Sun', 'Dinner', 3],\n       [21.01, 3.5, 'Male', ..., 'Sun', 'Dinner', 3],\n       ...,\n       [22.67, 2.0, 'Male', ..., 'Sat', 'Dinner', 2],\n       [17.82, 1.75, 'Male', ..., 'Sat', 'Dinner', 2],\n       [18.78, 3.0, 'Female', ..., 'Thur', 'Dinner', 2]], dtype=object)\n\n\n\ntips.head() # 처음 N개 나열\n\n   total_bill  tip     sex smoker  day    time  size\n0       16.99 1.01  Female     No  Sun  Dinner     2\n1       10.34 1.66    Male     No  Sun  Dinner     3\n2       21.01 3.50    Male     No  Sun  Dinner     3\n3       23.68 3.31    Male     No  Sun  Dinner     2\n4       24.59 3.61  Female     No  Sun  Dinner     4\n\n\n\ntips.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\ntips.describe() # numerical type만 나열\n\n\n\n       total_bill    tip   size\ncount      244.00 244.00 244.00\nmean        19.79   3.00   2.57\nstd          8.90   1.38   0.95\nmin          3.07   1.00   1.00\n25%         13.35   2.00   2.00\n50%         17.80   2.90   2.00\n75%         24.13   3.56   3.00\nmax         50.81  10.00   6.00\n\n\n\n\n\ntips.describe(include=\"all\") # all types 나열\n\n        total_bill    tip   sex smoker  day    time   size\ncount       244.00 244.00   244    244  244     244 244.00\nunique         NaN    NaN     2      2    4       2    NaN\ntop            NaN    NaN  Male     No  Sat  Dinner    NaN\nfreq           NaN    NaN   157    151   87     176    NaN\n...            ...    ...   ...    ...  ...     ...    ...\n25%          13.35   2.00   NaN    NaN  NaN     NaN   2.00\n50%          17.80   2.90   NaN    NaN  NaN     NaN   2.00\n75%          24.13   3.56   NaN    NaN  NaN     NaN   3.00\nmax          50.81  10.00   NaN    NaN  NaN     NaN   6.00\n\n[11 rows x 7 columns]\n\n\n\ntips.describe(include=\"category\")\n\n\n\n         sex smoker  day    time\ncount    244    244  244     244\nunique     2      2    4       2\ntop     Male     No  Sat  Dinner\nfreq     157    151   87     176\n\n\n\n\n\ns1 = tips[\"day\"].value_counts() # \"day\" 칼럼을 선택 후 각 카테고리별 counts\ns2 = tips[\"day\"].value_counts(sort=False) # default: sort is true\ns3 = tips[\"day\"].value_counts(normalize=True) # 카테고리별 비율\ns4 = tips[[\"sex\", \"smoker\"]].value_counts() # \"sex\", \"smoker\" 칼럼을 선택 후 유니크한 카테고리별 counts\n\n\n\n\n\n\nSat     87\nSun     76\nThur    62\nFri     19\nName: day, dtype: int64\n(a) s1\n\n\n\n\nThur    62\nFri     19\nSat     87\nSun     76\nName: day, dtype: int64\n(b) s2\n\n\n\n\n\n\nSat    0.36\nSun    0.31\nThur   0.25\nFri    0.08\nName: day, dtype: float64\n(c) s3\n\n\n\n\nsex     smoker\nMale    No        97\n        Yes       60\nFemale  No        54\n        Yes       33\ndtype: int64\n(d) s4\n\n\n\nFigure 1: value_count()의 arguments\n\n\n\n\n\n\n\n\nTip\n\n\n\n다음 두 가지 형태도 가능하며, 차이에 유의\ntips[[\"day\"]].value_counts()  # double bracket\ntips.value_counts(\"day\")  # argument\ntips.value_counts([\"day\", \"time\"])\n\n\n\nData: palmerpenguins\n\n# load a dataset\npenguins = sns.load_dataset(\"penguins\")\npenguins\n\n    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n0    Adelie  Torgersen           39.10          18.70             181.00   \n1    Adelie  Torgersen           39.50          17.40             186.00   \n2    Adelie  Torgersen           40.30          18.00             195.00   \n3    Adelie  Torgersen             NaN            NaN                NaN   \n..      ...        ...             ...            ...                ...   \n340  Gentoo     Biscoe           46.80          14.30             215.00   \n341  Gentoo     Biscoe           50.40          15.70             222.00   \n342  Gentoo     Biscoe           45.20          14.80             212.00   \n343  Gentoo     Biscoe           49.90          16.10             213.00   \n\n     body_mass_g     sex  \n0        3750.00    Male  \n1        3800.00  Female  \n2        3250.00  Female  \n3            NaN     NaN  \n..           ...     ...  \n340      4850.00  Female  \n341      5750.00    Male  \n342      5200.00  Female  \n343      5400.00    Male  \n\n[344 rows x 7 columns]\n\n\n\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 18.9+ KB\n\n\n\npenguins.describe(include=\"object\")\n\n\n\n       species  island   sex\ncount      344     344   333\nunique       3       3     2\ntop     Adelie  Biscoe  Male\nfreq       152     168   168\n\n\n\n\n\npenguins[[\"island\", \"species\"]].value_counts()\n\nisland     species  \nBiscoe     Gentoo       124\nDream      Chinstrap     68\n           Adelie        56\nTorgersen  Adelie        52\nBiscoe     Adelie        44\ndtype: int64\n\n\n\npenguins[[\"sex\", \"species\"]].value_counts(dropna=False) # NA은 기본적으로 생략\n\nsex     species  \nFemale  Adelie       73\nMale    Adelie       73\n        Gentoo       61\nFemale  Gentoo       58\n        Chinstrap    34\nMale    Chinstrap    34\nNaN     Adelie        6\n        Gentoo        5\ndtype: int64\n\n\n\npenguins.isna().sum() # NA의 개수\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\ndtype: int64\n\n\n\ntips.sort_values(\"tip\", ascending=False)\n\n     total_bill   tip     sex smoker  day    time  size\n170       50.81 10.00    Male    Yes  Sat  Dinner     3\n212       48.33  9.00    Male     No  Sat  Dinner     4\n23        39.42  7.58    Male     No  Sat  Dinner     4\n59        48.27  6.73    Male     No  Sat  Dinner     4\n..          ...   ...     ...    ...  ...     ...   ...\n236       12.60  1.00    Male    Yes  Sat  Dinner     2\n111        7.25  1.00  Female     No  Sat  Dinner     1\n67         3.07  1.00  Female    Yes  Sat  Dinner     1\n92         5.75  1.00  Female    Yes  Fri  Dinner     2\n\n[244 rows x 7 columns]\n\n\n\ntips.sort_values([\"size\", \"tip\"], ascending=[False, True])\n\n     total_bill  tip     sex smoker   day    time  size\n125       29.80 4.20  Female     No  Thur   Lunch     6\n143       27.05 5.00  Female     No  Thur   Lunch     6\n156       48.17 5.00    Male     No   Sun  Dinner     6\n141       34.30 6.70    Male     No  Thur   Lunch     6\n..          ...  ...     ...    ...   ...     ...   ...\n67         3.07 1.00  Female    Yes   Sat  Dinner     1\n111        7.25 1.00  Female     No   Sat  Dinner     1\n82        10.07 1.83  Female     No  Thur   Lunch     1\n222        8.58 1.92    Male    Yes   Fri   Lunch     1\n\n[244 rows x 7 columns]\n\n\n\ntips.nlargest(3, \"tip\")  # keep=\"first\", \"last\", \"all\"\n\n     total_bill   tip   sex smoker  day    time  size\n170       50.81 10.00  Male    Yes  Sat  Dinner     3\n212       48.33  9.00  Male     No  Sat  Dinner     4\n23        39.42  7.58  Male     No  Sat  Dinner     4"
  },
  {
    "objectID": "contents/setup.html",
    "href": "contents/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "Conda Cheatsheet: 기본적인 conda 명령어 요약\n\n\nAnaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 3. Command Line Tool 참고\n\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n#&gt; conda info # 콘다 정보 \n#&gt; conda update conda # 콘다 업데이트\n\n\n\n\nconda/managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n\n#&gt; conda config --add channels conda-forge\n#&gt; conda config --set channel_priority strict  # 채널 순으로 검색, 버전 순이 아니고\n\n\n# 개별적으로 채널을 선택해서 install하려면\n#&gt; conda install scipy --channel conda-forge\n\n# pakcage가 있는 채널들\n#&gt; conda search scipy\n\nconda base에 있는 Python을 update하려면, 가령 3.10으로 업데이트하려면\n\n#&gt; conda install python=3.10  # python update\n\n\n\n\nconda/user guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 수업에서는 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\n\n#$ conda create --name myenv\n\n# 특정 버전의 파이썬 설치시\n#&gt; conda create --name myenv python=3.9\n\n환경 확인\n\n#$ conda env list\n\n#&gt; conda environments:\n#&gt;  base         */.../miniconda3\n#&gt;                /.../miniconda3/envs/myenv\n\n환경 제거\n\n#&gt; conda env remove --name myenv\n\n환경 activate/deactivate\n\n#&gt; conda activate myenv\n#&gt; conda deactivate  # activated 환경 내에서\n\n특정 환경 안의 파이썬 버전 확인\n\n#(myenv) python --version\n\n\n\n\n\n\n\nJupyter notebook을 쓰는 경우\n\n\n\n새로 만든 가상환경을 등록해줘야 함.\n#&gt; ipython kernel install --user --name=myenv\n가상환경을 삭제해도 등록시킨 kernel 이름은 삭제되지 않으니 직접 삭제.\n등록된 커널 리스트를 확인\n#&gt; jupyter kernelspec list\n커널 삭제\n#&gt; jupyter kernelspec remove myenv\n\n\n\n\n\n\n# 특정 환경을 activate한 후\n#&gt; conda install &lt;package name1&gt; &lt;package name2&gt; ...\n#&gt; conda install --channel conda-forge &lt;package name&gt; # 특정 conda-forge 채널을 통한 설치\n\n# 제거\n#&gt; conda remove &lt;package name1&gt; &lt;package name2&gt; ...\n\n# update\n#&gt; conda update &lt;package name1&gt; &lt;package name2&gt; ...\n#&gt; conda update --all # all packages\n\n# 패키지 리스트\n#&gt; conda list\n\n\n# 환경 밖에서 특정 환경 안에 설치하려면 환경이름 추가\n#&gt; conda install --name myenv &lt;package name1&gt;\n\n\n# pip을  이용한  패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n#&gt; pip install &lt;package name1&gt; &lt;package name2&gt; ...\n\n\n# 환경 안에 다른 버전의 Python 설치하려면, 가령 python 3.9라면\n#&gt; conda install python=3.9\n\n\n# 수업에 필요한 기본 패키지 설치\n#&gt; conda install jupyter numpy pandas matplotlib seaborn\n#&gt; conda install -c plotly plotly=5.13.0"
  },
  {
    "objectID": "contents/setup.html#miniconda-설치",
    "href": "contents/setup.html#miniconda-설치",
    "title": "환경설정",
    "section": "",
    "text": "Anaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 3. Command Line Tool 참고\n\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n#&gt; conda info # 콘다 정보 \n#&gt; conda update conda # 콘다 업데이트"
  },
  {
    "objectID": "contents/setup.html#패키지-repositorychannel-선택",
    "href": "contents/setup.html#패키지-repositorychannel-선택",
    "title": "환경설정",
    "section": "",
    "text": "conda/managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n\n#&gt; conda config --add channels conda-forge\n#&gt; conda config --set channel_priority strict  # 채널 순으로 검색, 버전 순이 아니고\n\n\n# 개별적으로 채널을 선택해서 install하려면\n#&gt; conda install scipy --channel conda-forge\n\n# pakcage가 있는 채널들\n#&gt; conda search scipy\n\nconda base에 있는 Python을 update하려면, 가령 3.10으로 업데이트하려면\n\n#&gt; conda install python=3.10  # python update"
  },
  {
    "objectID": "contents/setup.html#conda-environment",
    "href": "contents/setup.html#conda-environment",
    "title": "환경설정",
    "section": "",
    "text": "conda/user guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 수업에서는 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\n\n#$ conda create --name myenv\n\n# 특정 버전의 파이썬 설치시\n#&gt; conda create --name myenv python=3.9\n\n환경 확인\n\n#$ conda env list\n\n#&gt; conda environments:\n#&gt;  base         */.../miniconda3\n#&gt;                /.../miniconda3/envs/myenv\n\n환경 제거\n\n#&gt; conda env remove --name myenv\n\n환경 activate/deactivate\n\n#&gt; conda activate myenv\n#&gt; conda deactivate  # activated 환경 내에서\n\n특정 환경 안의 파이썬 버전 확인\n\n#(myenv) python --version\n\n\n\n\n\n\n\nJupyter notebook을 쓰는 경우\n\n\n\n새로 만든 가상환경을 등록해줘야 함.\n#&gt; ipython kernel install --user --name=myenv\n가상환경을 삭제해도 등록시킨 kernel 이름은 삭제되지 않으니 직접 삭제.\n등록된 커널 리스트를 확인\n#&gt; jupyter kernelspec list\n커널 삭제\n#&gt; jupyter kernelspec remove myenv"
  },
  {
    "objectID": "contents/setup.html#activated-환경-내에서-패키지-설치-및-제거",
    "href": "contents/setup.html#activated-환경-내에서-패키지-설치-및-제거",
    "title": "환경설정",
    "section": "",
    "text": "# 특정 환경을 activate한 후\n#&gt; conda install &lt;package name1&gt; &lt;package name2&gt; ...\n#&gt; conda install --channel conda-forge &lt;package name&gt; # 특정 conda-forge 채널을 통한 설치\n\n# 제거\n#&gt; conda remove &lt;package name1&gt; &lt;package name2&gt; ...\n\n# update\n#&gt; conda update &lt;package name1&gt; &lt;package name2&gt; ...\n#&gt; conda update --all # all packages\n\n# 패키지 리스트\n#&gt; conda list\n\n\n# 환경 밖에서 특정 환경 안에 설치하려면 환경이름 추가\n#&gt; conda install --name myenv &lt;package name1&gt;\n\n\n# pip을  이용한  패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n#&gt; pip install &lt;package name1&gt; &lt;package name2&gt; ...\n\n\n# 환경 안에 다른 버전의 Python 설치하려면, 가령 python 3.9라면\n#&gt; conda install python=3.9\n\n\n# 수업에 필요한 기본 패키지 설치\n#&gt; conda install jupyter numpy pandas matplotlib seaborn\n#&gt; conda install -c plotly plotly=5.13.0"
  },
  {
    "objectID": "contents/setup.html#vs-code-설치",
    "href": "contents/setup.html#vs-code-설치",
    "title": "환경설정",
    "section": "VS Code 설치",
    "text": "VS Code 설치\n개인마다 선호하는 text editor가 있으나 본 수업에서는 VS Code로 진행: download and install here"
  },
  {
    "objectID": "contents/setup.html#mac의-경우-기본-bash-shell인-terminal-대신-다음-zsh을-추천",
    "href": "contents/setup.html#mac의-경우-기본-bash-shell인-terminal-대신-다음-zsh을-추천",
    "title": "환경설정",
    "section": "Mac의 경우: 기본 bash shell인 terminal 대신 다음 zsh을 추천",
    "text": "Mac의 경우: 기본 bash shell인 terminal 대신 다음 zsh을 추천\nOh-My-Zsh!: 링크\n\n이 경우 miniconda 설치시 bash의 추가된 conda setup을 zsh로 가져와야 함: minconda를 zsh 설치 후에 설치하는 경우는 miniconda가 추가시키니 신경쓸 필요 없음\n\nhome directory에 있는 .bash_profile 을 열면 # &gt;&gt;&gt; conda initialize &gt;&gt;&gt; 로 시작해서 # &lt;&lt;&lt; conda initialize &lt;&lt;&lt; 부분까지를 복사한 후 .zshrc 파일을 열어 맨 뒤에 붙여넣음\n위 파일을 VS Code에서 쉽게 열어보려면 아래 그림처럼 VS Code에서 Sehll Command: Install 'Code' command in PATH 실행하고 나면\nshell 환경에서 code .zshrc를 실행하면 VS Code에서 편집할 수 있음"
  },
  {
    "objectID": "contents/setup.html#windows의-경우-windows-terminal-추천",
    "href": "contents/setup.html#windows의-경우-windows-terminal-추천",
    "title": "환경설정",
    "section": "Windows의 경우: Windows Terminal 추천",
    "text": "Windows의 경우: Windows Terminal 추천\n\n설치 링크는 구글링…\n명령프롬프트(CMD) vs. Powershell\nPowershell에서 conda를 사용하기 위해서는 몇 가지 설정 필요: 블로그 링크"
  },
  {
    "objectID": "contents/setup.html#extensions",
    "href": "contents/setup.html#extensions",
    "title": "환경설정",
    "section": "Extensions",
    "text": "Extensions\n\nPython\nPython Extension Pack 중\n\nIntelliCode\nPython Environment Manager\n\nDocs View"
  },
  {
    "objectID": "contents/setup.html#preferences",
    "href": "contents/setup.html#preferences",
    "title": "환경설정",
    "section": "Preferences",
    "text": "Preferences\n\nThemes\nFont, font size (notebook, results)"
  },
  {
    "objectID": "contents/setup.html#shortcuts",
    "href": "contents/setup.html#shortcuts",
    "title": "환경설정",
    "section": "Shortcuts",
    "text": "Shortcuts\nShow Command Palette: ctrl(cmd) + shift + p, 또는 F1\nCell 안과 밖\n\nundo/redo : ctrl(cmd) + z / ctrl(cmd) + shift + z\nalt(option) + arrow up/down : move\nalt(option) + shift + arrow up/down : copy\n\n실행: ctrl/shift/alt(option) + enter\nBasic editing 참고"
  },
  {
    "objectID": "contents/setup.html#그-외",
    "href": "contents/setup.html#그-외",
    "title": "환경설정",
    "section": "그 외",
    "text": "그 외\n\ninteractive mode\nexport\ndocs view\nvariables viewer, data viewer\nformatter\nsnippets"
  }
]