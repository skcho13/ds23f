[
  {
    "objectID": "contents/Introduction/vis.html",
    "href": "contents/Introduction/vis.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Python의 시각화 라이브러리는 다양하게 개발되어지고 있으며, 각기 특성이 달라 하나로만 쓰기 어려운 상황임\nR의 ggplot2라는 매우 강력한 시각화 도구와 비교하면 이에 상응할 만한 Python 시각화 도구는 찾기 어려움\n\n\n\nMatplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017",
    "crumbs": [
      "Introduction",
      "Data visualization"
    ]
  },
  {
    "objectID": "contents/Introduction/vis.html#대표적-도구들",
    "href": "contents/Introduction/vis.html#대표적-도구들",
    "title": "Data Visualization",
    "section": "",
    "text": "Matplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017",
    "crumbs": [
      "Introduction",
      "Data visualization"
    ]
  },
  {
    "objectID": "contents/Introduction/vis.html#the-grammer-of-graphics",
    "href": "contents/Introduction/vis.html#the-grammer-of-graphics",
    "title": "Data Visualization",
    "section": "The Grammer of Graphics",
    "text": "The Grammer of Graphics\nA coherent system for describing and building graphs\nSource: Fundamentals of Data Visualization by Claus O. Wilke\nAesthetics and types of data\n\n데이터의 값을 특정 aesthetics에 mapping\n\n데이터의 타입은 다음과 같이 나누어짐\n\ncontinuous / discrete\nquatitative / qualitative\ncategorical unordered (nominal) / categorical ordered (ordinal)\n\n성별, 지역 / 등급, 랭킹\nordinal: 등간격을 가정\n\n퀄리티 good, fair, poor는 등간격이라고 봐야하는가?\n랭킹은?\n선호도 1, 2, …, 8; continuous?\n임금 구간?\n\n\n\n데이터 타입에 따라 좀 더 적절한 aesthetic mapping이 있으며,\n같은 정보를 품고 있는 시각화라도 더 적절한 representation이 존재\nBertin’s Semiology of Graphics (1967)\nLevels of organization\n\nSource: Jake VanderPlas’ presentation at PyCon 2018\n\nCase 1\n예를 들어, 다음과 같이 1) 지역별로 2) 날짜에 따른 3) 온도의 변화를 나타낸다면,\n즉, x축의 위치에 날짜 정보를, y축의 위치에 온도 정보를, 색깔에 지역 정보를 할당했음.\n\n한편, 아래는 x축의 위치에 압축된 날짜 정보를, y축의 위치에 지역 정보를, 색깔에 압축된 온도 정보를 할당했음.\n\n\n\nCase 2\n다음은 GDP, mortality, population, region의 네 정보를 다른 방식으로 mapping한 결과임.",
    "crumbs": [
      "Introduction",
      "Data visualization"
    ]
  },
  {
    "objectID": "contents/Introduction/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "href": "contents/Introduction/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "title": "Data Visualization",
    "section": "탐색적 (Exploratory) vs. 정보전달 (Communicative)",
    "text": "탐색적 (Exploratory) vs. 정보전달 (Communicative)\n\n분석도구: 현미경, 연장도구\n강점이자 약점",
    "crumbs": [
      "Introduction",
      "Data visualization"
    ]
  },
  {
    "objectID": "contents/Introduction/vis.html#interative-plots",
    "href": "contents/Introduction/vis.html#interative-plots",
    "title": "Data Visualization",
    "section": "Interative Plots",
    "text": "Interative Plots\nAltair\n\n\n\n\n\n\n\nPlotly",
    "crumbs": [
      "Introduction",
      "Data visualization"
    ]
  },
  {
    "objectID": "contents/Introduction/inspection.html",
    "href": "contents/Introduction/inspection.html",
    "title": "Inspecting data",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 8\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)",
    "crumbs": [
      "Introduction",
      "NumPy and pandas",
      "Inspecting data"
    ]
  },
  {
    "objectID": "contents/Introduction/inspection.html#useful-method",
    "href": "contents/Introduction/inspection.html#useful-method",
    "title": "Inspecting data",
    "section": "Useful method",
    "text": "Useful method\n.head(), .tail(), .sample()\n.info(), .describe(),\n.value_counts(),\n.sort_values(), .nlargest(), .nsmallest()\nData: Tips\n일정기간 한 웨이터가 얻은 팁에 대한 데이터\n\n# load a dataset\ntips = sns.load_dataset(\"tips\")\ntips\n\n     total_bill  tip     sex smoker   day    time  size\n0         16.99 1.01  Female     No   Sun  Dinner     2\n1         10.34 1.66    Male     No   Sun  Dinner     3\n2         21.01 3.50    Male     No   Sun  Dinner     3\n3         23.68 3.31    Male     No   Sun  Dinner     2\n..          ...  ...     ...    ...   ...     ...   ...\n240       27.18 2.00  Female    Yes   Sat  Dinner     2\n241       22.67 2.00    Male    Yes   Sat  Dinner     2\n242       17.82 1.75    Male     No   Sat  Dinner     2\n243       18.78 3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]\n\n\n\n# DataFrame의 값들: ndarray\ntips.values # or tips.to_numpy()\n\narray([[16.99, 1.01, 'Female', ..., 'Sun', 'Dinner', 2],\n       [10.34, 1.66, 'Male', ..., 'Sun', 'Dinner', 3],\n       [21.01, 3.5, 'Male', ..., 'Sun', 'Dinner', 3],\n       ...,\n       [22.67, 2.0, 'Male', ..., 'Sat', 'Dinner', 2],\n       [17.82, 1.75, 'Male', ..., 'Sat', 'Dinner', 2],\n       [18.78, 3.0, 'Female', ..., 'Thur', 'Dinner', 2]], dtype=object)\n\n\n\ntips.head() # 처음 N개 나열\n\n   total_bill  tip     sex smoker  day    time  size\n0       16.99 1.01  Female     No  Sun  Dinner     2\n1       10.34 1.66    Male     No  Sun  Dinner     3\n2       21.01 3.50    Male     No  Sun  Dinner     3\n3       23.68 3.31    Male     No  Sun  Dinner     2\n4       24.59 3.61  Female     No  Sun  Dinner     4\n\n\n\ntips.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\ntips.describe() # numerical type만 나열\n\n\n\n       total_bill    tip   size\ncount      244.00 244.00 244.00\nmean        19.79   3.00   2.57\nstd          8.90   1.38   0.95\nmin          3.07   1.00   1.00\n25%         13.35   2.00   2.00\n50%         17.80   2.90   2.00\n75%         24.13   3.56   3.00\nmax         50.81  10.00   6.00\n\n\n\n\ntips.describe(include=\"all\") # all types 나열\n\n        total_bill    tip   sex smoker  day    time   size\ncount       244.00 244.00   244    244  244     244 244.00\nunique         NaN    NaN     2      2    4       2    NaN\ntop            NaN    NaN  Male     No  Sat  Dinner    NaN\nfreq           NaN    NaN   157    151   87     176    NaN\n...            ...    ...   ...    ...  ...     ...    ...\n25%          13.35   2.00   NaN    NaN  NaN     NaN   2.00\n50%          17.80   2.90   NaN    NaN  NaN     NaN   2.00\n75%          24.13   3.56   NaN    NaN  NaN     NaN   3.00\nmax          50.81  10.00   NaN    NaN  NaN     NaN   6.00\n\n[11 rows x 7 columns]\n\n\ntips.describe(include=\"category\")\n\n\n\n         sex smoker  day    time\ncount    244    244  244     244\nunique     2      2    4       2\ntop     Male     No  Sat  Dinner\nfreq     157    151   87     176\n\n\n\n\ns1 = tips.value_counts(\"day\") # \"day\" 칼럼에 대한 각 카테고리별 counts\ns2 = tips.value_counts(\"day\", sort=False) # default: sort is true\ns3 = tips.value_counts(\"day\", ascending=True) # default: ascending is False\ns4 = tips.value_counts(\"day\", normalize=True) # 카테고리별 비율\ns5 = tips.value_counts([\"sex\", \"smoker\"]) # \"sex\", \"smoker\" 칼럼에 대한 유니크한 카테고리별 counts\n\n\n\n\n\n\n\n\n\nday\nSat     87\nSun     76\nThur    62\nFri     19\nName: count, dtype: int64\n\n\n(a) s1\n\n\n\n\n\n\n\n\nday\nThur    62\nFri     19\nSat     87\nSun     76\nName: count, dtype: int64\n\n\n(b) s2\n\n\n\n\n\n\n\n\n\n\nday\nFri     19\nThur    62\nSun     76\nSat     87\nName: count, dtype: int64\n\n\n(c) s3\n\n\n\n\n\n\n\n\nday\nSat    0.36\nSun    0.31\nThur   0.25\nFri    0.08\nName: proportion, dtype: float64\n\n\n(d) s4\n\n\n\n\n\n\n\n\n\n\nsex     smoker\nMale    No        97\n        Yes       60\nFemale  No        54\n        Yes       33\nName: count, dtype: int64\n\n\n(e) s5\n\n\n\n\n\n\n\nFigure 1: value_count()의 arguments\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n.value_count()의 결과는 Series이며 그 이름은 ‘count’ 또는 ’proportion’임 (pandas 2.0)\nMissing(NA)을 count하지 않으나 dropna=False을 이용해 나타낼 수 있음\ntips.value_counts(\"day\", dropna=False)\nSeries에 대해서도 적용되며, DataFrame을 먼저 선택해 적용할 수 있음\ntips[\"day\"].value_counts()  # tips[\"day\"]: Series object\ntips[[\"sex\", \"smoker\"]].value_counts()\n\n\n\nData: palmerpenguins\n\n# load a dataset\npenguins = sns.load_dataset(\"penguins\")\npenguins\n\n    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n0    Adelie  Torgersen            39.1           18.7              181.0   \n1    Adelie  Torgersen            39.5           17.4              186.0   \n2    Adelie  Torgersen            40.3           18.0              195.0   \n3    Adelie  Torgersen             NaN            NaN                NaN   \n4    Adelie  Torgersen            36.7           19.3              193.0   \n..      ...        ...             ...            ...                ...   \n339  Gentoo     Biscoe             NaN            NaN                NaN   \n340  Gentoo     Biscoe            46.8           14.3              215.0   \n341  Gentoo     Biscoe            50.4           15.7              222.0   \n342  Gentoo     Biscoe            45.2           14.8              212.0   \n343  Gentoo     Biscoe            49.9           16.1              213.0   \n\n     body_mass_g     sex  \n0         3750.0    Male  \n1         3800.0  Female  \n2         3250.0  Female  \n3            NaN     NaN  \n4         3450.0  Female  \n..           ...     ...  \n339          NaN     NaN  \n340       4850.0  Female  \n341       5750.0    Male  \n342       5200.0  Female  \n343       5400.0    Male  \n\n[344 rows x 7 columns]\n\n\n\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 18.9+ KB\n\n\npenguins.describe(include=\"object\")\n\n\n\n       species  island   sex\ncount      344     344   333\nunique       3       3     2\ntop     Adelie  Biscoe  Male\nfreq       152     168   168\n\n\n\n\npenguins.value_counts([\"island\", \"species\"])\n\nisland     species  \nBiscoe     Gentoo       124\nDream      Chinstrap     68\n           Adelie        56\nTorgersen  Adelie        52\nBiscoe     Adelie        44\nName: count, dtype: int64\n\n\n\npenguins.value_counts([\"sex\", \"species\"], dropna=False) # NA은 기본적으로 생략\n\nsex     species  \nFemale  Adelie       73\nMale    Adelie       73\n        Gentoo       61\nFemale  Gentoo       58\n        Chinstrap    34\nMale    Chinstrap    34\nNaN     Adelie        6\n        Gentoo        5\nName: count, dtype: int64\n\n\n\n# NA의 개수\npenguins.isna().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\ndtype: int64\n\n\n\n# NA의 비율\npenguins.isna().mean()\n\nspecies              0.000000\nisland               0.000000\nbill_length_mm       0.005814\nbill_depth_mm        0.005814\nflipper_length_mm    0.005814\nbody_mass_g          0.005814\nsex                  0.031977\ndtype: float64\n\n\n\ntips.sort_values(\"tip\", ascending=False)\n\n     total_bill   tip     sex smoker  day    time  size\n170       50.81 10.00    Male    Yes  Sat  Dinner     3\n212       48.33  9.00    Male     No  Sat  Dinner     4\n23        39.42  7.58    Male     No  Sat  Dinner     4\n59        48.27  6.73    Male     No  Sat  Dinner     4\n..          ...   ...     ...    ...  ...     ...   ...\n236       12.60  1.00    Male    Yes  Sat  Dinner     2\n111        7.25  1.00  Female     No  Sat  Dinner     1\n67         3.07  1.00  Female    Yes  Sat  Dinner     1\n92         5.75  1.00  Female    Yes  Fri  Dinner     2\n\n[244 rows x 7 columns]\n\n\n\ntips.sort_values([\"size\", \"tip\"], ascending=[False, True])\n\n     total_bill  tip     sex smoker   day    time  size\n125       29.80 4.20  Female     No  Thur   Lunch     6\n143       27.05 5.00  Female     No  Thur   Lunch     6\n156       48.17 5.00    Male     No   Sun  Dinner     6\n141       34.30 6.70    Male     No  Thur   Lunch     6\n..          ...  ...     ...    ...   ...     ...   ...\n67         3.07 1.00  Female    Yes   Sat  Dinner     1\n111        7.25 1.00  Female     No   Sat  Dinner     1\n82        10.07 1.83  Female     No  Thur   Lunch     1\n222        8.58 1.92    Male    Yes   Fri   Lunch     1\n\n[244 rows x 7 columns]\n\n\n\ntips.nlargest(3, \"tip\")  # 다수의 동등 순위가 있을 때 처리: keep=\"first\", \"last\", \"all\"\n\n     total_bill   tip   sex smoker  day    time  size\n170       50.81 10.00  Male    Yes  Sat  Dinner     3\n212       48.33  9.00  Male     No  Sat  Dinner     4\n23        39.42  7.58  Male     No  Sat  Dinner     4",
    "crumbs": [
      "Introduction",
      "NumPy and pandas",
      "Inspecting data"
    ]
  },
  {
    "objectID": "contents/shortcuts.html",
    "href": "contents/shortcuts.html",
    "title": "오늘의 숏컷",
    "section": "",
    "text": "move : alt(option) + arrow up/down\ncopy : alt(option) + shift + arrow up/down\nctrl(cmd) + /\n셀 밖에서 a / b (esc, enter)\n셀 밖에서 c / x / v\ncmd + enter, cmd+ shift + enter (Mac)\nctrl + shift + -\nctrl(cmd) + d\nctrl(cmd) + [, ]\n\n\nctrl -\npandas=2.1.3, seaborn=0.13 update!"
  },
  {
    "objectID": "contents/Introduction/setup.html",
    "href": "contents/Introduction/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "Conda Cheatsheet: 기본적인 conda 명령어 요약\n\n\nAnaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 2. Command Line Tool 참고\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n(base)&gt; conda info # 콘다 정보 \n(base)&gt; conda update conda # 콘다 업데이트\n\n\n\nconda/managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n(base)&gt; conda config --add channels conda-forge\n(base)&gt; conda config --set channel_priority strict  # 채널 순으로 검색, 버전 순이 아니고\n# 개별적으로 채널을 선택해서 install하려면 (특정 환경에 설치하려면 아래 conda environment 참조)\n(base)&gt; conda install scipy --channel conda-forge\n\n# pakcage가 있는 채널들\n(base)&gt; conda search scipy\nconda base에 있는 Python을 update하려면, 가령 3.12으로 업데이트하려면\n(base)&gt; conda install python=3.12  # python update\n\n\n\nconda/user guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 수업에서는 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\nconda create --name myenv\n\n# 특정 버전의 파이썬과 함께 설치시\nconda create --name myenv python=3.12\n환경 확인\nconda env list\n\nconda environments:\n# base         */.../miniconda3\n#               /.../miniconda3/envs/myenv\n환경 제거\nconda env remove --name myenv\n환경 activate/deactivate\nconda activate myenv\n(myenv)&gt; conda deactivate\n특정 환경 안의 파이썬 버전 확인\n(myenv)&gt; python --version\n\n\n\n\n\n\nJupyter notebook을 쓰는 경우\n\n\n\n\n\n새로 만든 환경을 등록해줘야 함. 환경을 activate한 상태에서\n(myenv)&gt; ipython kernel install --user --name=myenv\n환경을 삭제해도 등록시킨 kernel 이름은 삭제되지 않으니 직접 삭제.\n등록된 커널 리스트를 확인\n(myenv)&gt; jupyter kernelspec list\n커널 삭제\n(myenv)&gt; jupyter kernelspec remove myenv\n\n\n\n\n\n\n# 특정 환경을 activate한 후\n(myenv)&gt; conda install &lt;package name1&gt; &lt;package name2&gt; ...\n(myenv)&gt; conda install --channel conda-forge &lt;package name&gt;  # 특정 conda-forge 채널을 통한 설치\n\n# 다른 버전의 Python 설치하려면, 가령 python 3.9라면\n(myenv)&gt; conda install python=3.9\n\n# 제거\n(myenv)&gt; conda remove &lt;package name1&gt; &lt;package name2&gt; ...\n\n# 업데이트\n(myenv)&gt; conda update &lt;package name1&gt; &lt;package name2&gt; ...\n(myenv)&gt; conda update --all  # all packages\n\n# 패키지 리스트\n(myenv)&gt; conda list\n환경 밖에서 특정 환경 안에 설치하려면 환경 이름 추가\n(base)&gt; conda install --name myenv &lt;package name1&gt;\npip을 이용한 패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n(myenv)&gt; pip install &lt;package name1&gt; &lt;package name2&gt; ...\n수업에 필요한 기본 패키지 설치\n# 수업에 필요한 기본 패키지 설치\n(myenv)&gt; conda install jupyter numpy pandas matplotlib seaborn",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#miniconda-설치",
    "href": "contents/Introduction/setup.html#miniconda-설치",
    "title": "환경설정",
    "section": "",
    "text": "Anaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 2. Command Line Tool 참고\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n(base)&gt; conda info # 콘다 정보 \n(base)&gt; conda update conda # 콘다 업데이트",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#패키지-repositorychannel-선택",
    "href": "contents/Introduction/setup.html#패키지-repositorychannel-선택",
    "title": "환경설정",
    "section": "",
    "text": "conda/managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n(base)&gt; conda config --add channels conda-forge\n(base)&gt; conda config --set channel_priority strict  # 채널 순으로 검색, 버전 순이 아니고\n# 개별적으로 채널을 선택해서 install하려면 (특정 환경에 설치하려면 아래 conda environment 참조)\n(base)&gt; conda install scipy --channel conda-forge\n\n# pakcage가 있는 채널들\n(base)&gt; conda search scipy\nconda base에 있는 Python을 update하려면, 가령 3.12으로 업데이트하려면\n(base)&gt; conda install python=3.12  # python update",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#conda-environment",
    "href": "contents/Introduction/setup.html#conda-environment",
    "title": "환경설정",
    "section": "",
    "text": "conda/user guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 수업에서는 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\nconda create --name myenv\n\n# 특정 버전의 파이썬과 함께 설치시\nconda create --name myenv python=3.12\n환경 확인\nconda env list\n\nconda environments:\n# base         */.../miniconda3\n#               /.../miniconda3/envs/myenv\n환경 제거\nconda env remove --name myenv\n환경 activate/deactivate\nconda activate myenv\n(myenv)&gt; conda deactivate\n특정 환경 안의 파이썬 버전 확인\n(myenv)&gt; python --version\n\n\n\n\n\n\nJupyter notebook을 쓰는 경우\n\n\n\n\n\n새로 만든 환경을 등록해줘야 함. 환경을 activate한 상태에서\n(myenv)&gt; ipython kernel install --user --name=myenv\n환경을 삭제해도 등록시킨 kernel 이름은 삭제되지 않으니 직접 삭제.\n등록된 커널 리스트를 확인\n(myenv)&gt; jupyter kernelspec list\n커널 삭제\n(myenv)&gt; jupyter kernelspec remove myenv",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#환경activated-내에서-패키지-설치-및-제거",
    "href": "contents/Introduction/setup.html#환경activated-내에서-패키지-설치-및-제거",
    "title": "환경설정",
    "section": "",
    "text": "# 특정 환경을 activate한 후\n(myenv)&gt; conda install &lt;package name1&gt; &lt;package name2&gt; ...\n(myenv)&gt; conda install --channel conda-forge &lt;package name&gt;  # 특정 conda-forge 채널을 통한 설치\n\n# 다른 버전의 Python 설치하려면, 가령 python 3.9라면\n(myenv)&gt; conda install python=3.9\n\n# 제거\n(myenv)&gt; conda remove &lt;package name1&gt; &lt;package name2&gt; ...\n\n# 업데이트\n(myenv)&gt; conda update &lt;package name1&gt; &lt;package name2&gt; ...\n(myenv)&gt; conda update --all  # all packages\n\n# 패키지 리스트\n(myenv)&gt; conda list\n환경 밖에서 특정 환경 안에 설치하려면 환경 이름 추가\n(base)&gt; conda install --name myenv &lt;package name1&gt;\npip을 이용한 패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n(myenv)&gt; pip install &lt;package name1&gt; &lt;package name2&gt; ...\n수업에 필요한 기본 패키지 설치\n# 수업에 필요한 기본 패키지 설치\n(myenv)&gt; conda install jupyter numpy pandas matplotlib seaborn",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#vs-code-설치",
    "href": "contents/Introduction/setup.html#vs-code-설치",
    "title": "환경설정",
    "section": "VS Code 설치",
    "text": "VS Code 설치\n개인마다 선호하는 text editor가 있으나 본 수업에서는 VS Code로 진행: download and install here",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#extensions",
    "href": "contents/Introduction/setup.html#extensions",
    "title": "환경설정",
    "section": "Extensions",
    "text": "Extensions\n\nPython\nPython Extension Pack 중\n\nIntelliCode\nPython Environment Manager\n\nPylance: 문법 체크, 자동완성, …\nDocs View\n\n안 보일시, 설정에서 language server를 default(Pylance)에서 Jedi로 바꾸면 해결\n\nCopilot…",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#preferences",
    "href": "contents/Introduction/setup.html#preferences",
    "title": "환경설정",
    "section": "Preferences",
    "text": "Preferences\n\nThemes\nFont, font size (notebook, markup, output)",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#shortcuts",
    "href": "contents/Introduction/setup.html#shortcuts",
    "title": "환경설정",
    "section": "Shortcuts",
    "text": "Shortcuts\nShow Command Palette: ctrl(cmd) + shift + p, 또는 F1\nCell 안과 밖에서 다르게 작동\n\nundo / redo : ctrl(cmd) + z / ctrl(cmd) + shift + z\nmove: alt(option) + arrow up/down\ncopy : alt(option) + shift + arrow up/down\n\n코드 실행 방식 3가지: ctrl/shift/alt(option) + enter\nHelp: Keyboard shortcuts reference의 Basic editing 참고",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#그-외",
    "href": "contents/Introduction/setup.html#그-외",
    "title": "환경설정",
    "section": "그 외",
    "text": "그 외\n\ninteractive mode\nexport\ndocs view: sticky mode\nvariables viewer, data viewer\nformatter: “Black formatter”\nsnippets: 구글링…",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/setup.html#vs-code내에서-terminal-사용",
    "href": "contents/Introduction/setup.html#vs-code내에서-terminal-사용",
    "title": "환경설정",
    "section": "VS Code내에서 terminal 사용",
    "text": "VS Code내에서 terminal 사용\nTerminal: Select Default Profile에서 선택\n\nMac: zsh\nWindows: powershell",
    "crumbs": [
      "Introduction",
      "Setup"
    ]
  },
  {
    "objectID": "contents/Introduction/intro2.html",
    "href": "contents/Introduction/intro2.html",
    "title": "개관",
    "section": "",
    "text": "다양한 소스들로부터 데이터 생성: 전지구적 개인과 환경에 대한 상세한 정보 발생\n인터넷 & 통신 (SNS, 사진, 위치, 장소, 유동인구, 상품거래, 물류)\n사물인터넷 (IoT), CCTV\n스마트 팩토리, 파밍\n게놈프로젝트, 생체정보, 의료/보건: 인류, 실시간\n\n23andMe, Theranos\n\n과학적 발견: 물리법칙의 발견, 약물의 합성, 생체 내 상호작용의 메커니즘 규명\n자율주행차량: 내부, 외부\n금융정보 및 흐름\n사회 지표 활용: 고용, 직업, 연봉, 만족도 조사, 취약 계층, 우울\n생성형 인공지능: 기계의 정보 생산\nAI companion: 개인 내면에 대한 정보\n\n영화 Her (2013), Sony’s robotics dog ‘Aibo’",
    "crumbs": [
      "Introduction",
      "Data Analysis Intro"
    ]
  },
  {
    "objectID": "contents/Introduction/intro2.html#미래-데이터의-중요성",
    "href": "contents/Introduction/intro2.html#미래-데이터의-중요성",
    "title": "개관",
    "section": "",
    "text": "다양한 소스들로부터 데이터 생성: 전지구적 개인과 환경에 대한 상세한 정보 발생\n인터넷 & 통신 (SNS, 사진, 위치, 장소, 유동인구, 상품거래, 물류)\n사물인터넷 (IoT), CCTV\n스마트 팩토리, 파밍\n게놈프로젝트, 생체정보, 의료/보건: 인류, 실시간\n\n23andMe, Theranos\n\n과학적 발견: 물리법칙의 발견, 약물의 합성, 생체 내 상호작용의 메커니즘 규명\n자율주행차량: 내부, 외부\n금융정보 및 흐름\n사회 지표 활용: 고용, 직업, 연봉, 만족도 조사, 취약 계층, 우울\n생성형 인공지능: 기계의 정보 생산\nAI companion: 개인 내면에 대한 정보\n\n영화 Her (2013), Sony’s robotics dog ‘Aibo’",
    "crumbs": [
      "Introduction",
      "Data Analysis Intro"
    ]
  },
  {
    "objectID": "contents/Introduction/intro2.html#데이터-사이언스의-응용-사례",
    "href": "contents/Introduction/intro2.html#데이터-사이언스의-응용-사례",
    "title": "개관",
    "section": "데이터 사이언스의 응용 사례",
    "text": "데이터 사이언스의 응용 사례\n\n영업 및 마케팅\n\n웹사이트에서 고객의 구매 행동, 소셜 미디어의 댓글을 추적 고객의 선호도를 파악\n월마트의 경우,\n\n수 십년 넘게 매장의 재고 수준을 최적화했고, 2004년, 몇 주 전에 발생한 허리케인의 판매 데이터를 분석하여 “딸기 팝타트”를 재입고\n소셜 미디어 트렌드 및 신용카드 활동을 분석하여 신제품 출시 및 고객 경험 개인화/최적화\n\n추천 시스템을 통해 사용자 취향에 맞는 제품을 추천하여 틈새 상품의 판매도 촉진\n\n\n\n공공기관\n\n미국의 경우, 정부 주도의 데이터 과학 이니셔티브 발족; 특히, 보건 분야에 큰 투자\n\nPrecision Medicine Initiative (2015)\n\n인간 게놈 시퀀싱과 데이터 과학을 결합하여 개별 환자를 위한 약물을 설계\n백만 명 이상의 자원봉사자로부터 환경, 라이프스타일, 생물학적 데이터를 수집하여 정밀 의학을 위한 세계 최대의 데이터를 구축\n\n\n\n도시 운영 및 설계\n\n스마트 시티: 환경, 에너지, 교통 흐름을 추적, 분석, 제어\n장기적 도시 계획 수립에 정보를 축적\n\n치안 및 범죄 예측\n\nPolice Data Initiative\n\n범죄 다발 지역과 재범률을 예측\n시민 단체들의 비판도 존재\n\n시카고 경찰; 1주일 이내의 범죄 예측\n비판: Event-level prediction of urban crime reveals a signature of enforcement bias in US cities. Nature human behaviour\n\n각종 보험료 산정\n\n과거의 데이터를 분석하여, 보험금을 지급할 확률을 계산하고 보험료를 산정\n\n\n\n\n스포츠\n\nMoneyball: The Art of Winning an Unfair Game\n\n야구에서 전통적으로 강조되던 도루, 타점, 타율의 통계보다 출루율과 장타율이 더 나은 척도였음\n“저평가된” 선수, 승리에 기여하는 능력에 비해 낮은 급여를 받는 선수를 찾아 영입\n\nSabermetrics: sciecne of baseball\n데이터 분석을 통해 시장에서 어떤 조직이 우위를 점할 수 있는 방법을 제시\n적절한 속성을 찾는 것의 중요성",
    "crumbs": [
      "Introduction",
      "Data Analysis Intro"
    ]
  },
  {
    "objectID": "contents/Introduction/intro2.html#사회적-파장",
    "href": "contents/Introduction/intro2.html#사회적-파장",
    "title": "개관",
    "section": "사회적 파장",
    "text": "사회적 파장\n\n유토피아 vs. 디스토피아\n\n초연결성, 투명성 vs. 완전한 감시와 통제\n개인화된 서비스 vs. 설득/유혹/조작\n개별성/자율성 vs. 피동적/비주체적\n기계/디지털과의 교감 vs. 인간관계의 소외, 현실과의 단절\n정보와 인간에 대한 신뢰 vs. 사회적 연대, 문명 붕괴\n자연과의 조화 vs. 생태계의 파괴\n\n\n\n\n\n\n\n\n\n\n\nBrave New World, 1932\n\n\n\n\n\n\n\nThe Technological Society, 1954\n\n\n\n\n\n\n\nSapiens, Homo Deus, 21 Lessons for the 21st Century by Yuval Noah Harari\n\n\n\n\n\nYuval Noah Harari: An Urgent Warning They Hope You Ignore.\n\nThe Social Dilemma (2020)",
    "crumbs": [
      "Introduction",
      "Data Analysis Intro"
    ]
  },
  {
    "objectID": "contents/Introduction/intro2.html#data-science",
    "href": "contents/Introduction/intro2.html#data-science",
    "title": "개관",
    "section": "Data Science",
    "text": "Data Science\n\nArtificial intelligence (인공 지능)\nMachine learning (기계 학습)\nDeep learning (심층 학습)\nData mining (데이터 마이닝)\nStatistical Learning (통계적 학습)\n\n\n\n\n소프트웨어 개발\n데이터에 기반한 분석 위해 작동하도록 프로그래밍을 하여 운영되도록 하는 일\n주로 전통적인 컴퓨터 사이언스의 커리큘럼에 의해 트레이닝\n\n유튜브의 영상 추천\n페이스북의 친구 매칭\n스팸메일 필터링\n자율주행\n\n\n\n\n\n\n데이터 분석\n하나의 구체적인 질문에 답하고자 함\n다양한 소스의 정제되는 않은 데이터를 통합하거나 가공하는 기술이 요구\n\nDNA의 분석을 통해 특정 질병의 발병 인자를 탐색\n유동인구와 매출을 분석해 상권을 분석\n어떤 정책의 유효성을 분석에 정책결정에 공헌\n교통 흐름의 지연이 어떻게 발생하는지를 분석, 해결책 제시",
    "crumbs": [
      "Introduction",
      "Data Analysis Intro"
    ]
  },
  {
    "objectID": "contents/Introduction/intro2.html#skills",
    "href": "contents/Introduction/intro2.html#skills",
    "title": "개관",
    "section": "Skills",
    "text": "Skills\n\n\nDomain knowledge\n\n해결하려는 문제에 대한 이해없이 단순한 알고리즘만으로 “one size fits all”은 효과적이지 않음\n추상화된 현실에 대한 모형은 수많은 가정/사전 지식(prior knowledge)을 전제하고 있음.\n각 분야의 전문 지식은 데이터가 발생되는 과정, 데이터의 특성, 데이터의 의미를 이해하는데 필수적\n\nEthics\n\n데이터를 합법적이고 적절하게 사용하려면 규정을 이해하고, 자신의 업무에 미치는 영향과 사회에 미치는 파급력 대한 윤리적 이해가 필요\n\n배출(exhaust) 데이터: 어떤 목적을 가진 데이터 수집 프로세스로부터 얻어진 부산물\n\n소셜 미디어: 사용자가 다른 사람들과 소통할 수 있도록 도움\n\n공유된 이미지, 블로그 게시물, 트윗, 좋아요 등으로부터\n누가/얼마나 많이 보았는지/좋아요/리트윗을 했는지 등을 수집\n\n아마존 웹사이트: 다양한 물건을 편리하게 구매할 수 있도록 도움\n\n사용자가 장바구니에 어떤 품목을 담았는지, 사이트에 얼마나 오래 머물렀는지, 어떤 다른 품목을 보았는지 등을 수집\n\n메타데이터(metadata)\n통화 내역만으로 많은 민감한 정보을 유추할 수 있음\n\n알코올 중독자 모임, 이혼 전문 변호사, 성병 전문 병원 등\n\n\n한편, 서비스와 마케팅을 타겟팅할 수 있는 잠재력\n\n\nWrangling\n\n데이터 소스는 다양한 형식으로 존재\n통합, 정리, 변환, 정규화 등의 작업이 요구\ndata munging, data wrangling, data cleaning, data preparation, data preprocessing 등으로 불림\n\nDatabase & computer science\n\n수집된 데이터가 저장되고, 가공/추출된 데이터의 재저장 등 데이터베이스와의 소통할 수 있는 기술\n다양해지고 방대해진 빅데이터를 저장/배포하기 위한 도구를 활용\nML 모델을 이해하고 개발하여 제품의 출시, 분석, 백엔드 애플리케이션에 통합할 수 있는 기술 등\n\nVisualisation\n\n작업 프로세스의 모든 과정에 관여\n\n데이터를 탐색하거나,\n데이터의 의미를 효과적으로 전달\n\n\nStatistics & Probability\n\n데이터 과학 프로세스 전반에 걸쳐 사용됨\n\n초기 수집과 조사\n다양한 모델과 분석의 결과를 해석\n의사결정에 활용\n\n\nMachine Learning\n\n데이터로부터 패턴을 찾기 위한 다양한 알고리즘을 사용\n응용 측면에서는\n\n수많은 알고리즘에 대해 가정, 특성, 용도, 결과의 의미, 적용가능한 유형의 데이터 등\n해결할 문제와 데이터에 가장 적합한 알고리즘을 파악\n\n\nCommunication\n\n데이터에 담긴 스토리를 효과적으로 전달하는 능력\n분석을 통해 얻은 인사이트, 조직 내 목적에 어떻게 부합하는지, 조직의 기능에 미칠 수 있는 영향 등",
    "crumbs": [
      "Introduction",
      "Data Analysis Intro"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contents/Introduction/rethinking.html",
    "href": "contents/Introduction/rethinking.html",
    "title": "Statistical thinking",
    "section": "",
    "text": "Data is a window, not a mirror to reality!\n\n수많은 가정과 사전 지식을 전제로 함: 올바른 결과 뿐 아니라 효율적인 분석을 위해 필요\n분석 결과는 주어진 가정에 대한 분명한 제시(transparency)와\n그 가정을 기반으로 한 적절한 해석이 요구됨\n\n\nSource: The Book of Why by Judea Pearl, Dana Mackenzie (2018)\n\n\n\n\n\n예측 모델\n예측의 신속성과 정확성\nMachine Learning 강점\nAlgorithmic\n\n이미지/사물 인식\n개인화된 추천 목록: 유튜브, 넷플릭스\n시리, ChatGPT의 답변\n비즈니스 분석\n이상치 탐지\n\n\n\n\n관계/원인 분석\n현상/실재에 대한 이해과 매커니즘 파악\nStatistical Models 강점\nParametric\n\n음식/운동의 효능\n광고의 효과\n복지/치안 정책의 효과\n\n\n\n\n\n\n\n전형적인 인과적 질문들\n\n\n\nHow effective is a given treatment in preventing a disease?\nWas it the new tax break that caused our sales to go up? Or our marketing campaign?\nWhat is the annual health-care costs attributed to obesity?\nCan hiring records prove an employer guilty of sex discrimination?\nI am about to quit my job, will I regret it?\n\n\n번역 by DeepL\n\n특정 치료법이 질병 예방에 얼마나 효과적일까요?\n새로운 세금 감면 혜택이 매출 상승의 원인이었을까요? 아니면 마케팅 캠페인 때문이었나요?\n비만으로 인한 연간 의료 비용은 얼마인가요?\n채용 기록으로 고용주의 성차별을 입증할 수 있나요?\n직장을 그만두려고 하는데 후회하게 될까요?\n\n\n\n예를 들어,\n\n닭의 울음이 태양을 솟게 하는가?\n돈과 행복: 패턴 vs. 예외\n\n임금 차별\n\n가난, 인종, 범죄\n출산율의 감소\n\n\n\n\n\n\n심리적 관성/편견 주의\n분석가의 책임의식\n두 가지 접근법(예측과 이해)는 서로 상보 관계!",
    "crumbs": [
      "Introduction",
      "Statistical Thinking"
    ]
  },
  {
    "objectID": "contents/Introduction/rethinking.html#데이터를-분석한다는-것은",
    "href": "contents/Introduction/rethinking.html#데이터를-분석한다는-것은",
    "title": "Statistical thinking",
    "section": "",
    "text": "Data is a window, not a mirror to reality!\n\n수많은 가정과 사전 지식을 전제로 함: 올바른 결과 뿐 아니라 효율적인 분석을 위해 필요\n분석 결과는 주어진 가정에 대한 분명한 제시(transparency)와\n그 가정을 기반으로 한 적절한 해석이 요구됨\n\n\nSource: The Book of Why by Judea Pearl, Dana Mackenzie (2018)\n\n\n\n\n\n예측 모델\n예측의 신속성과 정확성\nMachine Learning 강점\nAlgorithmic\n\n이미지/사물 인식\n개인화된 추천 목록: 유튜브, 넷플릭스\n시리, ChatGPT의 답변\n비즈니스 분석\n이상치 탐지\n\n\n\n\n관계/원인 분석\n현상/실재에 대한 이해과 매커니즘 파악\nStatistical Models 강점\nParametric\n\n음식/운동의 효능\n광고의 효과\n복지/치안 정책의 효과\n\n\n\n\n\n\n\n전형적인 인과적 질문들\n\n\n\nHow effective is a given treatment in preventing a disease?\nWas it the new tax break that caused our sales to go up? Or our marketing campaign?\nWhat is the annual health-care costs attributed to obesity?\nCan hiring records prove an employer guilty of sex discrimination?\nI am about to quit my job, will I regret it?\n\n\n번역 by DeepL\n\n특정 치료법이 질병 예방에 얼마나 효과적일까요?\n새로운 세금 감면 혜택이 매출 상승의 원인이었을까요? 아니면 마케팅 캠페인 때문이었나요?\n비만으로 인한 연간 의료 비용은 얼마인가요?\n채용 기록으로 고용주의 성차별을 입증할 수 있나요?\n직장을 그만두려고 하는데 후회하게 될까요?\n\n\n\n예를 들어,\n\n닭의 울음이 태양을 솟게 하는가?\n돈과 행복: 패턴 vs. 예외\n\n임금 차별\n\n가난, 인종, 범죄\n출산율의 감소\n\n\n\n\n\n\n심리적 관성/편견 주의\n분석가의 책임의식\n두 가지 접근법(예측과 이해)는 서로 상보 관계!",
    "crumbs": [
      "Introduction",
      "Statistical Thinking"
    ]
  },
  {
    "objectID": "contents/Introduction/rethinking.html#데이터-분석에-관한-전통적인-분류",
    "href": "contents/Introduction/rethinking.html#데이터-분석에-관한-전통적인-분류",
    "title": "Statistical thinking",
    "section": "데이터 분석에 관한 전통적인 분류",
    "text": "데이터 분석에 관한 전통적인 분류\n\n\n\n탐색적 분석 vs. 가설 검증\nexploratory vs. confirmatory\n\n탐색적 분석\n\n통찰 혹은 가설의 기초 제공\n끼워 맞추기? 오류에 빠지기 쉬움\n\n가설 검증\n\n진위의 확률을 높임\n탐색적 분석으로부터 온 가설은 재테스트\n\n\n\n\n\n관찰 vs. 실험 데이터\nobservational vs. experimental\n\n당근과 시력?\n커피의 효과?\n남녀의 임금 차별?\n\n\n\n\n표본 vs. 모집단\nsample vs. population\n\nParameter(모수), uncertainty(불확실성)\n내일 태양이 뜰 확률?\n연봉과 삶의 만족도와 관계\n성별과 임금과의 관계\n두통약의 효능: “effect size”",
    "crumbs": [
      "Introduction",
      "Statistical Thinking"
    ]
  },
  {
    "objectID": "contents/Introduction/rethinking.html#통계적-사고",
    "href": "contents/Introduction/rethinking.html#통계적-사고",
    "title": "Statistical thinking",
    "section": "통계적 사고",
    "text": "통계적 사고\nDistribution\n\n남녀 임금의 차이\n \n\n\nConfounding\nCommon Cause\n\n머리가 길면 우울증도 높다?\n초등생이 발이 크면 독해력도 높다?\n\n\n\n\n\n\n\nAnswers!\n\n\n\n\n\nSpurious relations\n \n\n\n\n앞서 든 예도 마찬가지로\n  \n올바른 관계를 파악하려면, 동일한 나이에 대해 그 관계를 파악한 후 각 나이에서의 효과를 (weighted) 평균해서 살펴봐야함\n통계에서는 이를 나이를 통제 (control for age)한다고 표현하며, 같은 의미로 다음과 같은 표현을 씀\n\n나이를 고려했을 때; account for age\n\n나이를 조정했을 때; adjust for age\n\n나이와 무관/독립인; independent of age\n\nSimpson’s paradox\n\nSource: The book of why by Judea Pearl\n예를 들어, 은퇴한 노인들을 대상으로 규칙적인 걷기가 사망율을 감소시킬 것이라는 가설을 확인하기 위해 1965년 이후 8000명 가량의 남성들을 추적조사한 데이터의 일부를 이용했는데,\n\n12년 후 사망율에서 casual walker(하루 1마일 이하)와 intense walker(하루 2마일 이상)가 각각 43%, 21.5%로 나타났음.\n이 걷기의 효과를 의심케 하는 요소들(confounding)은 무엇인가?\n\n\n\n\n\n\n\nAnswers!\n\n\n\n\n\n\n건강이 나빠 많이 걷지 못했을 수도…\n많이 걷는 사람은 상대적으로 젊을 수도…\n많이 먹는 사람이 덜 걸을 수도…\n술을 많이 먹는 사람이 덜 걸을 수도…\n\n\n\n\n남녀 연봉 차이의 원인을 찾으려면?\n\n직업 특성, 부서, 직급, 연령, 출산, 출세욕\n\n\n\nColider bias\n운동능력이 뛰어나면 지능이 떨어지는가?\n\nSource: Statistical Modeling by Daniel T. Kaplan\nMechanisms/Mediation\n\n레몬과 괴혈병\n\n\n만약, 장거리 항해에서 상급자(높은 연령)에게만 과일이 제공되었을 때, 나이가 많은 선원들에게서 괴혈병이 덜 생겼다는 현상으로부터 연령과 괴혈병의 관계를 추론해서는 안됨. 하지만 예측은 여전히 유효함.\n\n\n\n수집된 데이터의 성격\nSelection Bias\n수집된 데이터의 성격에 따라 인과추론을 방해하거나(confounding)\n일반화할 수 있는 대상의 범위가 제한됨(external validity)\n\n노인에 관한 데이터: 누가 사망했는가?\n관찰 할 수 없는 대상\n과거 기록을 이용?\n누가 참여했는가?\n회사 내에서의 만족도 조사: 근속년수에 따른 샘플 속성의 변화\n코호트/특정세대의 특성: 그들의 특성인가?\n\n\n\n실험\nExperiment\nRCT (randomized controlled trial)\n\n개념적으로는 물리적 통제라고 볼 수 있으며,\n두 그룹으로 집단을 randomly assign(무선/무작위 배정/할당)",
    "crumbs": [
      "Introduction",
      "Statistical Thinking"
    ]
  },
  {
    "objectID": "contents/notice.html#중간고사",
    "href": "contents/notice.html#중간고사",
    "title": "Notice",
    "section": "중간고사",
    "text": "중간고사",
    "crumbs": [
      "{{< fa check size=xs >}} Notice"
    ]
  },
  {
    "objectID": "contents/notice.html#기말고사",
    "href": "contents/notice.html#기말고사",
    "title": "Notice",
    "section": "기말고사",
    "text": "기말고사",
    "crumbs": [
      "{{< fa check size=xs >}} Notice"
    ]
  },
  {
    "objectID": "contents/notice.html#개별-프로젝트",
    "href": "contents/notice.html#개별-프로젝트",
    "title": "Notice",
    "section": "개별 프로젝트",
    "text": "개별 프로젝트",
    "crumbs": [
      "{{< fa check size=xs >}} Notice"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균 / sk.cho@snu.ac.kr\n면담 시간: 수업 후\n수업시간: 월, 수 1:00 ~ 2:50PM\nWebsite: dgdavs.modellings.art\n과제: Notice\n질문: Communicate/Ask",
    "crumbs": [
      "{{< fa angles-right size=xs >}} Welcome"
    ]
  },
  {
    "objectID": "index.html#강의-정보",
    "href": "index.html#강의-정보",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균 / sk.cho@snu.ac.kr\n면담 시간: 수업 후\n수업시간: 월, 수 1:00 ~ 2:50PM\nWebsite: dgdavs.modellings.art\n과제: Notice\n질문: Communicate/Ask",
    "crumbs": [
      "{{< fa angles-right size=xs >}} Welcome"
    ]
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n본 강의에서는 인터넷과 기술의 발전으로 풍부한 데이터들이 양산됨에 따라 그 안에 숨겨진 패턴을 찾고 분석하여 실증적 사실과 원리를 파악하는데 요구되는 기술들을 계발하는데 도움을 주고자 합니다. 이를 위해서는 1) 데이터 분석 툴을 자유자재로 다룰 수 있는 기술, 2) 주어진 데이터에 적절한 툴을 선택할 수 있는 판단력, 3) 파악한 패턴으로부터 현상의 본질을 추론할 수 있는 인과관계 추론의 원리들이 함께 필요합니다.\n\n데이터를 조작, 가공하는 기술을 익히고,\n이를 통해 얻은 정제된 데이터를 시각화를 통해패턴을 여러 각도에서 살펴보고,\n데이터 모델링과 통계적 분석을 접목하여 현상에 대한 올바른이해를 돕습니다.\n\n수업은 크게 5부분으로 나뉨\n\n탐색적 분석 (exploratory data analysis)과 그에 필요한 데이터 전처리 (data wrangling)\n데이터 시각화 (data visualization)\n기술적 분석 (descriptive analysis)\n모델링 (modelling)\n통계 (statistics)\n\n\n교재\n\n번역서: Pandas를 이용한 데이터 분석 실습 2/e\nHands-On Data Analysis with Pandas (2e) by Stefanie Molin: code in GitHub\nPython for Data Analysis (3e) by Wes McKinney: code in GitHub\n3판 번역서: 파이썬 라이브러리를 활용한 데이터 분석\nR for Data Science by Wickham & Grolemund; 2nd edition",
    "crumbs": [
      "{{< fa angles-right size=xs >}} Welcome"
    ]
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (5%), 일반과제 (25%), 중간고사 (25%), 기말고사 (25%), 개별 프로젝트 (20%)",
    "crumbs": [
      "{{< fa angles-right size=xs >}} Welcome"
    ]
  },
  {
    "objectID": "index.html#수업-계획",
    "href": "index.html#수업-계획",
    "title": "Welcome",
    "section": "수업 계획",
    "text": "수업 계획\n1주. 강의 개요 및 데이터 분석의 의미 소개\n2주. 넘파이와 판다스 라이브러리의 기본\n3주. 탐색적 분석을 위한 시각화 라이브러리\n4주. 시각화의 활용1\n5주. 시각화의 활용2\n6주. 판다스를 이용한 데이터의 변형 및 가공 1\n7주. 판다스를 이용한 데이터의 변형 및 가공 2\n8주. 기술적(descriptive) 분석 1\n9주. 기술적(descriptive) 분석 2\n10주. 탐색적 분석 & 및 중간고사\n11주. 데이터 모델링 기초 & 통계의 기초 개념\n12주. 데이터 모델링 1\n13주. 데이터 모델링 2\n14주. Binary 명목 변수에 대한 분석: 로지스틱 회귀분석 및 GLM 소개\n15주. 기말고사",
    "crumbs": [
      "{{< fa angles-right size=xs >}} Welcome"
    ]
  },
  {
    "objectID": "contents/Introduction/pandas.html",
    "href": "contents/Introduction/pandas.html",
    "title": "NumPy and pandas",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\nNumpy & pandas\nPython 언어는 수치 계산을 위해 디자인되지 않았기 때문에, 데이터 분석에 대한 효율적이고 빠른 계산이 요구되면서 C/C++이라는 언어로 구현된 NumPy (Numerical Python)가 탄생하였고, Python 생태계 안에 통합되었음. 기본적으로 Python 언어 안에 새로운 언어라고 볼 수 있음. 데이터 사이언스에서의 대부분의 계산은 NumPy의 ndarray (n-dimensioal array)와 수학적 operator들을 통해 계산됨.\n데이터 사이언스가 발전함에 따라 단일한 floating-point number들을 성분으로하는 array들의 계산에서 벗어나 칼럼별로 다른 데이터 타입(string, integer, object..)을 포함하는 tabular형태의 데이터를 효율적으로 처리해야 할 필요성이 나타났고, 이를 다룰 수 있는 새로운 언어를 NumPy 위에 개발한 것이 pandas임. 이는 기본적으로 Wes Mckinney에 의해 독자적으로 개발이 시작되었으며, 디자인적으로 불만족스러운 점이 지적되고는 있으나 데이터 사이언스의 기본적인 언어가 되었음.\nNumPy와 pandas에 대한 자세한 내용은 Python for Data Analysis by Wes MacKinney 참고\n특히, NumPy는 Ch.4 & appendices",
    "crumbs": [
      "Introduction",
      "NumPy and pandas"
    ]
  },
  {
    "objectID": "contents/Introduction/pandas.html#numpy",
    "href": "contents/Introduction/pandas.html#numpy",
    "title": "NumPy and pandas",
    "section": "NumPy",
    "text": "NumPy\n\n수학적 symbolic 연산에 대한 구현이라고 볼 수 있으며,\n행렬(matrix) 또는 벡터(vector)를 ndarray (n-dimensional array)이라는 이름으로 구현함.\n\n사실상 정수(int)나 실수(float)의 한가지 타입으로 이루어짐.\n\n고차원의 arrays 가능\n\nSource: Medium.com\n\n\n가령, 다음과 같은 행렬 연산이 있다면,\n\\(\\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\begin{bmatrix}2 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2 \\\\ 4 \\end{bmatrix}\\)\n\n\nA = np.array([[1, 2],\n              [3, 4],\n              [5, 6]]) # 3x2 matrix\nX = np.array([[2],\n              [-1]]) # 2x1 matrix\n\nA @ X  # A * X : matrix multiplication\n\narray([[0],\n       [2],\n       [4]])\n\n\n\nA.dot(X)\n\narray([[0],\n       [2],\n       [4]])\n\n\nVector vs. Matrix\n\nprint(np.array([0, 2, 4])) # 1-dim matrix: vector\nprint(np.array([0, 2, 4]).reshape(3, 1)) # 3x1 matrix\n\n[0 2 4]\n[[0]\n [2]\n [4]]\n\n\n\narr = np.array([0, 2, 4])\narr.reshape(3, -1).T\n\narray([[0, 2, 4]])\n\n\n\nX2 = np.array([2, -1])\nA @ X2  # same as A.dot(X2)\n\narray([0, 2, 4])\n\n\n\nprint(A.shape)\nprint(A.ndim)\nprint(A.dtype)\n\n(3, 2)\n2\nint64\n\n\n\nA + A # element-wise addition\n\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n\n\n\n2 * A - 1 # braodcasting\n\narray([[ 1,  3],\n       [ 5,  7],\n       [ 9, 11]])\n\n\n\nnp.exp(A) # element-wise\n\narray([[  2.72,   7.39],\n       [ 20.09,  54.6 ],\n       [148.41, 403.43]])\n\n\n\nPython vs. NumPy\n\na = 2**31 - 1\nprint(a)\nprint(a + 1)\n\n2147483647\n2147483648\n\n\n\na = np.array([2**31 - 1], dtype='int32')\nprint(a)\nprint(a + 1)\n\n[2147483647]\n[-2147483648]\n\n\n\nSource: Ch.4 in Python for Data Analysis (3e) by Wes McKinney",
    "crumbs": [
      "Introduction",
      "NumPy and pandas"
    ]
  },
  {
    "objectID": "contents/Introduction/pandas.html#pandas",
    "href": "contents/Introduction/pandas.html#pandas",
    "title": "NumPy and pandas",
    "section": "pandas",
    "text": "pandas\nSeries & DataFrame\n\nSeries\n1개의 칼럼으로 이루어진 데이터 포멧: 1d numpy array에 labels을 부여한 것으로 볼 수 있음.\nDataFrame의 각 칼럼들을 Series로 이해할 수 있음.\n\nSource: Practical Data Science\n\n\nDataFrame\n각 칼럼들이 한 가지 데이터 타입으로 이루어진 tabular형태 (2차원)의 데이터 포맷\n\n각 칼럼은 기본적으로 한 가지 데이터 타입인 것이 이상적이나, 다른 타입이 섞여 있을 수 있음\nNumPy의 2차원 array의 각 칼럼에 labels을 부여한 것으로 볼 수도 있으나, 여러 다른 기능들이 추가됨\nNumPy의 경우 고차원의 array를 다룰 수 있음: ndarray\n\n고차원의 DataFrame과 비슷한 것은 xarray가 존재\n\nLabels와 index를 제외한 데이터 값은 거의 NumPy ndarray로 볼 수 있음\n(pandas.array 존재)\n\n\nSource: Practical Data Science\n\n\nndarray &lt;&gt; DataFrame\n\ndf = pd.DataFrame(A, columns=[\"A1\", \"A2\"])\ndf\n\n   A1  A2\n0   1   2\n1   3   4\n2   5   6\n\n\n\n# 데이터 값들은 NumPy array\ndf.values # 또는 df.to_numpy()\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n\n\nColumns\nSeries로 추출\n\ns = df[\"A1\"] # A1 칼럼 선택\ns\n# DataFrame의 column 이름이 Series의 name으로 전환\n\n0    1\n1    3\n2    5\nName: A1, dtype: int64\n\n\n\ntype(s)\n\npandas.core.series.Series\n\n\n\ns.values # Series의 값은 1d array\n\narray([1, 3, 5])\n\n\n\n\n\n\n\n\nA DataFrame with a single column\n\n\n\n\n\ndf[[\"A1\"]] # double brackets\n\n\n\n\n\n\n\n\n\nIndex objects\nframe = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                     index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                     columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\nframe\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\n\n\nframe.index\n\nIndex(['Ohio', 'Colorado'], dtype='object', name='state')\n\n\n\nframe.columns # columns도 index object\n\nIndex(['one', 'two', 'three'], dtype='object', name='number')\n\n\n\n\n\n\n\n\nNote\n\n\n\n“number”: columns의 이름 “state”: index의 이름\nframe.columns.name #&gt; ‘number’\nframe.index.name #&gt; ‘state’\n\n\n\nMulti-Index object\nIndex는 여러 levels을 지닐 수 있음\n\nframe.stack() # stack()은 long form으로 변환\n# 2 levels의 index를 가진 Series\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\n# MultiIndex를 직접 구성\npd.DataFrame(np.arange(12).reshape((4, 3)),\n        index=pd.MultiIndex.from_arrays([[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]], names=[\"idx1\", \"idx2\"]),\n        columns=pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"], [\"Green\", \"Red\", \"Green\"]], names=[\"state\", \"color\"]))\n\nstate      Ohio     Colorado\ncolor     Green Red    Green\nidx1 idx2                   \na    1        0   1        2\n     2        3   4        5\nb    1        6   7        8\n     2        9  10       11\n\n\n\n\nTime Series\nIndex는 times series에 특화\n\nfb = pd.read_csv('data/fb_stock_prices_2018.csv', index_col='date', parse_dates=True)\nfb.head()\n\n             open   high    low  close    volume\ndate                                            \n2018-01-02 177.68 181.58 177.55 181.42  18151903\n2018-01-03 181.88 184.78 181.33 184.67  16886563\n2018-01-04 184.90 186.21 184.10 184.33  13880896\n2018-01-05 185.59 186.90 184.93 186.85  13574535\n2018-01-08 187.20 188.90 186.33 188.28  17994726\n\n\n\nfb.plot(kind='line', y=['high', 'low'], figsize=(7, 4), title='Facebook Stock 2018')\nplt.show()\n\n\n\n\n\n\n\n\nindex없이 분석 가능?\nindex의 활용은 강의 후반부에…\nIndex를 column으로 전환시켜 분석할 수 있음: .reset_index()\n\nfb.reset_index()\n\n          date   open   high    low  close    volume\n0   2018-01-02 177.68 181.58 177.55 181.42  18151903\n1   2018-01-03 181.88 184.78 181.33 184.67  16886563\n2   2018-01-04 184.90 186.21 184.10 184.33  13880896\n..         ...    ...    ...    ...    ...       ...\n248 2018-12-27 132.44 134.99 129.67 134.52  31202509\n249 2018-12-28 135.34 135.92 132.20 133.20  22627569\n250 2018-12-31 134.45 134.64 129.95 131.09  24625308\n\n[251 rows x 6 columns]\n\n\n반대로 column을 index로 전환: .set_index(\"column\")\n\nfb.reset_index().set_index(\"date\")\n\n             open   high    low  close    volume\ndate                                            \n2018-01-02 177.68 181.58 177.55 181.42  18151903\n2018-01-03 181.88 184.78 181.33 184.67  16886563\n2018-01-04 184.90 186.21 184.10 184.33  13880896\n...           ...    ...    ...    ...       ...\n2018-12-27 132.44 134.99 129.67 134.52  31202509\n2018-12-28 135.34 135.92 132.20 133.20  22627569\n2018-12-31 134.45 134.64 129.95 131.09  24625308\n\n[251 rows x 5 columns]\n\n\n\n\n\n\nDataFrame의 연산\nNumPy의 ndarray들이 연산되는 방식과 동일하게 series나 DataFrame들의 연산 가능함\n\ndf + 2 * df\n\n   A1  A2\n0   3   6\n1   9  12\n2  15  18\n\n\n\nnp.log(df)\n\n    A1   A2\n0 0.00 0.69\n1 1.10 1.39\n2 1.61 1.79\n\n\n사실 연산은 index를 align해서 시행됨\n\n\n\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\nnumber  one  two  three\nstate                  \nOhio      0    2      4\nFloria    6    8     10\n\n\n\nframe1 + frame2\n\n\n\nnumber    one  two  three\nstate                    \nColorado  NaN  NaN    NaN\nFloria    NaN  NaN    NaN\nOhio     0.00 3.00   6.00\n\n\n\n\n(참고) Mixed Data Type\n\ns = pd.Series([1, 2, \"3\"])\n\n\ns.dtype\n\ndtype('O')\n\n\n\ns + s\n\n0     2\n1     4\n2    33\ndtype: object\n\n\n\ns_int = s.astype(\"int\")\ns_int + s_int\n\n0    2\n1    4\n2    6\ndtype: int64\n\n\n\ns2 = pd.Series([1, 2, 3.1])\ns2.dtype\n\ndtype('float64')\n\n\n\ns2.astype(\"int\")\n\n0    1\n1    2\n2    3\ndtype: int64",
    "crumbs": [
      "Introduction",
      "NumPy and pandas"
    ]
  },
  {
    "objectID": "contents/Introduction/pandas.html#missing",
    "href": "contents/Introduction/pandas.html#missing",
    "title": "NumPy and pandas",
    "section": "Missing",
    "text": "Missing\nNaN, NA, None\npandas에서는 missing을 명명하는데 R의 컨벤션을 따라 NA (not available)라 부름.\n대부분의 경우에서 NumPy object NaN(np.nan)을 NA을 나타내는데 사용됨.\nnp.nan은 실제로 floating-point의 특정 값으로 float64 데이터 타입임. Integer 또는 string type에서 약간 이상하게 작동될 수 있음.\nPython object인 None은 pandas에서 NA로 인식함.\n현재 NA라는 새로운 pandas object 실험중임\nNA의 handling에 대해서는 교재 참고\n.dropna(), .fillna(), .isna(), .notna()\n\nMckinney’s: 7.1 Handling Missing Data,\n\nMollin’s: 3.5 Handling duplicate, missing, or invalid data\n\nWorking with missing data\n\n\ns = pd.Series([1, 2, np.nan])\ns\n\n0   1.00\n1   2.00\n2    NaN\ndtype: float64\n\n\n\ns.astype(\"Int64\") # &lt;NA&gt;\n\n0       1\n1       2\n2    &lt;NA&gt;\ndtype: Int64\n\n\n\ns = pd.Series([\"a\", \"b\", np.nan])\ns\n\n0      a\n1      b\n2    NaN\ndtype: object\n\n\n\ns.astype(\"string\") # &lt;NA&gt;\n\n0       a\n1       b\n2    &lt;NA&gt;\ndtype: string\n\n\n\ns = pd.Series([1, 2, np.nan, None])\ns\n\n0   1.00\n1   2.00\n2    NaN\n3    NaN\ndtype: float64\n\n\n\ns.isna() # or s.isnull()\n\n0    False\n1    False\n2     True\n3     True\ndtype: bool\n\n\n\ns.notna() # or s.notnull()\n\n0     True\n1     True\n2    False\n3    False\ndtype: bool\n\n\n\n\n\n\n\n\nNote\n\n\n\nPython object인 None의 경우\nNone == None\n#&gt; True\nNumPy object인 np.nan의 경우\nnp.nan == np.nan\n#&gt; False",
    "crumbs": [
      "Introduction",
      "NumPy and pandas"
    ]
  },
  {
    "objectID": "contents/Introduction/pandas.html#attributes",
    "href": "contents/Introduction/pandas.html#attributes",
    "title": "NumPy and pandas",
    "section": "Attributes",
    "text": "Attributes\n자주 사용되는 attributes;\nSeries objects: name, dtype, shape, index, values\nIndex objects: name, dtype, shape, values, is_unique\nDataFrame objects: dtype, shape, index, columns, values",
    "crumbs": [
      "Introduction",
      "NumPy and pandas"
    ]
  },
  {
    "objectID": "contents/Introduction/pandas.html#creating-dataframes",
    "href": "contents/Introduction/pandas.html#creating-dataframes",
    "title": "NumPy and pandas",
    "section": "Creating DataFrames",
    "text": "Creating DataFrames\nDataFrame을 만드는 방식에 대해서는\nMckinney’s: 5.1 Introduction to pandas Data Structures",
    "crumbs": [
      "Introduction",
      "NumPy and pandas"
    ]
  }
]