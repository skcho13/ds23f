[
  {
    "objectID": "contents/vis.html",
    "href": "contents/vis.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Python의 시각화 라이브러리는 다양하게 개발되어지고 있으며, 각기 특성이 달라 하나로만 쓰기 어려운 상황임\nR의 ggplot2라는 매우 강력한 시각화 도구와 비교하면 이에 상응할 만한 Python 시각화 도구는 찾기 어려움\n\n\n\nMatplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017"
  },
  {
    "objectID": "contents/vis.html#대표적-도구들",
    "href": "contents/vis.html#대표적-도구들",
    "title": "Data Visualization",
    "section": "",
    "text": "Matplotlib\n가장 오래된 Python과 잘 통합된 널리 사용되는 라이브러리\n거의 가능한 모든 플랏을 그릴 수 있음\n한편, 디테일한 부분을 모두 specify해야 함으로써 많은 코딩이 요구되며, interactive 또는 web graphs에 취약함\npandas\nMatplotlib로 구현된 DataFrame의 method로 간략하게 시각화가 가능하며, 빠르게 데이터를 들여다볼 수 있음\nSeaborn & the seaborn.objects interface\nMatplotlib 위에 개발된 간결한 문법의 high-level 언어\nDecalative: 변수들이 어떤 시각화 속성과 위치를 지니는지만 specify\n“Grammer of graphics”라는 시각화 문법에 충실하고자 the seaborn.objects로 새롭게 변화 중\n\n\n\nAltair\n“Grammer of graphics”를 충실히 따라 설계됨\n각 plot이 이미지가 아닌 data + specification으로 이루어짐: 이미지가 저장되지 않고, 브라우저에서 이미지로 complie되어 생성됨\nWeb-based interactive 시각화인 D3에 그 모체를 두며, Vega/Vega-Lite로부터 파생됨\njavascript-based로 interactive 시각화에 용이하나 Python과 연계가 부족한 부분이 있고, 개발이 더딘 듯\nBokeh\nPlotly\n다양한 언어(R, Python, Julia)을 지원하며, 기업 수준의 상용화 제품들도 있으며, 지원군 많음\n\n\nJake VanderPlas의 2017년 발표 자료 중: The Python Visualization Landscape\n\nSource: Jake VanderPlas - The Python Visualization Landscape PyCon 2017"
  },
  {
    "objectID": "contents/vis.html#the-grammer-of-graphics",
    "href": "contents/vis.html#the-grammer-of-graphics",
    "title": "Data Visualization",
    "section": "The Grammer of Graphics",
    "text": "The Grammer of Graphics\nA coherent system for describing and building graphs\nSource: Fundamentals of Data Visualization by Claus O. Wilke\nAesthetics and types of data\n\n데이터의 값을 특정 aesthetics에 mapping\n\n데이터의 타입은 다음과 같이 나누어짐\n\ncontinuous / discrete\nquatitative / qualitative\ncategorical unordered (nominal) / categorical ordered (ordinal)\n\n성별, 지역 / 등급, 랭킹\nordinal: 등간격을 가정\n\n퀄리티 good, fair, poor는 등간격이라고 봐야하는가?\n랭킹은?\n선호도 1, 2, …, 8; continuous?\n임금 구간?\n\n\n\n데이터 타입에 따라 좀 더 적절한 aesthetic mapping이 있으며,\n같은 정보를 품고 있는 시각화라도 더 적절한 representation이 존재\nBertin’s Semiology of Graphics (1967)\nLevels of organization\n\nSource: Jake VanderPlas’ presentation at PyCon 2018\n\nCase 1\n예를 들어, 다음과 같이 1) 지역별로 2) 날짜에 따른 3) 온도의 변화를 나타낸다면,\n즉, x축의 위치에 날짜 정보를, y축의 위치에 온도 정보를, 색깔에 지역 정보를 할당했음.\n\n한편, 아래는 x축의 위치에 압축된 날짜 정보를, y축의 위치에 지역 정보를, 색깔에 압축된 온도 정보를 할당했음.\n\n\n\nCase 2\n다음은 GDP, mortality, population, region의 네 정보를 다른 방식으로 mapping한 결과임."
  },
  {
    "objectID": "contents/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "href": "contents/vis.html#탐색적-exploratory-vs.-정보전달-communicative",
    "title": "Data Visualization",
    "section": "탐색적 (Exploratory) vs. 정보전달 (Communicative)",
    "text": "탐색적 (Exploratory) vs. 정보전달 (Communicative)"
  },
  {
    "objectID": "contents/vis.html#interative-plots",
    "href": "contents/vis.html#interative-plots",
    "title": "Data Visualization",
    "section": "Interative Plots",
    "text": "Interative Plots\nAltair\n\n\n\n\n\n\n\nPlotly"
  },
  {
    "objectID": "contents/transform.html",
    "href": "contents/transform.html",
    "title": "Transforming I",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.mode.copy_on_write = True\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\n이번 장에서는 시각화를 하기 전후로, 중요한 데이터 패턴을 보기 위해서 새로운 변수를 만들거나 요약한 통계치를 만들 필요가 있는데 이를 다루는 핵심적인 함수들에 대해 익힙니다.\n대략 다음과 같은 transform들을 조합하여 분석에 필요한 상태로 바꿉니다.\nOn-time data for all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013\n# import the dataset\nflights_data = sm.datasets.get_rdataset(\"flights\", \"nycflights13\")\nflights = flights_data.data\nflights = flights.drop(columns=\"time_hour\")  # drop the \"time_hour\" column\n# Description\nprint(flights_data.__doc__)\nflights\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n0\n2013\n1\n1\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n2013\n1\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n2013\n1\n1\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336773\n2013\n9\n30\nNaN\n1210\nNaN\nNaN\n1330\nNaN\nMQ\n3461\nN535MQ\nLGA\nBNA\nNaN\n764\n12\n10\n\n\n336774\n2013\n9\n30\nNaN\n1159\nNaN\nNaN\n1344\nNaN\nMQ\n3572\nN511MQ\nLGA\nCLE\nNaN\n419\n11\n59\n\n\n336775\n2013\n9\n30\nNaN\n840\nNaN\nNaN\n1020\nNaN\nMQ\n3531\nN839MQ\nLGA\nRDU\nNaN\n431\n8\n40\n\n\n\n\n336776 rows × 18 columns\nflights.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 336776 entries, 0 to 336775\nData columns (total 18 columns):\n #   Column          Non-Null Count   Dtype  \n---  ------          --------------   -----  \n 0   year            336776 non-null  int64  \n 1   month           336776 non-null  int64  \n 2   day             336776 non-null  int64  \n 3   dep_time        328521 non-null  float64\n 4   sched_dep_time  336776 non-null  int64  \n 5   dep_delay       328521 non-null  float64\n 6   arr_time        328063 non-null  float64\n 7   sched_arr_time  336776 non-null  int64  \n 8   arr_delay       327346 non-null  float64\n 9   carrier         336776 non-null  object \n 10  flight          336776 non-null  int64  \n 11  tailnum         334264 non-null  object \n 12  origin          336776 non-null  object \n 13  dest            336776 non-null  object \n 14  air_time        327346 non-null  float64\n 15  distance        336776 non-null  int64  \n 16  hour            336776 non-null  int64  \n 17  minute          336776 non-null  int64  \ndtypes: float64(5), int64(9), object(4)\nmemory usage: 46.2+ MB"
  },
  {
    "objectID": "contents/transform.html#rows",
    "href": "contents/transform.html#rows",
    "title": "Transforming I",
    "section": "Rows",
    "text": "Rows\n\nquery()\n\nConditional operators\n&gt;, &gt;=, &lt;, &lt;=,\n== (equal to), != (not equal to)\nand, & (and)\nor, | (or)\nnot, ~ (not)\nin (includes), not in (not included)\n\n\n# Flights that arrived more than 120 minutes (two hours) late\nflights.query('arr_delay &gt; 120')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n119\n2013\n1\n1\n811.00\n630\n101.00\n1047.00\n830\n137.00\nMQ\n4576\nN531MQ\nLGA\nCLT\n118.00\n544\n6\n30\n\n\n151\n2013\n1\n1\n848.00\n1835\n853.00\n1001.00\n1950\n851.00\nMQ\n3944\nN942MQ\nJFK\nBWI\n41.00\n184\n18\n35\n\n\n218\n2013\n1\n1\n957.00\n733\n144.00\n1056.00\n853\n123.00\nUA\n856\nN534UA\nEWR\nBOS\n37.00\n200\n7\n33\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336724\n2013\n9\n30\n2053.00\n1815\n158.00\n2310.00\n2054\n136.00\nEV\n5292\nN600QX\nEWR\nATL\n91.00\n746\n18\n15\n\n\n336757\n2013\n9\n30\n2159.00\n1845\n194.00\n2344.00\n2030\n194.00\n9E\n3320\nN906XJ\nJFK\nBUF\n50.00\n301\n18\n45\n\n\n336763\n2013\n9\n30\n2235.00\n2001\n154.00\n59.00\n2249\n130.00\nB6\n1083\nN804JB\nJFK\nMCO\n123.00\n944\n20\n1\n\n\n\n\n10034 rows × 18 columns\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n외부 변수/함수를 참조하려면 @와 함께\ndelay_cutoff = 120\nflights.query('arr_delay &gt; @delay_cutoff')\ndef cut_off(df):\n    return df[\"dep_delay\"].min()\n\nflights.query('arr_delay &lt; @cut_off(@flights)')\n위의 query 방식의 filtering은 다음과 같은 boolean indexing의 결과와 같음\nflights[flights[\"arr_delay\"] &gt; 120]\n\n\n\n# Flights that departed on January 1\nflights.query('month == 1 and day == 1')  # == 과 = 을 혼동하지 말것!\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n0\n2013\n1\n1\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n2013\n1\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n2013\n1\n1\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n839\n2013\n1\n1\nNaN\n1935\nNaN\nNaN\n2240\nNaN\nAA\n791\nN3EHAA\nLGA\nDFW\nNaN\n1389\n19\n35\n\n\n840\n2013\n1\n1\nNaN\n1500\nNaN\nNaN\n1825\nNaN\nAA\n1925\nN3EVAA\nLGA\nMIA\nNaN\n1096\n15\n0\n\n\n841\n2013\n1\n1\nNaN\n600\nNaN\nNaN\n901\nNaN\nB6\n125\nN618JB\nJFK\nFLL\nNaN\n1069\n6\n0\n\n\n\n\n842 rows × 18 columns\n\n\n\n\n# Flights that departed in January or February\nflights.query('month == 1 or month == 2')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n0\n2013\n1\n1\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n2013\n1\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n2013\n1\n1\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n136244\n2013\n2\n28\nNaN\n1115\nNaN\nNaN\n1310\nNaN\nMQ\n4485\nN725MQ\nLGA\nCMH\nNaN\n479\n11\n15\n\n\n136245\n2013\n2\n28\nNaN\n830\nNaN\nNaN\n1205\nNaN\nUA\n1480\nNaN\nEWR\nSFO\nNaN\n2565\n8\n30\n\n\n136246\n2013\n2\n28\nNaN\n840\nNaN\nNaN\n1147\nNaN\nUA\n443\nNaN\nJFK\nLAX\nNaN\n2475\n8\n40\n\n\n\n\n51955 rows × 18 columns\n\n\n\n\n# A shorter way to select flights that departed in January or February\nflights.query('month in [1, 2]')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n0\n2013\n1\n1\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n2013\n1\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n2013\n1\n1\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n136244\n2013\n2\n28\nNaN\n1115\nNaN\nNaN\n1310\nNaN\nMQ\n4485\nN725MQ\nLGA\nCMH\nNaN\n479\n11\n15\n\n\n136245\n2013\n2\n28\nNaN\n830\nNaN\nNaN\n1205\nNaN\nUA\n1480\nNaN\nEWR\nSFO\nNaN\n2565\n8\n30\n\n\n136246\n2013\n2\n28\nNaN\n840\nNaN\nNaN\n1147\nNaN\nUA\n443\nNaN\nJFK\nLAX\nNaN\n2475\n8\n40\n\n\n\n\n51955 rows × 18 columns\n\n\n\n\nflights.query('arr_delay &gt; 120 and not (origin == \"JFK\")')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n119\n2013\n1\n1\n811.00\n630\n101.00\n1047.00\n830\n137.00\nMQ\n4576\nN531MQ\nLGA\nCLT\n118.00\n544\n6\n30\n\n\n218\n2013\n1\n1\n957.00\n733\n144.00\n1056.00\n853\n123.00\nUA\n856\nN534UA\nEWR\nBOS\n37.00\n200\n7\n33\n\n\n268\n2013\n1\n1\n1114.00\n900\n134.00\n1447.00\n1222\n145.00\nUA\n1086\nN76502\nLGA\nIAH\n248.00\n1416\n9\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336529\n2013\n9\n30\n1738.00\n1529\n129.00\n1906.00\n1649\n137.00\nEV\n4580\nN12563\nEWR\nMKE\n110.00\n725\n15\n29\n\n\n336668\n2013\n9\n30\n1951.00\n1649\n182.00\n2157.00\n1903\n174.00\nEV\n4294\nN13988\nEWR\nSAV\n95.00\n708\n16\n49\n\n\n336724\n2013\n9\n30\n2053.00\n1815\n158.00\n2310.00\n2054\n136.00\nEV\n5292\nN600QX\nEWR\nATL\n91.00\n746\n18\n15\n\n\n\n\n6868 rows × 18 columns\n\n\n\n\nflights.query('dep_time &lt; sched_dep_time')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n3\n2013\n1\n1\n544.00\n545\n-1.00\n1004.00\n1022\n-18.00\nB6\n725\nN804JB\nJFK\nBQN\n183.00\n1576\n5\n45\n\n\n4\n2013\n1\n1\n554.00\n600\n-6.00\n812.00\n837\n-25.00\nDL\n461\nN668DN\nLGA\nATL\n116.00\n762\n6\n0\n\n\n5\n2013\n1\n1\n554.00\n558\n-4.00\n740.00\n728\n12.00\nUA\n1696\nN39463\nEWR\nORD\n150.00\n719\n5\n58\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336766\n2013\n9\n30\n2240.00\n2250\n-10.00\n2347.00\n7\n-20.00\nB6\n2002\nN281JB\nJFK\nBUF\n52.00\n301\n22\n50\n\n\n336767\n2013\n9\n30\n2241.00\n2246\n-5.00\n2345.00\n1\n-16.00\nB6\n486\nN346JB\nJFK\nROC\n47.00\n264\n22\n46\n\n\n336769\n2013\n9\n30\n2349.00\n2359\n-10.00\n325.00\n350\n-25.00\nB6\n745\nN516JB\nJFK\nPSE\n196.00\n1617\n23\n59\n\n\n\n\n184782 rows × 18 columns\n\n\n\n\nflights.query('arr_delay + dep_delay &lt; 0')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n3\n2013\n1\n1\n544.00\n545\n-1.00\n1004.00\n1022\n-18.00\nB6\n725\nN804JB\nJFK\nBQN\n183.00\n1576\n5\n45\n\n\n4\n2013\n1\n1\n554.00\n600\n-6.00\n812.00\n837\n-25.00\nDL\n461\nN668DN\nLGA\nATL\n116.00\n762\n6\n0\n\n\n7\n2013\n1\n1\n557.00\n600\n-3.00\n709.00\n723\n-14.00\nEV\n5708\nN829AS\nLGA\nIAD\n53.00\n229\n6\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336766\n2013\n9\n30\n2240.00\n2250\n-10.00\n2347.00\n7\n-20.00\nB6\n2002\nN281JB\nJFK\nBUF\n52.00\n301\n22\n50\n\n\n336767\n2013\n9\n30\n2241.00\n2246\n-5.00\n2345.00\n1\n-16.00\nB6\n486\nN346JB\nJFK\nROC\n47.00\n264\n22\n46\n\n\n336769\n2013\n9\n30\n2349.00\n2359\n-10.00\n325.00\n350\n-25.00\nB6\n745\nN516JB\nJFK\nPSE\n196.00\n1617\n23\n59\n\n\n\n\n188401 rows × 18 columns\n\n\n\n\nflights.query('not dep_delay.isna() and arr_delay.isna()')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n471\n2013\n1\n1\n1525.00\n1530\n-5.00\n1934.00\n1805\nNaN\nMQ\n4525\nN719MQ\nLGA\nXNA\nNaN\n1147\n15\n30\n\n\n477\n2013\n1\n1\n1528.00\n1459\n29.00\n2002.00\n1647\nNaN\nEV\n3806\nN17108\nEWR\nSTL\nNaN\n872\n14\n59\n\n\n615\n2013\n1\n1\n1740.00\n1745\n-5.00\n2158.00\n2020\nNaN\nMQ\n4413\nN739MQ\nLGA\nXNA\nNaN\n1147\n17\n45\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n334495\n2013\n9\n28\n1214.00\n1225\n-11.00\n1801.00\n1510\nNaN\nAA\n300\nN488AA\nEWR\nDFW\nNaN\n1372\n12\n25\n\n\n335534\n2013\n9\n29\n1734.00\n1711\n23.00\n2159.00\n2020\nNaN\nUA\n327\nN463UA\nEWR\nPDX\nNaN\n2434\n17\n11\n\n\n335805\n2013\n9\n30\n559.00\n600\n-1.00\nNaN\n715\nNaN\nWN\n464\nN411WN\nEWR\nMDW\nNaN\n711\n6\n0\n\n\n\n\n1175 rows × 18 columns\n\n\n\n\ndelay_time = 900\nflights.query('arr_delay &gt; @delay_time')\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n7072\n2013\n1\n9\n641.00\n900\n1301.00\n1242.00\n1530\n1272.00\nHA\n51\nN384HA\nJFK\nHNL\n640.00\n4983\n9\n0\n\n\n8239\n2013\n1\n10\n1121.00\n1635\n1126.00\n1239.00\n1810\n1109.00\nMQ\n3695\nN517MQ\nEWR\nORD\n111.00\n719\n16\n35\n\n\n151974\n2013\n3\n17\n2321.00\n810\n911.00\n135.00\n1020\n915.00\nDL\n2119\nN927DA\nLGA\nMSP\n167.00\n1020\n8\n10\n\n\n173992\n2013\n4\n10\n1100.00\n1900\n960.00\n1342.00\n2211\n931.00\nDL\n2391\nN959DL\nJFK\nTPA\n139.00\n1005\n19\n0\n\n\n235778\n2013\n6\n15\n1432.00\n1935\n1137.00\n1607.00\n2120\n1127.00\nMQ\n3535\nN504MQ\nJFK\nCMH\n74.00\n483\n19\n35\n\n\n270376\n2013\n7\n22\n845.00\n1600\n1005.00\n1044.00\n1815\n989.00\nMQ\n3075\nN665MQ\nJFK\nCVG\n96.00\n589\n16\n0\n\n\n327043\n2013\n9\n20\n1139.00\n1845\n1014.00\n1457.00\n2210\n1007.00\nAA\n177\nN338AA\nJFK\nSFO\n354.00\n2586\n18\n45\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n.query()의 결과는 view이므로 수정하려면 SettingWithCopyWarning; .copy() 후 사용 권장\nPython에서 유효하지 않은 변수명의 경우, 예를 들어, 빈칸이나 .이 있는 경우; income total, income.total\nBacktick으로 감싸줘야 함; `income total`, `income.total`, `class`\n\n\n\n\n\n\n\n\n\nquery() 조건의 참거짓에 상관없이 NA값은 모두 제외함\n\n\n\n\n\n# df가 다음과 같을 때,\n#      A     B\n# 0 1.00  2.00\n# 1  NaN  5.00\n# 2 3.00  3.00\n# 3 4.00   NaN\n\ndf.query('A &gt; 1')\n#      A     B\n# 2 3.00  3.00\n# 3 4.00   NaN\n\n# NA를 포함하고자 할 때,\ndf.query('A &gt; 1 | A.isna()') # .isna() : NA인지 여부\n#      A     B\n# 1  NaN  5.00\n# 2 3.00  3.00\n# 3 4.00   NaN\nNA(missing)에 대해서는 뒤에서 자세히\n\n\n\n\n\nsort_values()\n\n# \"year\", \"month\", \"day\", \"dep_time\" 순서대로 내림차순으로 정렬\nflights.sort_values(by=[\"year\", \"month\", \"day\", \"dep_time\"], ascending=False)   # default: ascending=True\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n111279\n2013\n12\n31\n2356.00\n2359\n-3.00\n436.00\n445\n-9.00\nB6\n745\nN665JB\nJFK\nPSE\n200.00\n1617\n23\n59\n\n\n111278\n2013\n12\n31\n2355.00\n2359\n-4.00\n430.00\n440\n-10.00\nB6\n1503\nN509JB\nJFK\nSJU\n195.00\n1598\n23\n59\n\n\n111277\n2013\n12\n31\n2332.00\n2245\n47.00\n58.00\n3\n55.00\nB6\n486\nN334JB\nJFK\nROC\n60.00\n264\n22\n45\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n839\n2013\n1\n1\nNaN\n1935\nNaN\nNaN\n2240\nNaN\nAA\n791\nN3EHAA\nLGA\nDFW\nNaN\n1389\n19\n35\n\n\n840\n2013\n1\n1\nNaN\n1500\nNaN\nNaN\n1825\nNaN\nAA\n1925\nN3EVAA\nLGA\nMIA\nNaN\n1096\n15\n0\n\n\n841\n2013\n1\n1\nNaN\n600\nNaN\nNaN\n901\nNaN\nB6\n125\nN618JB\nJFK\nFLL\nNaN\n1069\n6\n0\n\n\n\n\n336776 rows × 18 columns\n\n\n\n\n# pd.DataFrame.nlargest()를 이용할 수도 있음\nflights.nlargest(3, columns=[\"year\", \"month\", \"day\", \"dep_time\"], keep=\"all\")\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n111279\n2013\n12\n31\n2356.00\n2359\n-3.00\n436.00\n445\n-9.00\nB6\n745\nN665JB\nJFK\nPSE\n200.00\n1617\n23\n59\n\n\n111278\n2013\n12\n31\n2355.00\n2359\n-4.00\n430.00\n440\n-10.00\nB6\n1503\nN509JB\nJFK\nSJU\n195.00\n1598\n23\n59\n\n\n111277\n2013\n12\n31\n2332.00\n2245\n47.00\n58.00\n3\n55.00\nB6\n486\nN334JB\nJFK\nROC\n60.00\n264\n22\n45\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nmethod의 설명이 잘 나타나지 않을 시, 함수를 직접 써서 확인\n예를 들어,\npd.DataFrame.nlargest\npd.Series.nlargest\n\n\n\n# \"dep_time\"은 내림차순으로, \"arr_delay\"는 오름차순으로\nflights.sort_values(by=[\"dep_time\", \"arr_delay\"], ascending=[False, True])\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n150301\n2013\n3\n15\n2400.00\n2359\n1.00\n324.00\n338\n-14.00\nB6\n727\nN636JB\nJFK\nBQN\n186.00\n1576\n23\n59\n\n\n87893\n2013\n12\n5\n2400.00\n2359\n1.00\n427.00\n440\n-13.00\nB6\n1503\nN587JB\nJFK\nSJU\n182.00\n1598\n23\n59\n\n\n212941\n2013\n5\n21\n2400.00\n2359\n1.00\n339.00\n350\n-11.00\nB6\n739\nN527JB\nJFK\nPSE\n199.00\n1617\n23\n59\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336773\n2013\n9\n30\nNaN\n1210\nNaN\nNaN\n1330\nNaN\nMQ\n3461\nN535MQ\nLGA\nBNA\nNaN\n764\n12\n10\n\n\n336774\n2013\n9\n30\nNaN\n1159\nNaN\nNaN\n1344\nNaN\nMQ\n3572\nN511MQ\nLGA\nCLE\nNaN\n419\n11\n59\n\n\n336775\n2013\n9\n30\nNaN\n840\nNaN\nNaN\n1020\nNaN\nMQ\n3531\nN839MQ\nLGA\nRDU\nNaN\n431\n8\n40\n\n\n\n\n336776 rows × 18 columns\n\n\n\n query()와 sort_values()을 함께 이용하여 좀 더 복잡한 문제를 해결할 수 있음\n예를 들어, 다음과 같이 거의 제시간에 출발한(+- 10분 이내) 항공편들 중 가장 도착 지연이 큰 항공편을 찾을 수 있음\n\n# Method chaining\n(\n    flights\n    .query('dep_delay &lt;= 10 & dep_delay &gt;= -10')\n    .sort_values(\"arr_delay\", ascending=False)\n)\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n55985\n2013\n11\n1\n658.00\n700\n-2.00\n1329.00\n1015\n194.00\nVX\n399\nN629VA\nJFK\nLAX\n336.00\n2475\n7\n0\n\n\n181270\n2013\n4\n18\n558.00\n600\n-2.00\n1149.00\n850\n179.00\nAA\n707\nN3EXAA\nLGA\nDFW\n234.00\n1389\n6\n0\n\n\n256340\n2013\n7\n7\n1659.00\n1700\n-1.00\n2050.00\n1823\n147.00\nUS\n2183\nN948UW\nLGA\nDCA\n64.00\n214\n17\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n334354\n2013\n9\n28\n847.00\n839\n8.00\n1130.00\n959\nNaN\nEV\n4510\nN14542\nEWR\nMKE\nNaN\n725\n8\n39\n\n\n334412\n2013\n9\n28\n1010.00\n1020\n-10.00\n1344.00\n1222\nNaN\nEV\n4412\nN12175\nEWR\nDSM\nNaN\n1017\n10\n20\n\n\n335805\n2013\n9\n30\n559.00\n600\n-1.00\nNaN\n715\nNaN\nWN\n464\nN411WN\nEWR\nMDW\nNaN\n711\n6\n0\n\n\n\n\n239109 rows × 18 columns\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRow가 재정렬되는 operation을 한 후에는 index 순서가 바뀌는데, 이를 reset하려면,\n.sort_values(ignore_index=True)\nDataFrame updated: inplace=True\nNA는 sort 후 맨 뒤로\n맨 앞으로 오게하려면 na_position='first'\n\n\n\n\n\nunique()\nSeries method\n\nflights[\"origin\"].unique()  # return as a NumPy array, but depends on the dtypes\n\narray(['EWR', 'LGA', 'JFK'], dtype=object)\n\n\n\nflights[\"origin\"].nunique()  # return the number of unique values\n\n3\n\n\n\n# finds all unique origin and destination pairs.\nflights[[\"origin\", \"dest\"]].value_counts(sort=False)  # default: dropna=True\n\norigin  dest\nEWR     ALB      439\n        ANC        8\n        ATL     5022\n                ... \nLGA     TVC       77\n        TYS      308\n        XNA      745\nName: count, Length: 224, dtype: int64\n\n\n\nflights[[\"origin\", \"dest\"]].value_counts(sort=False).reset_index(name=\"n\")\n\n    origin dest     n\n0      EWR  ALB   439\n1      EWR  ANC     8\n2      EWR  ATL  5022\n..     ...  ...   ...\n221    LGA  TVC    77\n222    LGA  TYS   308\n223    LGA  XNA   745\n\n[224 rows x 3 columns]"
  },
  {
    "objectID": "contents/transform.html#columns",
    "href": "contents/transform.html#columns",
    "title": "Transforming I",
    "section": "Columns",
    "text": "Columns\n\nSelect\n기본적인 column selection은 이전 섹션 참고: subsetting\n\n# Select columns by name\nflights[[\"year\", \"month\", \"day\"]]\n\n        year  month  day\n0       2013      1    1\n1       2013      1    1\n2       2013      1    1\n...      ...    ...  ...\n336773  2013      9   30\n336774  2013      9   30\n336775  2013      9   30\n\n[336776 rows x 3 columns]\n\n\n\n# Select all columns between year and day (inclusive)\nflights.loc[:, \"year\":\"day\"]\n\n        year  month  day\n0       2013      1    1\n1       2013      1    1\n2       2013      1    1\n...      ...    ...  ...\n336773  2013      9   30\n336774  2013      9   30\n336775  2013      9   30\n\n[336776 rows x 3 columns]\n\n\n\n# Select all columns except those from year to day (inclusive)\n# .isin(): includes\nflights.loc[:, ~flights.columns.isin([\"year\", \"month\", \"day\"])]  # Boolean indexing\n\n\n\n\n\n\n\n\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n0\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336773\nNaN\n1210\nNaN\nNaN\n1330\nNaN\nMQ\n3461\nN535MQ\nLGA\nBNA\nNaN\n764\n12\n10\n\n\n336774\nNaN\n1159\nNaN\nNaN\n1344\nNaN\nMQ\n3572\nN511MQ\nLGA\nCLE\nNaN\n419\n11\n59\n\n\n336775\nNaN\n840\nNaN\nNaN\n1020\nNaN\nMQ\n3531\nN839MQ\nLGA\nRDU\nNaN\n431\n8\n40\n\n\n\n\n336776 rows × 15 columns\n\n\n\n Series/Index object의 method와 함께 특정 string을 기준으로 선택 (string method와는 구별)\n.str.contains(), .str.startswith(), .str.endswith() ; True/False\n\n# Select all columns that begin with “dep”.\nflights.loc[:, flights.columns.str.startswith(\"dep\")]  # Boolean indexing\n\n        dep_time  dep_delay\n0         517.00       2.00\n1         533.00       4.00\n2         542.00       2.00\n...          ...        ...\n336773       NaN        NaN\n336774       NaN        NaN\n336775       NaN        NaN\n\n[336776 rows x 2 columns]\n\n\n\n# Select all columns that are characters\nflights.select_dtypes(\"object\")  # dtype: object, number, ...\n\n       carrier tailnum origin dest\n0           UA  N14228    EWR  IAH\n1           UA  N24211    LGA  IAH\n2           AA  N619AA    JFK  MIA\n...        ...     ...    ...  ...\n336773      MQ  N535MQ    LGA  BNA\n336774      MQ  N511MQ    LGA  CLE\n336775      MQ  N839MQ    LGA  RDU\n\n[336776 rows x 4 columns]\n\n\nindex selection: reindex\n\n\nrename()\n\npd.DataFrame.rename\n\n\nflights.rename(\n    columns={\"dep_time\": \"dep_t\", \"arr_time\": \"arr_t\"},  \n    # 첫번째 인자 index=\n    # inplace=True: dataframe is updated\n)\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_t\nsched_dep_time\ndep_delay\narr_t\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\n\n\n\n\n0\n2013\n1\n1\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n2013\n1\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n2013\n1\n1\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n336773\n2013\n9\n30\nNaN\n1210\nNaN\nNaN\n1330\nNaN\nMQ\n3461\nN535MQ\nLGA\nBNA\nNaN\n764\n12\n10\n\n\n336774\n2013\n9\n30\nNaN\n1159\nNaN\nNaN\n1344\nNaN\nMQ\n3572\nN511MQ\nLGA\nCLE\nNaN\n419\n11\n59\n\n\n336775\n2013\n9\n30\nNaN\n840\nNaN\nNaN\n1020\nNaN\nMQ\n3531\nN839MQ\nLGA\nRDU\nNaN\n431\n8\n40\n\n\n\n\n336776 rows × 18 columns\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nindex를 rename할 수도 있음\nflights.rename(\n    index={0: \"a\", 1: \"b\"},\n).head(3)\n#    year  month  day  dep_time  ...\n# a  2013      1    1    517.00  ...\n# b  2013      1    1    533.00  ...\n# 2  2013      1    1    542.00  ...\n\n\n\n\n\n\n\n\nTip\n\n\n\nSeries의 경우\ns = flights.dep_delay.head(3)\n# 0   2.00\n# 1   4.00\n# 2   2.00\n# Name: dep_delay, dtype: float64\n\ns.rename(\"what\")\n# 0   2.00\n# 1   4.00\n# 2   2.00\n# Name: what, dtype: float64\n\n\n함수 str.capitalize, str.lower, str.upper과 함께.\n\nflights.rename(str.capitalize, axis=\"columns\").head(3)  # axis=1\n\n\n\n\n\n\n\n\nYear\nMonth\nDay\nDep_time\nSched_dep_time\nDep_delay\nArr_time\nSched_arr_time\nArr_delay\nCarrier\nFlight\nTailnum\nOrigin\nDest\nAir_time\nDistance\nHour\nMinute\n\n\n\n\n0\n2013\n1\n1\n517.00\n515\n2.00\n830.00\n819\n11.00\nUA\n1545\nN14228\nEWR\nIAH\n227.00\n1400\n5\n15\n\n\n1\n2013\n1\n1\n533.00\n529\n4.00\n850.00\n830\n20.00\nUA\n1714\nN24211\nLGA\nIAH\n227.00\n1416\n5\n29\n\n\n2\n2013\n1\n1\n542.00\n540\n2.00\n923.00\n850\n33.00\nAA\n1141\nN619AA\nJFK\nMIA\n160.00\n1089\n5\n40\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n일반적으로 임의의 함수가 적용됨.\nflights.rename(lambda x: x[:3], axis=\"columns\")\n\n#     yea  mon  day    dep  sch  dep    arr  sch   arr car   fli     tai  ori  ...\n# 0  2013    1    1 517.00  515 2.00 830.00  819 11.00  UA  1545  N14228  EWR   \n# 1  2013    1    1 533.00  529 4.00 850.00  830 20.00  UA  1714  N24211  LGA   \n# 2  2013    1    1 542.00  540 2.00 923.00  850 33.00  AA  1141  N619AA  JFK  \n# ...\n\n\n\n\nassign()\n\ncols = [\"year\", \"month\", \"day\", \"distance\", \"air_time\"] + \\\n        [col for col in flights.columns if col.endswith(\"delay\")]  # string method .endswith\nflights_sml = flights[cols].copy()\nflights_sml\n\n        year  month  day  distance  air_time  dep_delay  arr_delay\n0       2013      1    1      1400    227.00       2.00      11.00\n1       2013      1    1      1416    227.00       4.00      20.00\n2       2013      1    1      1089    160.00       2.00      33.00\n...      ...    ...  ...       ...       ...        ...        ...\n336773  2013      9   30       764       NaN        NaN        NaN\n336774  2013      9   30       419       NaN        NaN        NaN\n336775  2013      9   30       431       NaN        NaN        NaN\n\n[336776 rows x 7 columns]\n\n\n\n# 새로 만들어진 변수는 맨 뒤로\nflights_sml.assign(\n    gain=lambda x: x.dep_delay - x.arr_delay,   # x: DataFrame, flights_sml\n    speed=flights_sml[\"distance\"] / flights_sml[\"air_time\"] * 60    # 직접 DataFrame 참조할 수도 있음\n)\n\n        year  month  day  distance  air_time  dep_delay  arr_delay   gain  \\\n0       2013      1    1      1400    227.00       2.00      11.00  -9.00   \n1       2013      1    1      1416    227.00       4.00      20.00 -16.00   \n2       2013      1    1      1089    160.00       2.00      33.00 -31.00   \n...      ...    ...  ...       ...       ...        ...        ...    ...   \n336773  2013      9   30       764       NaN        NaN        NaN    NaN   \n336774  2013      9   30       419       NaN        NaN        NaN    NaN   \n336775  2013      9   30       431       NaN        NaN        NaN    NaN   \n\n        speed  \n0      370.04  \n1      374.27  \n2      408.38  \n...       ...  \n336773    NaN  \n336774    NaN  \n336775    NaN  \n\n[336776 rows x 9 columns]\n\n\n\n# 앞에서 만든 변수나 함수를 이용할 수 있음\nflights_sml.assign(\n    gain=lambda x: x.dep_delay - x.arr_delay,\n    hours=lambda x: x.air_time / 60,\n    gain_per_hour=lambda x: x.gain / x.hours,\n    rounded=lambda x: np.round(x.gain_per_hour, 1)  # use a numpy function\n)\n\n        year  month  day  distance  air_time  dep_delay  arr_delay   gain  \\\n0       2013      1    1      1400    227.00       2.00      11.00  -9.00   \n1       2013      1    1      1416    227.00       4.00      20.00 -16.00   \n2       2013      1    1      1089    160.00       2.00      33.00 -31.00   \n...      ...    ...  ...       ...       ...        ...        ...    ...   \n336773  2013      9   30       764       NaN        NaN        NaN    NaN   \n336774  2013      9   30       419       NaN        NaN        NaN    NaN   \n336775  2013      9   30       431       NaN        NaN        NaN    NaN   \n\n        hours  gain_per_hour  rounded  \n0        3.78          -2.38    -2.40  \n1        3.78          -4.23    -4.20  \n2        2.67         -11.62   -11.60  \n...       ...            ...      ...  \n336773    NaN            NaN      NaN  \n336774    NaN            NaN      NaN  \n336775    NaN            NaN      NaN  \n\n[336776 rows x 11 columns]\n\n\n\n# Find the fastest flights\n(\n    flights_sml\n    .assign(speed=lambda x: x.distance / x.air_time)\n    .sort_values(by=\"speed\", ascending=False)\n    .head(5)\n)\n\n        year  month  day  distance  air_time  dep_delay  arr_delay  speed\n216447  2013      5   25       762     65.00       9.00     -14.00  11.72\n251999  2013      7    2      1008     93.00      45.00      26.00  10.84\n205388  2013      5   13       594     55.00      15.00      -1.00  10.80\n157516  2013      3   23       748     70.00       4.00       2.00  10.69\n10223   2013      1   12      1035    105.00      -1.00     -28.00   9.86"
  },
  {
    "objectID": "contents/transform.html#groups",
    "href": "contents/transform.html#groups",
    "title": "Transforming I",
    "section": "Groups",
    "text": "Groups\n\ngroupby()\n\ngroupby()는 데이터를 의미있는 그룹으로 나누어 분석할 수 있도록 해줌\n.count(), .sum(), .mean(), .min(), .max()과 같은 통계치를 구하는 methods와 함께 효과적으로, 자주 활용됨\n\n\nSource: Ch.10 in Python for Data Analysis (3e) by Wes McKinney\n아래 표는 groupby()와 함께 자주 쓰이는 효율적인 methods\n\nSource: Ch.10 in Python for Data Analysis (3e) by Wes McKinney\n\nflights.groupby(\"month\")  # “GroupBy” object\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x28001c810&gt;\n\n\n\nflights_sml.groupby(\"month\").mean()\n\n         year   day  distance  air_time  dep_delay  arr_delay\nmonth                                                        \n1     2013.00 15.99   1006.84    154.19      10.04       6.13\n2     2013.00 14.74   1000.98    151.35      10.82       5.61\n3     2013.00 16.00   1011.99    149.08      13.23       5.81\n...       ...   ...       ...       ...        ...        ...\n10    2013.00 15.98   1038.88    148.89       6.24      -0.17\n11    2013.00 15.29   1050.31    155.47       5.44       0.46\n12    2013.00 15.72   1064.66    162.59      16.58      14.87\n\n[12 rows x 6 columns]\n\n\n\n# 보통은 다음과 같이 특정 columns을 선택\nflights.groupby(\"month\")[\"dep_delay\"]  # [[\"dep_delay\"]] 처럼 list로 입력하면 DataFrameGroupBy object\n\n&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x13d0126d0&gt;\n\n\n\nflights.groupby(\"month\")[\"dep_delay\"].mean()  # Series GroupBy object에 적용된 결과는 Series\n\nmonth\n1    10.04\n2    10.82\n3    13.23\n      ... \n10    6.24\n11    5.44\n12   16.58\nName: dep_delay, Length: 12, dtype: float64\n\n\n\nflights.groupby(\"month\")[[\"dep_delay\", \"arr_delay\"]].mean().head(3)\n\n       dep_delay  arr_delay\nmonth                      \n1          10.04       6.13\n2          10.82       5.61\n3          13.23       5.81\n\n\n\nflights.groupby([\"month\", \"day\"])[\"arr_delay\"].nsmallest(1)\n\nmonth  day        \n1      1    696      -48.00\n       2    919      -59.00\n       3    2035     -65.00\n                      ...  \n12     29   108914   -60.00\n       30   110330   -45.00\n       31   111113   -44.00\nName: arr_delay, Length: 365, dtype: float64\n\n\n\n\n\n\n\n\nTip\n\n\n\nMulti-index의 level을 drop하려면 droplevel()\nflights.groupby([\"month\", \"day\"])[\"arr_delay\"].nsmallest(1).droplevel(2)\n# month  day\n# 1      1     -48.00\n#        2     -59.00\n#        3     -65.00\n#               ...  \n# 12     29    -60.00\n#        30    -45.00\n#        31    -44.00\n# Name: arr_delay, Length: 365, dtype: float64\n\n\n\nflights.groupby([\"origin\", \"dest\"])[\"arr_delay\"].count()\n\norigin  dest\nEWR     ALB      418\n        ANC        8\n        ATL     4876\n                ... \nLGA     TVC       73\n        TYS      265\n        XNA      709\nName: arr_delay, Length: 224, dtype: int64\n\n\n\n\n\n\n\n\nTip\n\n\n\nas_index=False: grouping 변수들을 index가 아닌 columns으로\nflights.groupby([\"month\", \"day\"], as_index=False)[\"arr_delay\"].mean().head(3)\n#    month  day  arr_delay\n# 0      1    1      12.65\n# 1      1    2      12.69\n# 2      1    3       5.73\n물론, 결과물에 .reset_index() method를 사용해도 됨\n\n\n\n\n\n\n\n\nNote\n\n\n\n원칙적으로 grouping은 같은 DataFrame의 변수일 필요없이 match만 되면 됨\nSource: Wes McKinney’s\n# df\n#    key1  key2  data1  data2\n# 0     a     1   0.36  -0.42\n# 1     a     2  -1.51   0.04\n# 2  None     1   0.75  -0.28\n# 3     b     2   0.57   0.25\n# 4     b     1   1.30  -0.77\n# 5     a  &lt;NA&gt;  -0.53  -0.73\n# 6  None     1   2.04  -0.37\n\nstates = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\nyears = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n\ndf[\"data1\"].groupby([states, years]).mean()\n# CA  2005   -1.02\n#     2006    0.75\n# OH  2005    0.46\n#     2006    1.67\n# Name: data1, dtype: float64\n\n\n\nflights.groupby(\"dest\").size()  # .size(): group의 사이즈/열의 갯수\n\ndest\nABQ     254\nACK     265\nALB     439\n       ... \nTVC     101\nTYS     631\nXNA    1036\nLength: 105, dtype: int64\n\n\n\nflights.groupby(\"tailnum\", dropna=False).size()  # groupby는 기본적으로 NA 무시\n\ntailnum\nD942DN       4\nN0EGMQ     371\nN10156     153\n          ... \nN999DN      61\nN9EAMQ     248\nNaN       2512\nLength: 4044, dtype: int64\n\n\n\n\n\n\n\n\nNote\n\n\n\n.size()는 .value_counts()와 유사하게 사용될 수 있음\nflights[\"tailnum\"].value_counts(dropna=False)\n# NaN       2512\n# N725MQ     575\n# N722MQ     513\n#           ... \n# N318AS       1\n# N651UA       1\n# N557AS       1\n# Name: tailnum, Length: 4044, dtype: int64\n\n\n\n\n\n\n\n\nNote\n\n\n\nIndex에 grouping하는 방식에 대해서는 Wes McKineey’s Chapter 10 참고\n\nGrouping with Dictionaries and Series\nGrouping with Functions\nGrouping by Index Levels\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTime series 데이터의 경우 다양한 grouping 방식이 존재\nStephanie Molin의 ch.4 Working with time series data 참고\n예를 들어, facebook stock에 대한 자료에서 2018년 4분기에 해당하는 날을 week단위로 그룹핑하여 volume을 다음과 같이 계산할 수 있음\nfb.loc['2018-Q4'].groupby(pd.Grouper(freq='W')).volume.sum()\n\n\n\n\n\n\n\n\nTip\n\n\n\ngroupby filtering\nflights.groupby([\"year\", \"month\", \"day\"]).filter(lambda x: x[\"arr_delay\"].mean() &lt; 0)\n좀 더 복잡한 groupby filtering은 이후 apply를 이용\n\n\n\n\n\nagg()\nAggregations: data transformation that produces scalar values from arrays\n앞서 GroupBy object에 직접 stats function을 적용하였는데, agg()를 이용하여 더 확장, 일반화할 수 있음\n\n# 모두 동일\nflights_sml.groupby(\"month\").mean()\nflights_sml.groupby(\"month\").agg(\"mean\")  # function names\nflights_sml.groupby(\"month\").agg(np.mean)  # numpy functions\nflights_sml.groupby(\"month\").agg(lambda x: x.sum() / x.count())  # general functions; not optimized!\n\n\n\n         year   day  distance  air_time  dep_delay  arr_delay\nmonth                                                        \n1     2013.00 15.99   1006.84    154.19      10.04       6.13\n2     2013.00 14.74   1000.98    151.35      10.82       5.61\n3     2013.00 16.00   1011.99    149.08      13.23       5.81\n...       ...   ...       ...       ...        ...        ...\n10    2013.00 15.98   1038.88    148.89       6.24      -0.17\n11    2013.00 15.29   1050.31    155.47       5.44       0.46\n12    2013.00 15.72   1064.66    162.59      16.58      14.87\n\n[12 rows x 6 columns]\n\n\n\nflights_sml.groupby(\"month\")[\"arr_delay\"].agg(\"mean\")  # Series에 string으로 함수 적용\n\nmonth\n1     6.13\n2     5.61\n3     5.81\n      ... \n10   -0.17\n11    0.46\n12   14.87\nName: arr_delay, Length: 12, dtype: float64\n\n\n\n\n\n\n\n\nTip\n\n\n\n차이 참고\nflights_sml.groupby(\"month\")[\"arr_delay\"].agg([\"mean\"])  # list로 함수를 입력하는 경우\nflights_sml.groupby(\"month\")[[\"arr_delay\"]].agg(\"mean\")  # DataFrame에 적용될 때\n#        mean                    arr_delay\n# month                 # month\n# 1      6.13           # 1           6.13\n# 2      5.61           # 2           5.61\n# 3      5.81           # 3           5.81\n# ...                   # ...\n\n\n\nflights.groupby(\"month\")[\"dep_delay\"].agg([\"mean\", \"count\"])\n\n       mean  count\nmonth             \n1     10.04  26483\n2     10.82  23690\n3     13.23  27973\n...     ...    ...\n10     6.24  28653\n11     5.44  27035\n12    16.58  27110\n\n[12 rows x 2 columns]\n\n\n\nflights_sml.groupby(\"month\")[[\"arr_delay\"]].agg([\"mean\", \"median\"])\n\n      arr_delay       \n           mean median\nmonth                 \n1          6.13  -3.00\n2          5.61  -3.00\n3          5.81  -6.00\n...         ...    ...\n10        -0.17  -7.00\n11         0.46  -6.00\n12        14.87   2.00\n\n[12 rows x 2 columns]\n\n\n\nflights_sml.groupby(\"month\")[[\"arr_delay\", \"dep_delay\"]].agg([\"mean\", \"count\"])\n\n      arr_delay        dep_delay       \n           mean  count      mean  count\nmonth                                  \n1          6.13  26398     10.04  26483\n2          5.61  23611     10.82  23690\n3          5.81  27902     13.23  27973\n...         ...    ...       ...    ...\n10        -0.17  28618      6.24  28653\n11         0.46  26971      5.44  27035\n12        14.87  27020     16.58  27110\n\n[12 rows x 4 columns]\n\n\n컬럼 별로 다른 함수를 적용하고자 할 때 (컬럼 이름을 지정): tuple\n\nflights_agg = (\n    flights.groupby(\"month\")\n    .agg(\n        air_min=(\"air_time\", \"min\"),  # 컬럼 이름 지정 = (컬럼, 함수)\n        air_max=(\"air_time\", \"max\"),\n        dep_mean=(\"dep_delay\", \"mean\"),\n        arr_median=(\"arr_delay\", \"median\"),\n    )\n    .reset_index()\n)\n\nflights_agg\n\n    month  air_min  air_max  dep_mean  arr_median\n0       1    20.00   667.00     10.04       -3.00\n1       2    21.00   691.00     10.82       -3.00\n2       3    21.00   695.00     13.23       -6.00\n..    ...      ...      ...       ...         ...\n9      10    23.00   642.00      6.24       -7.00\n10     11    24.00   676.00      5.44       -6.00\n11     12    21.00   661.00     16.58        2.00\n\n[12 rows x 5 columns]\n\n\n\n\n\n\n\n\nNote\n\n\n\n컬럼별 다른 함수를 적용하는 다른 방식: dictionary\nflights_agg = flights.groupby(\"month\").agg({\n    \"air_time\": [\"min\", \"max\"],\n    \"dep_delay\": \"mean\",\n    \"arr_delay\": \"median\"\n})\n#       air_time        dep_delay arr_delay\n#            min    max      mean    median\n# month                                    \n# 1        20.00 667.00     10.04     -3.00\n# 2        21.00 691.00     10.82     -3.00\n# 3        21.00 695.00     13.23     -6.00\n# ...\nMultiIndex를 collapse하는 팁\nflights_agg.columns\n# MultiIndex([( 'air_time',    'min'),\n#             ( 'air_time',    'max'),\n#             ('dep_delay',   'mean'),\n#             ('arr_delay', 'median')],\n#            )\n\nflights_agg.columns = ['_'.join(col_agg) for col_agg in flights_agg.columns]\nflights_agg.head(3)\n#        air_time_min  air_time_max  dep_delay_mean  arr_delay_median\n# month                                                              \n# 1             20.00        667.00           10.04             -3.00\n# 2             21.00        691.00           10.82             -3.00\n# 3             21.00        695.00           13.23             -6.00\n\n\n\n\n\n\n\n\nNote\n\n\n\nagg()에는 custom function을 pass할 수 있음\n단, the optimized functions (Table 10-1)에 비해 일반적으로 훨씬 느림\n\n\n\ndef peak_to_peak(arr):\n    return arr.max() - arr.min()\n\n\ngrouped = flights_sml.groupby([\"month\", \"day\"])\ngrouped_dist = flights_sml.groupby([\"month\", \"day\"])[\"distance\"]\n\ngrouped_dist.agg([\"std\", peak_to_peak])  # a list of functions\n\n             std  peak_to_peak\nmonth day                     \n1     1   727.73          4889\n      2   721.72          4889\n      3   714.95          4903\n...          ...           ...\n12    29  728.78          4887\n      30  723.88          4887\n      31  731.36          4887\n\n[365 rows x 2 columns]\n\n\n\n# Naming a function as a tuple\ngrouped_dist.agg([(\"sd\", \"std\"), (\"range\", peak_to_peak)])\n\n              sd  range\nmonth day              \n1     1   727.73   4889\n      2   721.72   4889\n      3   714.95   4903\n...          ...    ...\n12    29  728.78   4887\n      30  723.88   4887\n      31  731.36   4887\n\n[365 rows x 2 columns]\n\n\n\n\n\n\n\n\nTip\n\n\n\n.describe()는 aggregation은 아니나 grouped objects에 적용가능\nflights_sml.groupby(\"month\")[[\"dep_delay\", \"arr_delay\"]].describe()\n\n#       dep_delay                                              arr_delay        \\\n#           count  mean   std    min   25%   50%   75%     max     count  mean   \n# month                                                                          \n# 1      26483.00 10.04 36.39 -30.00 -5.00 -2.00  8.00 1301.00  26398.00  6.13   \n# 2      23690.00 10.82 36.27 -33.00 -5.00 -2.00  9.00  853.00  23611.00  5.61   \n# 3      27973.00 13.23 40.13 -25.00 -5.00 -1.00 12.00  911.00  27902.00  5.81   \n# ...         ...   ...   ...    ...   ...   ...   ...     ...       ...   ...    \n                                               \n#         std    min    25%   50%   75%     max  \n# month                                          \n# 1     40.42 -70.00 -15.00 -3.00 13.00 1272.00  \n# 2     39.53 -70.00 -15.00 -3.00 13.00  834.00  \n# 3     44.12 -68.00 -18.00 -6.00 13.00  915.00  \n# ...     ...    ...    ...   ...   ...     ...  \n\n# [12 rows x 16 columns]\n\n\n\n\ntransform()\n앞서 group별로 통계치가 summary되어 원래 reduced 데이터프레임으로 변형됐다면,\ntransform()은 group별로 얻은 통계치가 원래 데이터의 형태를 그대로 보존하면서 출력\n만약, 전달되는 함수가 Series를 반환하려면, 동일한 사이즈로 반환되어야 함.\n\nflights_sml.groupby([\"month\"])[\"arr_delay\"].mean()\n\nmonth\n1     6.13\n2     5.61\n3     5.81\n      ... \n10   -0.17\n11    0.46\n12   14.87\nName: arr_delay, Length: 12, dtype: float64\n\n\n\ngrouped_delay = flights_sml.groupby([\"month\"])[\"arr_delay\"].transform(\"mean\")\ngrouped_delay\n\n0         6.13\n1         6.13\n2         6.13\n          ... \n336773   -4.02\n336774   -4.02\n336775   -4.02\nName: arr_delay, Length: 336776, dtype: float64\n\n\n\nflights_sml[\"monthly_delay\"] = grouped_delay\nflights_sml\n\n        year  month  day  distance  air_time  dep_delay  arr_delay  \\\n0       2013      1    1      1400    227.00       2.00      11.00   \n1       2013      1    1      1416    227.00       4.00      20.00   \n2       2013      1    1      1089    160.00       2.00      33.00   \n...      ...    ...  ...       ...       ...        ...        ...   \n336773  2013      9   30       764       NaN        NaN        NaN   \n336774  2013      9   30       419       NaN        NaN        NaN   \n336775  2013      9   30       431       NaN        NaN        NaN   \n\n        monthly_delay  \n0                6.13  \n1                6.13  \n2                6.13  \n...               ...  \n336773          -4.02  \n336774          -4.02  \n336775          -4.02  \n\n[336776 rows x 8 columns]\n\n\nQ: 1년에 10000편 이상 운항편이 있는 도착지로 가는 항공편들만 추리면,\n\ndest_size =  flights.groupby(\"dest\").transform(\"size\")\ndest_size\n\n# 또는 flights.groupby(\"dest\")[\"dest\"].transform(\"count\")\n\n0          7198\n1          7198\n2         11728\n          ...  \n336773     6333\n336774     4573\n336775     8163\nLength: 336776, dtype: int64\n\n\n\n# 1년에 10000편 이상 운항편이 있는 도착지에 대한 항공편\nflights[dest_size &gt; 10000]\n\n        year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n2       2013      1    1    542.00             540       2.00    923.00   \n4       2013      1    1    554.00             600      -6.00    812.00   \n5       2013      1    1    554.00             558      -4.00    740.00   \n...      ...    ...  ...       ...             ...        ...       ...   \n336762  2013      9   30   2233.00            2113      80.00    112.00   \n336763  2013      9   30   2235.00            2001     154.00     59.00   \n336768  2013      9   30   2307.00            2255      12.00   2359.00   \n\n        sched_arr_time  arr_delay carrier  flight tailnum origin dest  \\\n2                  850      33.00      AA    1141  N619AA    JFK  MIA   \n4                  837     -25.00      DL     461  N668DN    LGA  ATL   \n5                  728      12.00      UA    1696  N39463    EWR  ORD   \n...                ...        ...     ...     ...     ...    ...  ...   \n336762              30      42.00      UA     471  N578UA    EWR  SFO   \n336763            2249     130.00      B6    1083  N804JB    JFK  MCO   \n336768            2358       1.00      B6     718  N565JB    JFK  BOS   \n\n        air_time  distance  hour  minute  \n2         160.00      1089     5      40  \n4         116.00       762     6       0  \n5         150.00       719     5      58  \n...          ...       ...   ...     ...  \n336762    318.00      2565    21      13  \n336763    123.00       944    20       1  \n336768     33.00       187    22      55  \n\n[131440 rows x 18 columns]\n\n\nQ: 하루 중 출발 지연이 가장 늦은 두 항공편들을 매일 각각 구하면,\n\ndef get_ranks(group):\n    return group.rank(ascending=False, method=\"min\") # method: 동일 등수에 대한 처리방식\n\ndelay_rank = flights.groupby([\"month\", \"day\"])[\"dep_delay\"].transform(get_ranks)\n# 또는 .transform(\"rank\", ascending=False, method=\"min\")\n\ndelay_rank\n\n0        302.00\n1        269.00\n2        302.00\n          ...  \n336773      NaN\n336774      NaN\n336775      NaN\nName: dep_delay, Length: 336776, dtype: float64\n\n\n\nflights[delay_rank &lt; 3].head(6)\n\n      year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n151   2013      1    1    848.00            1835     853.00   1001.00   \n834   2013      1    1   2343.00            1724     379.00    314.00   \n1440  2013      1    2   1607.00            1030     337.00   2003.00   \n1749  2013      1    2   2131.00            1512     379.00   2340.00   \n2598  2013      1    3   2008.00            1540     268.00   2339.00   \n2637  2013      1    3   2056.00            1605     291.00   2239.00   \n\n      sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n151             1950     851.00      MQ    3944  N942MQ    JFK  BWI     41.00   \n834             1938     456.00      EV    4321  N21197    EWR  MCI    222.00   \n1440            1355     368.00      AA     179  N324AA    JFK  SFO    346.00   \n1749            1741     359.00      UA     488  N593UA    LGA  DEN    228.00   \n2598            1909     270.00      DL    2027  N338NW    JFK  FLL    158.00   \n2637            1754     285.00      9E    3459  N928XJ    JFK  BNA    125.00   \n\n      distance  hour  minute  \n151        184    18      35  \n834       1092    17      24  \n1440      2586    10      30  \n1749      1620    15      12  \n2598      1069    15      40  \n2637       765    16       5  \n\n\nQ: Normalize air time by destination\n\ndest_air = flights.groupby(\"dest\")[\"air_time\"]\n\n\n# Z = (x - mean) / std\n(flights['air_time'] - dest_air.transform('mean')) / dest_air.transform('std')\n\n0        1.73\n1        1.73\n2        0.61\n         ... \n336773    NaN\n336774    NaN\n336775    NaN\nName: air_time, Length: 336776, dtype: float64\n\n\n\ndef normalize(x):\n    return (x - x.mean()) / x.std()\n\n\ndest_air.transform(normalize)\n\n0        1.73\n1        1.73\n2        0.61\n         ... \n336773    NaN\n336774    NaN\n336775    NaN\nName: air_time, Length: 336776, dtype: float64\n\n\n\n\napply()\nApply: General split-apply-combine in McKineey’s Chapter 10.3 참고\n\nThe most general-purpose GroupBy method is apply, which is the subject of this section. apply splits the object being manipulated into pieces, invokes the passed function on each piece, and then attempts to concatenate the pieces.\n\n\ntips = sns.load_dataset(\"tips\")\ntips = tips.assign(tip_pct = lambda x: x.tip / x.total_bill)\ntips.head(3)\n\n   total_bill  tip     sex smoker  day    time  size  tip_pct\n0       16.99 1.01  Female     No  Sun  Dinner     2     0.06\n1       10.34 1.66    Male     No  Sun  Dinner     3     0.16\n2       21.01 3.50    Male     No  Sun  Dinner     3     0.17\n\n\n\ndef top(df, n=5, column=\"tip_pct\"):\n    return df.sort_values(column, ascending=False)[:n]\n\n\ntop(tips, n=4)\n\n     total_bill  tip     sex smoker  day    time  size  tip_pct\n172        7.25 5.15    Male    Yes  Sun  Dinner     2     0.71\n178        9.60 4.00  Female    Yes  Sun  Dinner     2     0.42\n67         3.07 1.00  Female    Yes  Sat  Dinner     1     0.33\n232       11.61 3.39    Male     No  Sat  Dinner     2     0.29\n\n\n\ntips.groupby(\"time\").apply(top)\n\n            total_bill  tip     sex smoker   day    time  size  tip_pct\ntime                                                                   \nLunch  149        7.51 2.00    Male     No  Thur   Lunch     2     0.27\n       221       13.42 3.48  Female    Yes   Fri   Lunch     2     0.26\n       194       16.58 4.00    Male    Yes  Thur   Lunch     2     0.24\n...                ...  ...     ...    ...   ...     ...   ...      ...\nDinner 67         3.07 1.00  Female    Yes   Sat  Dinner     1     0.33\n       232       11.61 3.39    Male     No   Sat  Dinner     2     0.29\n       183       23.17 6.50    Male    Yes   Sun  Dinner     4     0.28\n\n[10 rows x 8 columns]\n\n\n\ntips.groupby([\"time\", \"day\"]).apply(top, n=1, column=\"total_bill\")\n\n                 total_bill   tip     sex smoker   day    time  size  tip_pct\ntime   day                                                                   \nLunch  Thur 197       43.11  5.00  Female    Yes  Thur   Lunch     4     0.12\n       Fri  225       16.27  2.50  Female    Yes   Fri   Lunch     2     0.15\nDinner Thur 243       18.78  3.00  Female     No  Thur  Dinner     2     0.16\n       Fri  95        40.17  4.73    Male    Yes   Fri  Dinner     4     0.12\n       Sat  170       50.81 10.00    Male    Yes   Sat  Dinner     3     0.20\n       Sun  156       48.17  5.00    Male     No   Sun  Dinner     6     0.10\n\n\n\n\n\n\n\n\nNote\n\n\n\n위에서 agg()에 custom function을 pass할 수 있지만, 일반적으로 훨씬 느리다고 했는데,\n이는 numeric array에 apply() method를 사용할 때에도 해당됨.\n가능하다면, apply()를 피하는 것이 실행 속도를 크게 높일 수 있음. (단, “string”에 적용될 때는 차이 없음)\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhat occurs inside the function passed is up to you;\nit must either return a pandas object or a scalar value.\n\n\n\ntips.groupby(\"sex\")[\"tip_pct\"].describe()\n\n        count  mean  std  min  25%  50%  75%  max\nsex                                              \nMale   157.00  0.16 0.06 0.04 0.12 0.15 0.19 0.71\nFemale  87.00  0.17 0.05 0.06 0.14 0.16 0.19 0.42\n\n\nInside GroupBy, when you invoke a method like describe, it is actually just a shortcut for:\ndef f(group):\n    return group.describe()\n\n\n\n\n\n\nTip\n\n\n\nSuppressing the Group Keys\ntips.groupby(\"time\", group_keys=False).apply(top)\n#      total_bill  tip     sex smoker   day    time  size  tip_pct\n# 149        7.51 2.00    Male     No  Thur   Lunch     2     0.27\n# 221       13.42 3.48  Female    Yes   Fri   Lunch     2     0.26\n# 194       16.58 4.00    Male    Yes  Thur   Lunch     2     0.24\n# 88        24.71 5.85    Male     No  Thur   Lunch     2     0.24\n# 222        8.58 1.92    Male    Yes   Fri   Lunch     1     0.22\n# 172        7.25 5.15    Male    Yes   Sun  Dinner     2     0.71\n# 178        9.60 4.00  Female    Yes   Sun  Dinner     2     0.42\n# 67         3.07 1.00  Female    Yes   Sat  Dinner     1     0.33\n# 232       11.61 3.39    Male     No   Sat  Dinner     2     0.29\n# 183       23.17 6.50    Male    Yes   Sun  Dinner     4     0.28\n\n\n비교\n\napplymap: element-wise, DataFrame method\nmap: element-wise, Series method\napply: column/row-wise, DataFrame method, 또는 element-wise, Series method\n\n\nSource, 비교 참고\n\ndef my_format(x):\n    return f\"{x:.1f}\"\n\n\ntips_num = tips.select_dtypes(\"number\")\n\n\n# element-wise, DataFrame method\ntips_num.applymap(my_format)\n\n    total_bill  tip size tip_pct\n0         17.0  1.0  2.0     0.1\n1         10.3  1.7  3.0     0.2\n2         21.0  3.5  3.0     0.2\n..         ...  ...  ...     ...\n241       22.7  2.0  2.0     0.1\n242       17.8  1.8  2.0     0.1\n243       18.8  3.0  2.0     0.2\n\n[244 rows x 4 columns]\n\n\n\n# element-wise, Series method\ntips[\"tip\"].map(my_format)\n\n0      1.0\n1      1.7\n2      3.5\n      ... \n241    2.0\n242    1.8\n243    3.0\nName: tip, Length: 244, dtype: object\n\n\n\ndef peak_to_peak(arr):\n    return arr.max() - arr.min()\n\n\n# column-wise operation\ntips_num.apply(peak_to_peak)\n\ntotal_bill   47.74\ntip           9.00\nsize          5.00\ntip_pct       0.67\ndtype: float64\n\n\n\n# row-wise operation\ntips_num.apply(peak_to_peak, axis=\"columns\")\n\n0     16.93\n1     10.18\n2     20.84\n       ... \n241   22.58\n242   17.72\n243   18.62\nLength: 244, dtype: float64\n\n\n\ndef f2(x):\n    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n\n\n# apply에 패스되는 함수는 scalar 값이 아닌 Series를 반환해도 됨\ntips_num.apply(f2)\n\n     total_bill   tip  size  tip_pct\nmin        3.07  1.00     1     0.04\nmax       50.81 10.00     6     0.71\n\n\n\n# Series Groupby object의 경우\ntips.groupby(\"time\")[\"tip\"].apply(f2)\n\ntime       \nLunch   min    1.25\n        max    6.70\nDinner  min    1.00\n        max   10.00\nName: tip, dtype: float64\n\n\n\n# DataFrame GroupBy object의 경우\ndef f3(g):\n    x = g[\"tip\"]\n    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n\ntips.groupby(\"time\").apply(f3)\n\n        min   max\ntime             \nLunch  1.25  6.70\nDinner 1.00 10.00"
  },
  {
    "objectID": "contents/setup.html",
    "href": "contents/setup.html",
    "title": "환경설정",
    "section": "",
    "text": "Conda Cheatsheet: 기본적인 conda 명령어 요약\n\n\nAnaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 2. Command Line Tool 참고\n\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n#(base)&gt; conda info # 콘다 정보 \n#(base)&gt; conda update conda # 콘다 업데이트\n\n\n\n\nconda/managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n\n#(base)&gt; conda config --add channels conda-forge\n#(base)&gt; conda config --set channel_priority strict  # 채널 순으로 검색, 버전 순이 아니고\n\n\n# 개별적으로 채널을 선택해서 install하려면 (특정 환경에 설치하려면 아래 conda environment 참조)\n#(base)&gt; conda install scipy --channel conda-forge\n\n# pakcage가 있는 채널들\n#(base)&gt; conda search scipy\n\nconda base에 있는 Python을 update하려면, 가령 3.10으로 업데이트하려면\n\n#(base)&gt; conda install python=3.10  # python update\n\n\n\n\nconda/user guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 수업에서는 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\n\n#&gt; conda create --name myenv\n\n# 특정 버전의 파이썬 설치시\n#&gt; conda create --name myenv python=3.9\n\n환경 확인\n\n#&gt; conda env list\n\n#&gt; conda environments:\n#&gt;  base         */.../miniconda3\n#&gt;                /.../miniconda3/envs/myenv\n\n환경 제거\n\n#&gt; conda env remove --name myenv\n\n환경 activate/deactivate\n\n#&gt; conda activate myenv\n#&gt; conda deactivate  # activated 환경 내에서\n\n특정 환경 안의 파이썬 버전 확인\n\n#(myenv)&gt; python --version\n\n\n\n\n\n\n\nJupyter notebook을 쓰는 경우\n\n\n\n새로 만든 가상환경을 등록해줘야 함.\n#(myenv)&gt; ipython kernel install --user --name=myenv\n가상환경을 삭제해도 등록시킨 kernel 이름은 삭제되지 않으니 직접 삭제.\n등록된 커널 리스트를 확인\n#(myenv)&gt; jupyter kernelspec list\n커널 삭제\n#(myenv)&gt; jupyter kernelspec remove myenv\n\n\n\n\n\n\n# 특정 환경을 activate한 후\n#(myenv)&gt; conda install &lt;package name1&gt; &lt;package name2&gt; ...\n#(myenv)&gt; conda install --channel conda-forge &lt;package name&gt; # 특정 conda-forge 채널을 통한 설치\n\n# 제거\n#(myenv)&gt; conda remove &lt;package name1&gt; &lt;package name2&gt; ...\n\n# 업데이트\n#(myenv)&gt; conda update &lt;package name1&gt; &lt;package name2&gt; ...\n#(myenv)&gt; conda update --all # all packages\n\n# 패키지 리스트\n#(myenv)&gt; conda list\n\n\n# 환경 밖에서 특정 환경 안에 설치하려면 환경이름 추가\n#(base)&gt; conda install --name myenv &lt;package name1&gt;\n\n\n# pip을  이용한  패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n#(myenv)&gt; pip install &lt;package name1&gt; &lt;package name2&gt; ...\n\n\n# 환경 안에 다른 버전의 Python 설치하려면, 가령 python 3.9라면\n#(myenv)&gt; conda install python=3.9\n\n수업에 필요한 기본 패키지 설치\n\n# 수업에 필요한 기본 패키지 설치\n#(myenv)&gt; conda install jupyter numpy pandas matplotlib seaborn"
  },
  {
    "objectID": "contents/setup.html#miniconda-설치",
    "href": "contents/setup.html#miniconda-설치",
    "title": "환경설정",
    "section": "",
    "text": "Anaconda보다는 기본 패키지들이 미리 설치되지 않는 miniconda를 추천: miniconda install page\n\nWindows 경우: 설치시 물어보는 “add Miniconda to your PATH variable” 옵션을 켜고 설치할 것\n\nShell 사용에 대해서는 아래 2. Command Line Tool 참고\n\n# Terminal (Mac) or Miniconda Powershell Prompt (Windows)\n\n#(base)&gt; conda info # 콘다 정보 \n#(base)&gt; conda update conda # 콘다 업데이트"
  },
  {
    "objectID": "contents/setup.html#패키지-repositorychannel-선택",
    "href": "contents/setup.html#패키지-repositorychannel-선택",
    "title": "환경설정",
    "section": "",
    "text": "conda/managing channels\n다음을 통해 .condarc 환경파일에 configuration 추가\n\n#(base)&gt; conda config --add channels conda-forge\n#(base)&gt; conda config --set channel_priority strict  # 채널 순으로 검색, 버전 순이 아니고\n\n\n# 개별적으로 채널을 선택해서 install하려면 (특정 환경에 설치하려면 아래 conda environment 참조)\n#(base)&gt; conda install scipy --channel conda-forge\n\n# pakcage가 있는 채널들\n#(base)&gt; conda search scipy\n\nconda base에 있는 Python을 update하려면, 가령 3.10으로 업데이트하려면\n\n#(base)&gt; conda install python=3.10  # python update"
  },
  {
    "objectID": "contents/setup.html#conda-environment",
    "href": "contents/setup.html#conda-environment",
    "title": "환경설정",
    "section": "",
    "text": "conda/user guide\n환경 생성: miniconda에서 자체 제공하는 가상환경으로 수업에서는 다른 가상환경 툴인 pyenv나 venv 사용하지 않음\n\n#&gt; conda create --name myenv\n\n# 특정 버전의 파이썬 설치시\n#&gt; conda create --name myenv python=3.9\n\n환경 확인\n\n#&gt; conda env list\n\n#&gt; conda environments:\n#&gt;  base         */.../miniconda3\n#&gt;                /.../miniconda3/envs/myenv\n\n환경 제거\n\n#&gt; conda env remove --name myenv\n\n환경 activate/deactivate\n\n#&gt; conda activate myenv\n#&gt; conda deactivate  # activated 환경 내에서\n\n특정 환경 안의 파이썬 버전 확인\n\n#(myenv)&gt; python --version\n\n\n\n\n\n\n\nJupyter notebook을 쓰는 경우\n\n\n\n새로 만든 가상환경을 등록해줘야 함.\n#(myenv)&gt; ipython kernel install --user --name=myenv\n가상환경을 삭제해도 등록시킨 kernel 이름은 삭제되지 않으니 직접 삭제.\n등록된 커널 리스트를 확인\n#(myenv)&gt; jupyter kernelspec list\n커널 삭제\n#(myenv)&gt; jupyter kernelspec remove myenv"
  },
  {
    "objectID": "contents/setup.html#activated-환경-내에서-패키지-설치-및-제거",
    "href": "contents/setup.html#activated-환경-내에서-패키지-설치-및-제거",
    "title": "환경설정",
    "section": "",
    "text": "# 특정 환경을 activate한 후\n#(myenv)&gt; conda install &lt;package name1&gt; &lt;package name2&gt; ...\n#(myenv)&gt; conda install --channel conda-forge &lt;package name&gt; # 특정 conda-forge 채널을 통한 설치\n\n# 제거\n#(myenv)&gt; conda remove &lt;package name1&gt; &lt;package name2&gt; ...\n\n# 업데이트\n#(myenv)&gt; conda update &lt;package name1&gt; &lt;package name2&gt; ...\n#(myenv)&gt; conda update --all # all packages\n\n# 패키지 리스트\n#(myenv)&gt; conda list\n\n\n# 환경 밖에서 특정 환경 안에 설치하려면 환경이름 추가\n#(base)&gt; conda install --name myenv &lt;package name1&gt;\n\n\n# pip을  이용한  패키지 설치: conda repository에 없는 패키지들을 설치하는 경우. 충돌의 우려 있음\n#(myenv)&gt; pip install &lt;package name1&gt; &lt;package name2&gt; ...\n\n\n# 환경 안에 다른 버전의 Python 설치하려면, 가령 python 3.9라면\n#(myenv)&gt; conda install python=3.9\n\n수업에 필요한 기본 패키지 설치\n\n# 수업에 필요한 기본 패키지 설치\n#(myenv)&gt; conda install jupyter numpy pandas matplotlib seaborn"
  },
  {
    "objectID": "contents/setup.html#mac의-경우-기본-bash-shell인-terminal-대신-다음-zsh을-추천",
    "href": "contents/setup.html#mac의-경우-기본-bash-shell인-terminal-대신-다음-zsh을-추천",
    "title": "환경설정",
    "section": "Mac의 경우: 기본 bash shell인 terminal 대신 다음 zsh을 추천",
    "text": "Mac의 경우: 기본 bash shell인 terminal 대신 다음 zsh을 추천\nOh-My-Zsh!: 링크\n\n이 경우 miniconda 설치시 bash의 추가된 conda setup을 zsh로 가져와야 함: minconda를 zsh 설치 후에 설치하는 경우는 miniconda가 추가시키니 신경쓸 필요 없음\n\nhome directory에 있는 .bash_profile 을 열면 # &gt;&gt;&gt; conda initialize &gt;&gt;&gt; 로 시작해서 # &lt;&lt;&lt; conda initialize &lt;&lt;&lt; 부분까지를 복사한 후 .zshrc 파일을 열어 맨 뒤에 붙여넣음\n위 파일을 VS Code에서 쉽게 열어보려면 아래 그림처럼 VS Code에서 Sehll Command: Install 'Code' command in PATH 실행하고 나면\nshell 환경에서 code .zshrc를 실행하면 VS Code에서 편집할 수 있음"
  },
  {
    "objectID": "contents/setup.html#windows의-경우-windows-terminal-추천",
    "href": "contents/setup.html#windows의-경우-windows-terminal-추천",
    "title": "환경설정",
    "section": "Windows의 경우: Windows Terminal 추천",
    "text": "Windows의 경우: Windows Terminal 추천\n\n설치 링크는 구글링…\n명령프롬프트(CMD) vs. Powershell\nPowershell에서 conda를 사용하기 위해서는 몇 가지 설정 필요: 블로그 링크\n다 잘 안될 경우, 그냥 conda 설치시 함께 설치되는 응용프로그램 콘다 powershell을 이용"
  },
  {
    "objectID": "contents/setup.html#vs-code-설치",
    "href": "contents/setup.html#vs-code-설치",
    "title": "환경설정",
    "section": "VS Code 설치",
    "text": "VS Code 설치\n개인마다 선호하는 text editor가 있으나 본 수업에서는 VS Code로 진행: download and install here"
  },
  {
    "objectID": "contents/setup.html#extensions",
    "href": "contents/setup.html#extensions",
    "title": "환경설정",
    "section": "Extensions",
    "text": "Extensions\n\nPython\nPython Extension Pack 중\n\nIntelliCode\nPython Environment Manager\n\nDocs View\n\n안 보일시, 설정에서 language server를 default(Pylance)에서 Jedi로 바꾸면 해결\n\nCopilot…"
  },
  {
    "objectID": "contents/setup.html#preferences",
    "href": "contents/setup.html#preferences",
    "title": "환경설정",
    "section": "Preferences",
    "text": "Preferences\n\nThemes\nFont, font size (notebook, markup, output)"
  },
  {
    "objectID": "contents/setup.html#shortcuts",
    "href": "contents/setup.html#shortcuts",
    "title": "환경설정",
    "section": "Shortcuts",
    "text": "Shortcuts\nShow Command Palette: ctrl(cmd) + shift + p, 또는 F1\nCell 안과 밖에서 다르게 작동\n\nundo/redo : ctrl(cmd) + z / ctrl(cmd) + shift + z\nalt(option) + arrow up/down : move\nalt(option) + shift + arrow up/down : copy\n\n실행 방식 3가지: ctrl/shift/alt(option) + enter\nHelp:Keyboard shortcuts reference의 Basic editing 참고"
  },
  {
    "objectID": "contents/setup.html#그-외",
    "href": "contents/setup.html#그-외",
    "title": "환경설정",
    "section": "그 외",
    "text": "그 외\n\ninteractive mode\nexport\ndocs view: sticky mode\nvariables viewer, data viewer\nformatter: “Black formatter”\nsnippets: 구글링…"
  },
  {
    "objectID": "contents/plots.html",
    "href": "contents/plots.html",
    "title": "Plots",
    "section": "",
    "text": "source: R for Data Science\n\nTransform (데이터 변형)\n\n데이터의 변수들 중 일부를 선택하기\n필요한 부분를 필터링하기\n기존의 변수들로 새로운 변수 만들기\n요약자료를 계산하기\n\nVisualise (시각화)\n\n시각화를 통해 데이터가 품고 있는 정보를 파악하여 데이터에 대한 이해를 높임\n\nModel (모형)\n\n시각화와 데이터 변형의 두 가지를 병행하면서 호기심과 의구심을 갖고 연구자가 자신의 관심사에 답을 구하는 탐색적 분석을 하는 과정\n이 과정에서 모형을 세우고 데이터를 얼마나 잘 설명하는지를 살펴보고, 모형을 수정해 나가는 과정을 거침"
  },
  {
    "objectID": "contents/plots.html#데이터-분석의-과정",
    "href": "contents/plots.html#데이터-분석의-과정",
    "title": "Plots",
    "section": "",
    "text": "source: R for Data Science\n\nTransform (데이터 변형)\n\n데이터의 변수들 중 일부를 선택하기\n필요한 부분를 필터링하기\n기존의 변수들로 새로운 변수 만들기\n요약자료를 계산하기\n\nVisualise (시각화)\n\n시각화를 통해 데이터가 품고 있는 정보를 파악하여 데이터에 대한 이해를 높임\n\nModel (모형)\n\n시각화와 데이터 변형의 두 가지를 병행하면서 호기심과 의구심을 갖고 연구자가 자신의 관심사에 답을 구하는 탐색적 분석을 하는 과정\n이 과정에서 모형을 세우고 데이터를 얼마나 잘 설명하는지를 살펴보고, 모형을 수정해 나가는 과정을 거침"
  },
  {
    "objectID": "contents/plots.html#first-steps",
    "href": "contents/plots.html#first-steps",
    "title": "Plots",
    "section": "First steps",
    "text": "First steps\n\n\nLoad packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\n\n\n\n\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 8\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\n\n\nData: Fuel economy data from 1999 to 2008 for 38 popular models of cars\n\n# import the dataset\nmpg_data = sm.datasets.get_rdataset(\"mpg\", \"ggplot2\")\nmpg = mpg_data.data\n\n\n# Description\nprint(mpg_data.__doc__)\n\n\nmpg\n\n    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n0           audi      a4   1.80  1999    4    auto(l5)   f   18   29  p   \n1           audi      a4   1.80  1999    4  manual(m5)   f   21   29  p   \n2           audi      a4   2.00  2008    4  manual(m6)   f   20   31  p   \n3           audi      a4   2.00  2008    4    auto(av)   f   21   30  p   \n..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n230   volkswagen  passat   2.00  2008    4  manual(m6)   f   21   29  p   \n231   volkswagen  passat   2.80  1999    6    auto(l5)   f   16   26  p   \n232   volkswagen  passat   2.80  1999    6  manual(m5)   f   18   26  p   \n233   volkswagen  passat   3.60  2008    6    auto(s6)   f   17   26  p   \n\n       class  \n0    compact  \n1    compact  \n2    compact  \n3    compact  \n..       ...  \n230  midsize  \n231  midsize  \n232  midsize  \n233  midsize  \n\n[234 rows x 11 columns]\n\n\nQ: 엔진의 크기(displ)와 연비(hwy)는 어떤 관계에 있는가?\n\n# Scatter plot: 산포도\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\") # empty plot을 생성하고, x, y축에 mapping할 mpg 데이터의 변수를 지정\n    .add(so.Dot()) # layer를 추가하여, points들을 Dot이라는 mark object를 써서 표현\n)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLayer-specific mappings\nglobal vs. local mapping\n다음과 같이 첫번째 layer 안에서 x, y를 mapping하는 경우, 이후 새로 추가되는 layer에는 그 mapping이 적용되지 않음\n(\n    so.Plot(mpg)\n    .add(so.Dot(), x=\"displ\", y=\"hwy\") # 이 layer에서만 mapping이 유효\n)\n\n\n\n\n\n\n\n\nTip\n\n\n\n다음과 같이 x, y를 생략하거나 간략히 할 수 있으나…\nso.Plot(mpg, \"displ\", \"hwy\").add(so.Dot())\n\n\n\n카테고리 변수인 경우\n\ncyl (실린더 개수), hwy (고속도로 연비)의 관계를 scatterplot으로 살펴볼 수 있는가? (left)\nclass (차량 타입), drv (전륜 구동, 후륜 구동, 4륜 구동 타입)의 관계는 어떠한가? (right)"
  },
  {
    "objectID": "contents/plots.html#aesthetic-mappings",
    "href": "contents/plots.html#aesthetic-mappings",
    "title": "Plots",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nQ: 엔진의 크기와 연비와의 관계에서 보이는 트렌드 라인에서 심하게 벗어난 것이 있는가?\n\n\n\n\n\n 변수들을 x, y라는 position에 mapping하는 것에 추가하여 다음과 같은 속성(aesthetic)에 mapping할 수 있음\n색(color), 크기(pointsize), 모양(marker), 선 종류(linestyle), 투명도(alpha)\n\n\nColor\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nPointsize\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", pointsize=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nMarker\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", marker=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nAlpha\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", alpha=\"class\")\n    .add(so.Dot())\n)\n\n\n\n\n\n\nLinestyle\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\np = so.Plot(healthexp, x=\"Spending_USD\", y=\"Life_Expectancy\", linestyle=\"Country\")\np.add(so.Line())\n\n\n\n\n\n\n두 가지 이상의 속성\nex. color & marker\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\", marker=\"drv\")\n    .add(so.Dot())\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"class\", pointsize=\"drv\")\n    .add(so.Dot())\n    .scale(pointsize=(5, 15))  # pointsize의 range설정\n)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n아래 그림에서처럼 연속 vs. 카테고리 변수 여부에 따라 다르게 작동\n\n\n\n\n\n\n\n\n\n(a) type of car\n\n\n\n\n\n\n\n(b) city miles per gallon\n\n\n\n\nFigure 1: Categorical vs. Continuous\n\n\n\n\n\n\n\n\nImportant\n\n\n\n어떤 속성을 어떤 변수에 할당하는 것이 적절한지를 선택하는 것이 기술\n예를 들어, 아래 두 플랏은 동일한 정보를 품고 있으나, 시각적 인식에 큰 차이를 만듦"
  },
  {
    "objectID": "contents/plots.html#setting-properties",
    "href": "contents/plots.html#setting-properties",
    "title": "Plots",
    "section": "Setting properties",
    "text": "Setting properties\nSetting properties vs. mapping properties (aesthetic)\n\n변수에 속성을 할당하는 것이 아니라, graphical objects (Marks)의 속성을 지정\nMarks (.Dot, .Line, .Bar, …) 마다 설정할 수 있는 속성이 다름\n주로 쓰이는 속성들: color, pointsize, alpha\n\n.Dot()의 경우\nclass seaborn.objects.Dot(artist_kws=, marker=&lt;‘o’&gt;, pointsize=&lt;6&gt;, stroke=&lt;0.75&gt;, color=&lt;‘C0’&gt;, alpha=&lt;1&gt;, fill=, edgecolor=, edgealpha=, edgewidth=&lt;0.5&gt;, edgestyle=&lt;‘-’&gt;)\n.Dots()의 경우\nclass seaborn.objects.Dots(artist_kws=, marker=&lt;rc:scatter.marker&gt;, pointsize=&lt;4&gt;, stroke=&lt;0.75&gt;, color=&lt;‘C0’&gt;, alpha=&lt;1&gt;, fill=, fillcolor=, fillalpha=&lt;0.2&gt;)\nAPI reference 참고\n\n\n\n\n\n\n\nTip\n\n\n\n다양한 Mark properties에 대해서는 홈페이지 참고\nProperties of Mark objects\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"deepskyblue\")) # Mark object 안에 지정!\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"deepskyblue\", pointsize=12, edgecolor=\"white\", edgewidth=1)) # Mark object 안에 지정!\n)\n\n\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\"orange\", pointsize=12, marker=\"&gt;\", alpha=.4))  # Mark object 안에 지정!\n)"
  },
  {
    "objectID": "contents/plots.html#faceting",
    "href": "contents/plots.html#faceting",
    "title": "Plots",
    "section": "Faceting",
    "text": "Faceting\n카테고리 변수들이 지니는 카테고리들(레벨)로 나누어 그리기\nData: palmerpenguins\n\n\n\n Artwork by @allison_horst\n\n\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\") # load a dataset: penguins\npenguins.head()\n\n  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n0  Adelie  Torgersen           39.10          18.70             181.00   \n1  Adelie  Torgersen           39.50          17.40             186.00   \n2  Adelie  Torgersen           40.30          18.00             195.00   \n3  Adelie  Torgersen             NaN            NaN                NaN   \n4  Adelie  Torgersen           36.70          19.30             193.00   \n\n   body_mass_g     sex  \n0      3750.00    Male  \n1      3800.00  Female  \n2      3250.00  Female  \n3          NaN     NaN  \n4      3450.00  Female  \n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .add(so.Dot(alpha=.5))\n    .facet(\"sex\")  # 기본적으로 columns으로 나누어져 그림, wrap: column에 몇 개까지 그릴지\n)\n\n\n\n\n\np = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(col=\"species\", row=\"sex\")\n    .add(so.Dot(alpha=.5))\n)\np\n\n\n\n\n\n# x, y축의 눈금을 일치할지 여부\np.share(x=False, y=True)\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFacet과 Color 중 어떤 방식으로 표현하는 것이 유리한가? 밸런스를 잘 선택!\n\n\n\nleft = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(col=\"species\")\n    .add(so.Dot(alpha=.5))\n)\nright = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\", color=\"species\")\n    .add(so.Dot(alpha=.5))\n)\n\nbottom = (\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .facet(row=\"species\")\n    .add(so.Dot(alpha=.5))\n)\n\n\n\n\n\n\n\n\n(a) faceting horizonally\n\n\n\n\n\n\n\n(b) color mapping\n\n\n\n\n\n\n\n\n\n(c) faceting vertically\n\n\n\n\nFigure 2: faceting vs. color mapping\n\n\n\nPairing\nFaceting이 변수 내에 다른 레벨에 따라 그려지는데 반해,\nparing은 x, y축에 다른 변수를 지정하여 그림\n\n(\n    so.Plot(penguins, y=\"body_mass_g\", color=\"species\")  # y축은 공유\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"])  # x축에 다른 변수를 mapping\n    .add(so.Dots())  # .Dots()! overploting에 유리. .Dot(alpha=.)로도 비슷\n)\n\n\n\n\nFacet & pair 동시\n\n(\n    so.Plot(penguins, y=\"body_mass_g\", color=\"sex\")\n    .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"])\n    .facet(row=\"species\")\n    .add(so.Dots())\n)\n\n\n\n\n\n\nMultiple plots\n개발 중…? Matplotlib을 이용\n\nimport matplotlib as mpl\n\nf = mpl.figure.Figure(figsize=(8, 4))\nsf1, sf2 = f.subfigures(1, 2)\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\")\n    .add(so.Dots())\n    .on(sf1)\n    .plot()\n)\n(\n    so.Plot(penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\")\n    .facet(row=\"sex\")\n    .add(so.Dots())\n    .on(sf2)\n    .plot()\n)\n\n\n\n\nSave plots\np.save(\"data/filename.png\") # p: a plot oject"
  },
  {
    "objectID": "contents/plots.html#geometric-objects",
    "href": "contents/plots.html#geometric-objects",
    "title": "Plots",
    "section": "Geometric objects",
    "text": "Geometric objects\n\nDot marks: Dot, Dots\nLine marks: Line, Lines, Path, Paths, Dash, Range\nBar marks: Bar, Bars\nFill marks: Area, Band\nText marks: Text"
  },
  {
    "objectID": "contents/plots.html#statistical-transformations",
    "href": "contents/plots.html#statistical-transformations",
    "title": "Plots",
    "section": "Statistical transformations",
    "text": "Statistical transformations\nAgg, Est, Count, Hist, KDE, Perc, PolyFit\n\n\n\n\n\n\nImportant\n\n\n\n위의 stats transform들을 이용하여 변형된 데이터 값을 geometric objects에 mapping하여 다양한 플랏을 그릴 수 있음\n원칙적으로는 직접 stats을 계산한 후에 그 데이터로 플랏을 그릴 수 있으나, 신속한 탐색적 분석을 위해 사용\n\n\n\n\n\n\n\n\nNote\n\n\n\n현재 seaborn.objects에서 다음 두 가지 중요한 statistical transformations이 제공되지 않고 있음\n\n(non-parametirc) fitted line을 보여주는 loess or GAM line\n분포의 간략한 summary인 boxplot\n\n이 부분에 대해서는 아래 몇 가지 대안이 있음: 그외에는 alternative plots 섹션 참고\n\n\n\n\n\n\n\n\nNote\n\n\n\nData에 fitted curve를 구하는 방식에는 여러 방법이 있음\n\nLinear fit: 1차 함수형태로 fit\nSmoothing fit\n\nPolynominal fit: n차 다항함수형태로 fit\nLoess/lowess: locally estimated/weighted scatterplot smoothing\nGAM: generalized additive model\nSpline: piece-wise polynominal regression\n\n\n나중에 좀 더 자세히 알아봄\n현재 seaborn.objects에서는 polynomial fit만 제공\n\n\n\nFitted lines\nseaborn.objects\n\nleft = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot())\n    .add(so.Line(), so.PolyFit(5))  # PolyFit(n): n차 다항식으로 fit\n)\n\nright = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Line(), so.PolyFit(5))  # PolyFit(n): n차 다항식으로 fit\n)\n\n\n\n\n\n\n\n\n(a) Scatterplot + trendline\n\n\n\n\n\n\n\n(b) Trendline only\n\n\n\n\nFigure 3: 데이터로부터 계산을 한 후 플랏이 그려짐\n\n\n\nleft = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\", color=\"drv\")  # color mapping이 이후 모든 layer에 적용\n    .add(so.Dot())\n    .add(so.Line(), so.PolyFit(5))\n)\n\nright = (\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"drv\")  # color mapping이 이 layer에만 적용\n    .add(so.Line(), so.PolyFit(5))\n)\n\n\n\n\n\n\n\n\n(a) color가 모든 layers에 적용: global mapping\n\n\n\n\n\n\n\n(b) color가 두번째 layer에만 적용: local mapping\n\n\n\n\nFigure 4: Inherited mapping\n\n\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"drv\")\n    .add(so.Line(), so.PolyFit(5), group=\"drv\") # color가 아닌 group으로 grouping\n)\n# 다항함수 fit의 특징 및 주의점\n\n\n\n\nLinear fit vs. smoothing fit:\n선형적인 트렌드에서 얼마나 벗어나는가?\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(color=\".6\"))\n    .add(so.Line(), so.PolyFit(5))\n    .add(so.Line(), so.PolyFit(1))\n)\n\n\n\n\n다른 대안으로는 plotly, seaborn; alternative plots 섹션 참고"
  },
  {
    "objectID": "contents/plots.html#seaborn.objects-요약",
    "href": "contents/plots.html#seaborn.objects-요약",
    "title": "Plots",
    "section": "Seaborn.objects 요약",
    "text": "Seaborn.objects 요약\n(\n    so.Plot(df, x=, y=, color=, ...)  # global mapping\n    .add(so.Dot(color=, pointsize=,...))  # mark object + setting properties\n    .add(so.Line(), x=, y=, color=, ...)  # local mapping\n    .add(so.Line(), so.Polyfit(5))  # 통계적으로 변환한 값을 Line plot으로 표현\n    .add(so.Bar(), so.Hist(stat=\"proportion\"))  # 통계적으로 변환한 값을 Bar plot로 표현\n    ...\n    .facet(col=, row=, wrap=) # 카테고리의 levels에 따라 나누어 표현\n)\n\nAesthetic mapping\n\n위치(position): x축, y축\n색(color), 크기(pointsize), 모양(marker), 선 종류(linestyle), 투명도(alpha)\nglobal vs. local mapping\n\nGeometric objects\n\nDot marks: Dot, Dots\nLine marks: Line, Path, Dash, Range\nBar marks: Bar, Bars\nFill marks: Area, Band\nText marks: Text\n\nSetting properties\n\nMarks (.Dot(), .Line(), .Bar(), …) 내부에 속성을 지정하고, marks마다 설정할 수 있는 속성이 다름.\n주로 쓰이는 속성들: color, pointsize, alpha\n\nStatistical transformations\n\n변수들을 통계적 변환 후 그 값을 이용\nAgg, Est, Count, Hist, KDE, Perc, PolyFit\n\nFaceting: 카테고리 변수들의 levels에 따라 나누어 그림"
  },
  {
    "objectID": "contents/plots.html#visualizing-distributions",
    "href": "contents/plots.html#visualizing-distributions",
    "title": "Plots",
    "section": "Visualizing distributions",
    "text": "Visualizing distributions\n분포를 살펴보는데 변수가 연속인지 카테고리인지에 따라 다른 방식\n\nA categorical variable\n\ntips = sns.load_dataset(\"tips\")\ntips.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\n(\n    so.Plot(tips, x=\"day\")\n    .add(so.Bar(), so.Count())  # category type의 변수는 순서가 존재. \n                                # 그렇지 않은 경우 알바벳 순서로. \n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n복잡한 통계치의 경우 직접 구한후 plot을 그리는 것이 용이\ncount_day = tips.value_counts(\"day\", normalize=True).reset_index(name=\"pct\")\n#     day  pct\n# 0   Sat 0.36\n# 1   Sun 0.31\n# 2  Thur 0.25\n# 3   Fri 0.08\n(\n    so.Plot(count_day, x=\"day\", y=\"pct\")\n    .add(so.Bar())\n)\n\n\n\npenguins = sns.load_dataset(\"penguins\") # load a dataset: penguins\n\n# Species에 inherent order가 없음; 알파벳 순으로 정렬\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n)\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Hist(\"proportion\"))  # Hist()의 default는 stat=\"count\"\n    .layout(size=(4.5, 3.5))\n)\n\n# grouping의 처리에 대해서는 뒤에... 에를 들어, color=\"sex\"\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n표시 순서를 변경하는 일은 의미있는 플랏을 만드는데 중요\n나중에 좀 더 자세히 다룸\n\n\n\n# value_counts()는 크기대로 sorting!\nreorder = penguins.value_counts(\"species\").index.values\n#&gt; array(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n    .scale(x=so.Nominal(order=reorder))  # x축의 카테고리 순서를 변경\n)\n\n# 직접 개수를 구해 그리는 경우, 테이블의 순서대로 그려짐\n(\n    so.Plot(penguins.value_counts(\"species\").reset_index(), \n            x=\"species\", y=\"count\")\n    .add(so.Bar())\n)\n\n\n\n\n\n\n\n\n\n\nA numerical variable\n\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist())  # Histogram; x값을 bins으로 나누어 count를 계산!\n                                # .Bars()는 .Bar()에 비해 연속변수에 더 적합: 얇은 경계선으로 나란히 붙혀서 그려짐\n)\n\n\n\n\n\n\n\n\n\nleft = (\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(binwidth=100))  # binwidth vs. bins\n)\nright = (\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(bins=10))  # binwidth vs. bins\n)\n\n\n\n\n\n\n\n\n(a) binwidth=100\n\n\n\n\n\n\n\n(b) bins=10\n\n\n\n\nFigure 5: binwidth vs. bins\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Bars(), so.Hist(\"proportion\"))  # 비율을 계산; stat=\"count\"가 default\n)\n\n\n\n\n\n\n\n\n\n# Density plot: 넓이가 1이 되도록\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Area(), so.KDE())  # Density plot\n)\n\n\n\n\n\n\n\n\n\n# Density plot: 넓이가 1이 되도록\n(\n    so.Plot(penguins, x=\"body_mass_g\")\n    .add(so.Line(color=\"orange\"), so.KDE(bw_adjust=.2))  # Density bandwidth: binwidth에 대응\n    .add(so.Bars(alpha=.3), so.Hist(\"density\", binwidth=100))  # stat=\"density\"\n)"
  },
  {
    "objectID": "contents/plots.html#visualizing-relationships",
    "href": "contents/plots.html#visualizing-relationships",
    "title": "Plots",
    "section": "Visualizing relationships",
    "text": "Visualizing relationships\n\nA numerical and a categorical variable\n\nBoxplot\nGrouped distribution: histogram, frequency polygon, density plot\n\nBoxplot\n\nsource: R for Data Science\n\n\nsns.boxplot(penguins, x=\"species\", y=\"body_mass_g\")\nplt.show()  # 생략해도 무방\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\")\n    .add(so.Dot(pointsize=8), so.Agg(\"median\"))  # .Agg(): aggregation, default는 mean\n    .add(so.Range(), so.Est(errorbar=(\"pi\", 50)))   # .Range(): 기본 min/max range, \n                                                    # .Est(): estimator\n)\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\")\n    .add(so.Dots(color=\".5\"), so.Jitter()) # so.Jitter(): 흐트려뜨려 그리기\n    .add(so.Dot(pointsize=8), so.Agg(\"median\"))  # .Agg(): aggregation, default는 mean\n    .add(so.Range(), so.Est(errorbar=(\"pi\", 50)))   # .Range(): 기본 min/max range, \n                                                    # .Est(): estimator\n)\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\")\n    .add(so.Dot(pointsize=8), so.Agg(\"median\"))  # .Agg(): aggregation, default는 mean\n    .add(so.Range(), so.Est(errorbar=(\"pi\", 50)))   # .Range(): 기본 min/max range, \n                                                    # .Est(): estimator\n)\n\n\n\n\n\n\n\n\nError bars에 대해서는 seaborn/statistical estimation and error bars\n\n(\n    so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\")\n    .add(so.Dots(), so.Jitter(), so.Dodge())\n    .add(so.Dot(pointsize=5), so.Agg(\"median\"), so.Dodge())\n    .add(so.Range(), so.Est(errorbar=(\"pi\", 50)), so.Dodge())\n)\n\n\n\n\n\nsns.boxplot(penguins, x=\"species\", y=\"body_mass_g\", hue=\"sex\")\nplt.show() # 생략해도 무방\n\n\n\n\n\n\n\n\n\n# Build a boxplot!\ndef boxplot(df, x, y, color=None, alpha=0.1):\n    return (\n        so.Plot(df, x=x, y=y, color=color)\n        .add(so.Dots(alpha=alpha, color=\".6\"), so.Jitter(), so.Dodge())\n        .add(so.Range(), so.Est(errorbar=(\"pi\", 50)), so.Dodge())\n        .add(so.Dots(pointsize=8, marker=\"&lt;\"), so.Agg(\"median\"), so.Dodge())\n        .scale(color=\"Dark2\")\n        .theme({**sns.axes_style(\"whitegrid\")})\n    )\n\n(\n    boxplot(penguins, x=\"species\", y=\"flipper_length_mm\", color=\"sex\")\n    .facet(\"island\")\n    .layout(size=(8, 4))\n)\n\n\n\n\n\n# Build a rangeplot!\ndef rangeplot(df, x, y, color=None):\n    return (\n        so.Plot(df, x=x, y=y, color=color)\n        .add(so.Range(), so.Est(errorbar=(\"pi\", 50)), so.Dodge())\n        .add(so.Dots(pointsize=8, marker=\"&lt;\"), so.Agg(\"median\"), so.Dodge())\n        .scale(color=\"Dark2\")\n        .theme({**sns.axes_style(\"whitegrid\")})\n    )\n\n(\n    rangeplot(penguins, x=\"species\", y=\"flipper_length_mm\", color=\"sex\")\n    .facet(\"island\")\n    .layout(size=(8, 4))\n)\n\n\n\n\nHistogram\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Bar(), so.Hist(binwidth=200, common_bins=False))  # bins을 공유하지 않도록\n)\n# Hist(): 다양한 parameter가 있음...\n\n\n\n\n\n\n\n\nFrequency polygon\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Line(marker=\".\"), so.Hist(binwidth=200))  # Line에 maker \".\"을 표시\n)\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Line(marker=\".\"), so.Hist(binwidth=200, stat=\"proportion\",  common_norm=False))  # Line에 maker \".\"을 표시\n)\n\n\n\n\n\n\n\n\nDensity plot\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", color=\"species\")\n    .add(so.Area(), so.KDE(common_norm=False))  # Density plot, species별로 넓이가 1이 되도록\n)\n\n\n\n\n\n\n\n\n\n\nTwo categorical variables\n\np = so.Plot(penguins, x=\"island\", color=\"species\")\np.add(so.Bar(), so.Count())  # Bar() mark + Count() transformation\n\n\n\n\n\n\n\n\n\nleft = p.add(so.Bar(), so.Count(), so.Dodge())   # 나란히 표시\nright = p.add(so.Bar(), so.Count(), so.Stack())  # stacking\n\n\n\n\n\n\n\n\n(a) dodge\n\n\n\n\n\n\n\n(b) stack\n\n\n\n\nFigure 6: dodge vs. stack\n\n\nCount 대신 proportion을 표시하는 경우\n\n# 각 비율값의 합이 1이 되도록, 즉 모든 카테고리에 걸쳐 normalize\np.add(\n    so.Bar(width=.5), so.Hist(\"proportion\"),  # proportion; stat=\"count\"로 하면 앞서 so.Count()와 동일\n    so.Stack()  # stacking\n)\n\n\n\n\n\n\n\n\n\n# x축 기준으로 normalize\np.add(\n    so.Bar(width=.5), so.Hist(\"proportion\", common_norm=[\"x\"]),  # proportion; \n    so.Stack()  # stacking\n)\n# warning이 뜰 수 있음!\n\n\n\n\n\n\n\n\n\n# x축, facet의 column 기준으로 normalize\np.add(\n    so.Bar(width=.8), so.Hist(\"proportion\", common_norm=[\"x\", \"col\"]),  # proportion\n    so.Stack(),  # stacking\n).facet(col=\"sex\")  # faceting\n\n\n\n\ncommon_norm: True vs. False 비교\n\n# 각 비율값의 합이 1이 되도록, 즉 모든 카테고리에 걸쳐 normalize\nleft = p.add(\n    so.Bar(width=.5), so.Hist(\"proportion\", common_norm=True),  # common_norm default: True \n    so.Stack()\n)\n\n# 각 species별로 normalize \nright = p.add(\n    so.Bar(width=.5), so.Hist(\"proportion\", common_norm=False),\n    so.Stack()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo numerical variables\nScatterplot\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n    .add(so.Dot())  # overplotting에는 so.Dots()가 유리 \n)\n\n\n\n\n\n\n\n\n\n\nThree or more variables\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\",\n            color=\"species\", marker=\"island\")\n    .add(so.Dot())\n    .layout(size=(6, 4))\n)\n\n\n\n\nFacet의 활용\n\n(\n    so.Plot(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\",\n            color=\"species\")\n    .add(so.Dot(alpha=.5))\n    .facet(\"island\")\n    .layout(size=(8, 4))\n)\n\n\n\n\n\n\nTime series\n\nhealthexp = sns.load_dataset(\"healthexp\")\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Spending_USD\", color=\"Country\")\n    .add(so.Lines())\n)\n\n\n\n\n\n# 전체와 각 그룹의 상태를 동시에 파악\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Spending_USD\", color=\"Country\")\n    .add(so.Area(), so.Stack()) # add stacking\n)\n\n\n\n\n\n(\n    so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\")\n    .add(so.Line(alpha=.3), group=\"Country\", col=None)\n    .add(so.Line(linewidth=3))\n    .facet(\"Country\", wrap=3)  # wrap!!!\n)\n\n\n\n\n\nfmri = sns.load_dataset(\"fmri\")\n\np = so.Plot(fmri, x=\"timepoint\", y=\"signal\", color=\"region\", linestyle=\"event\")\np.add(so.Line(), so.Agg())  # Agg()의 default 함수는 mean\n\n\n\n\n\np.add(so.Line(marker=\"o\", edgecolor=\"w\"), so.Agg(), linestyle=None)  # linestyle을 overwrite!"
  },
  {
    "objectID": "contents/plots.html#overploting",
    "href": "contents/plots.html#overploting",
    "title": "Plots",
    "section": "Overploting",
    "text": "Overploting\n대표적으로 다음과 같은 방식으로 해결할 수 있음.\n\nalpha property: 투명도를 조절\n\nso.Jitter() mark: 흐트려뜨려 그리기\n\nso.Dots() mark: 불투명, 테두리 선명한 점들\n\n.facet() facet: 다른 면에 그리기\n\n특별히 overplotting에 특화된 plots도 있음. 예를 들어,\n\nsns.catplot(\n    data=penguins, kind=\"swarm\",\n    x=\"species\", y=\"body_mass_g\", hue=\"sex\", col=\"island\",\n    aspect=.6\n)\nplt.show()\n\n\n\n\n\nsns.histplot(penguins, x=\"bill_depth_mm\", y=\"body_mass_g\")\nplt.show()"
  },
  {
    "objectID": "contents/plots.html#new-data",
    "href": "contents/plots.html#new-data",
    "title": "Plots",
    "section": "New data",
    "text": "New data\n새로운 데이터 값을 이용하고자 할 때, 직접 입력\n\nmpg_suv = mpg.query('`class` == \"suv\"')\n\n(\n    so.Plot(mpg, x=\"displ\", y=\"hwy\")\n    .add(so.Dot(), color=\"class\")\n    .add(so.Line(), so.PolyFit(5), \n         x=mpg_suv[\"displ\"], y=mpg_suv[\"hwy\"])\n)"
  },
  {
    "objectID": "contents/plots.html#exercises",
    "href": "contents/plots.html#exercises",
    "title": "Plots",
    "section": "Exercises",
    "text": "Exercises\n다음 데이터들로 위에서 다룬 시각화를 연습해보세요.\n\ntips\ntips = sns.load_dataset(\"tips\")\nData on houses in Saratoga County, New York, USA in 2006\nhouses_data = sm.datasets.get_rdataset(\"SaratogaHouses\", \"mosaicData\")\n\nhouses = houses_data.data   # data\nprint(houses_data.__doc__)  # description of the data"
  },
  {
    "objectID": "contents/inspection.html",
    "href": "contents/inspection.html",
    "title": "Inspecting data",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 8\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)"
  },
  {
    "objectID": "contents/inspection.html#useful-method",
    "href": "contents/inspection.html#useful-method",
    "title": "Inspecting data",
    "section": "Useful method",
    "text": "Useful method\n.head(), .tail(), .sample()\n.info(), .describe(),\n.value_counts(),\n.sort_values(), .nlargest(), .nsmallest()\nData: Tips\n일정기간 한 웨이터가 얻은 팁에 대한 데이터\n\n# load a dataset\ntips = sns.load_dataset(\"tips\")\ntips\n\n     total_bill  tip     sex smoker   day    time  size\n0         16.99 1.01  Female     No   Sun  Dinner     2\n1         10.34 1.66    Male     No   Sun  Dinner     3\n2         21.01 3.50    Male     No   Sun  Dinner     3\n3         23.68 3.31    Male     No   Sun  Dinner     2\n..          ...  ...     ...    ...   ...     ...   ...\n240       27.18 2.00  Female    Yes   Sat  Dinner     2\n241       22.67 2.00    Male    Yes   Sat  Dinner     2\n242       17.82 1.75    Male     No   Sat  Dinner     2\n243       18.78 3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]\n\n\n\n# DataFrame의 값들: ndarray\ntips.values # or tips.to_numpy()\n\narray([[16.99, 1.01, 'Female', ..., 'Sun', 'Dinner', 2],\n       [10.34, 1.66, 'Male', ..., 'Sun', 'Dinner', 3],\n       [21.01, 3.5, 'Male', ..., 'Sun', 'Dinner', 3],\n       ...,\n       [22.67, 2.0, 'Male', ..., 'Sat', 'Dinner', 2],\n       [17.82, 1.75, 'Male', ..., 'Sat', 'Dinner', 2],\n       [18.78, 3.0, 'Female', ..., 'Thur', 'Dinner', 2]], dtype=object)\n\n\n\ntips.head() # 처음 N개 나열\n\n   total_bill  tip     sex smoker  day    time  size\n0       16.99 1.01  Female     No  Sun  Dinner     2\n1       10.34 1.66    Male     No  Sun  Dinner     3\n2       21.01 3.50    Male     No  Sun  Dinner     3\n3       23.68 3.31    Male     No  Sun  Dinner     2\n4       24.59 3.61  Female     No  Sun  Dinner     4\n\n\n\ntips.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n\n\n\ntips.describe() # numerical type만 나열\n\n\n\n       total_bill    tip   size\ncount      244.00 244.00 244.00\nmean        19.79   3.00   2.57\nstd          8.90   1.38   0.95\nmin          3.07   1.00   1.00\n25%         13.35   2.00   2.00\n50%         17.80   2.90   2.00\n75%         24.13   3.56   3.00\nmax         50.81  10.00   6.00\n\n\n\n\n\ntips.describe(include=\"all\") # all types 나열\n\n        total_bill    tip   sex smoker  day    time   size\ncount       244.00 244.00   244    244  244     244 244.00\nunique         NaN    NaN     2      2    4       2    NaN\ntop            NaN    NaN  Male     No  Sat  Dinner    NaN\nfreq           NaN    NaN   157    151   87     176    NaN\n...            ...    ...   ...    ...  ...     ...    ...\n25%          13.35   2.00   NaN    NaN  NaN     NaN   2.00\n50%          17.80   2.90   NaN    NaN  NaN     NaN   2.00\n75%          24.13   3.56   NaN    NaN  NaN     NaN   3.00\nmax          50.81  10.00   NaN    NaN  NaN     NaN   6.00\n\n[11 rows x 7 columns]\n\n\n\ntips.describe(include=\"category\")\n\n\n\n         sex smoker  day    time\ncount    244    244  244     244\nunique     2      2    4       2\ntop     Male     No  Sat  Dinner\nfreq     157    151   87     176\n\n\n\n\n\ns1 = tips.value_counts(\"day\") # \"day\" 칼럼에 대한 각 카테고리별 counts\ns2 = tips.value_counts(\"day\", sort=False) # default: sort is true\ns3 = tips.value_counts(\"day\", ascending=True) # default: ascending is False\ns4 = tips.value_counts(\"day\", normalize=True) # 카테고리별 비율\ns5 = tips.value_counts([\"sex\", \"smoker\"]) # \"sex\", \"smoker\" 칼럼에 대한 유니크한 카테고리별 counts\n\n\n\n\n\n\nday\nSat     87\nSun     76\nThur    62\nFri     19\nName: count, dtype: int64\n(a) s1\n\n\n\n\nday\nThur    62\nFri     19\nSat     87\nSun     76\nName: count, dtype: int64\n(b) s2\n\n\n\n\n\n\nday\nFri     19\nThur    62\nSun     76\nSat     87\nName: count, dtype: int64\n(c) s3\n\n\n\n\nday\nSat    0.36\nSun    0.31\nThur   0.25\nFri    0.08\nName: proportion, dtype: float64\n(d) s4\n\n\n\n\n\n\nsex     smoker\nMale    No        97\n        Yes       60\nFemale  No        54\n        Yes       33\nName: count, dtype: int64\n(e) s5\n\n\n\nFigure 1: value_count()의 arguments\n\n\n\n\n\n\n\n\nTip\n\n\n\n.value_count()의 결과는 Series이며 그 이름은 ‘count’ 또는 ’proportion’임 (pandas 2.0)\nMissing(NA)을 count하지 않으나 dropna=False을 이용해 나타낼 수 있음\ntips.value_counts(\"day\", dropna=False)\nSeries에 대해서도 적용되며, DataFrame을 먼저 선택해 적용할 수 있음\ntips[\"day\"].value_counts()  # tips[\"day\"]: Series object\ntips[[\"sex\", \"smoker\"]].value_counts()\n\n\n\nData: palmerpenguins\n\n# load a dataset\npenguins = sns.load_dataset(\"penguins\")\npenguins\n\n    species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n0    Adelie  Torgersen            39.1           18.7              181.0   \n1    Adelie  Torgersen            39.5           17.4              186.0   \n2    Adelie  Torgersen            40.3           18.0              195.0   \n3    Adelie  Torgersen             NaN            NaN                NaN   \n4    Adelie  Torgersen            36.7           19.3              193.0   \n..      ...        ...             ...            ...                ...   \n339  Gentoo     Biscoe             NaN            NaN                NaN   \n340  Gentoo     Biscoe            46.8           14.3              215.0   \n341  Gentoo     Biscoe            50.4           15.7              222.0   \n342  Gentoo     Biscoe            45.2           14.8              212.0   \n343  Gentoo     Biscoe            49.9           16.1              213.0   \n\n     body_mass_g     sex  \n0         3750.0    Male  \n1         3800.0  Female  \n2         3250.0  Female  \n3            NaN     NaN  \n4         3450.0  Female  \n..           ...     ...  \n339          NaN     NaN  \n340       4850.0  Female  \n341       5750.0    Male  \n342       5200.0  Female  \n343       5400.0    Male  \n\n[344 rows x 7 columns]\n\n\n\npenguins.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 18.9+ KB\n\n\n\npenguins.describe(include=\"object\")\n\n\n\n       species  island   sex\ncount      344     344   333\nunique       3       3     2\ntop     Adelie  Biscoe  Male\nfreq       152     168   168\n\n\n\n\n\npenguins.value_counts([\"island\", \"species\"])\n\nisland     species  \nBiscoe     Gentoo       124\nDream      Chinstrap     68\n           Adelie        56\nTorgersen  Adelie        52\nBiscoe     Adelie        44\nName: count, dtype: int64\n\n\n\npenguins.value_counts([\"sex\", \"species\"], dropna=False) # NA은 기본적으로 생략\n\nsex     species  \nFemale  Adelie       73\nMale    Adelie       73\n        Gentoo       61\nFemale  Gentoo       58\n        Chinstrap    34\nMale    Chinstrap    34\nNaN     Adelie        6\n        Gentoo        5\nName: count, dtype: int64\n\n\n\n# NA의 개수\npenguins.isna().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\ndtype: int64\n\n\n\n# NA의 비율\npenguins.isna().mean()\n\nspecies              0.000000\nisland               0.000000\nbill_length_mm       0.005814\nbill_depth_mm        0.005814\nflipper_length_mm    0.005814\nbody_mass_g          0.005814\nsex                  0.031977\ndtype: float64\n\n\n\ntips.sort_values(\"tip\", ascending=False)\n\n     total_bill   tip     sex smoker  day    time  size\n170       50.81 10.00    Male    Yes  Sat  Dinner     3\n212       48.33  9.00    Male     No  Sat  Dinner     4\n23        39.42  7.58    Male     No  Sat  Dinner     4\n59        48.27  6.73    Male     No  Sat  Dinner     4\n..          ...   ...     ...    ...  ...     ...   ...\n236       12.60  1.00    Male    Yes  Sat  Dinner     2\n111        7.25  1.00  Female     No  Sat  Dinner     1\n67         3.07  1.00  Female    Yes  Sat  Dinner     1\n92         5.75  1.00  Female    Yes  Fri  Dinner     2\n\n[244 rows x 7 columns]\n\n\n\ntips.sort_values([\"size\", \"tip\"], ascending=[False, True])\n\n     total_bill  tip     sex smoker   day    time  size\n125       29.80 4.20  Female     No  Thur   Lunch     6\n143       27.05 5.00  Female     No  Thur   Lunch     6\n156       48.17 5.00    Male     No   Sun  Dinner     6\n141       34.30 6.70    Male     No  Thur   Lunch     6\n..          ...  ...     ...    ...   ...     ...   ...\n67         3.07 1.00  Female    Yes   Sat  Dinner     1\n111        7.25 1.00  Female     No   Sat  Dinner     1\n82        10.07 1.83  Female     No  Thur   Lunch     1\n222        8.58 1.92    Male    Yes   Fri   Lunch     1\n\n[244 rows x 7 columns]\n\n\n\ntips.nlargest(3, \"tip\")  # 다수의 동등 순위가 있을 때 처리: keep=\"first\", \"last\", \"all\"\n\n     total_bill   tip   sex smoker  day    time  size\n170       50.81 10.00  Male    Yes  Sat  Dinner     3\n212       48.33  9.00  Male     No  Sat  Dinner     4\n23        39.42  7.58  Male     No  Sat  Dinner     4"
  },
  {
    "objectID": "contents/customizing.html",
    "href": "contents/customizing.html",
    "title": "Customizing",
    "section": "",
    "text": "Load packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 8\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)"
  },
  {
    "objectID": "contents/customizing.html#scales-and-layouts",
    "href": "contents/customizing.html#scales-and-layouts",
    "title": "Customizing",
    "section": "Scales and layouts",
    "text": "Scales and layouts\n\npenguins = sns.load_dataset(\"penguins\")\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"island\")\n    .facet(col=\"sex\")\n    .add(so.Dot(), so.Jitter(.5))\n    .scale(color=\"Set2\")  # color palettes: \"Set2\"\n    .layout(size=(8, 5))  # plot size\n)\n\n\n\n\n\ndiamonds = sns.load_dataset(\"diamonds\")\n\n(\n    so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"carat\", marker=\"cut\")\n    .add(so.Dots())\n    .scale(\n        color=so.Continuous(\"crest\", norm=(0, 3), trans=\"sqrt\"),\n    )\n)\n\n\n\n\nChoosing color palettes"
  },
  {
    "objectID": "contents/customizing.html#legends-and-ticks",
    "href": "contents/customizing.html#legends-and-ticks",
    "title": "Customizing",
    "section": "Legends and ticks",
    "text": "Legends and ticks\n\n(\n    so.Plot(penguins, x=\"species\")\n    .add(so.Bar(), so.Count())\n    .scale(x=so.Nominal(order=[\"Adelie\", \"Gentoo\", \"Chinstrap\"])) # x축의 카테고리 순서를 변경\n)\n\n\n\n\n\n\n\n\n\n(\n    so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"carat\")\n    .add(so.Dots())\n    .scale(\n        x=so.Continuous().tick(every=0.5),\n        y=so.Continuous().label(like=\"${x:.0f}\"), # %표시: like=\"{x:.1f%}\" \n        color=so.Continuous().tick(at=[1, 2, 3, 4]),\n    )\n)"
  },
  {
    "objectID": "contents/customizing.html#limits-labels-and-titles",
    "href": "contents/customizing.html#limits-labels-and-titles",
    "title": "Customizing",
    "section": "Limits, labels, and titles",
    "text": "Limits, labels, and titles\nPlot has a number of methods for simple customization, including Plot.label(), Plot.limit(), and Plot.share():\n\npenguins = sns.load_dataset(\"penguins\")\n\n(\n    so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"island\")\n    .facet(col=\"sex\")\n    .add(so.Dot(), so.Jitter(.5))\n    .share(x=False)\n    .limit(y=(2.5, -.5))\n    .label(\n        x=\"Body mass (g)\", y=\"\",\n        color=str.capitalize,\n        title=\"{} penguins\".format,\n    )\n)"
  },
  {
    "objectID": "contents/customizing.html#themes",
    "href": "contents/customizing.html#themes",
    "title": "Customizing",
    "section": "Themes",
    "text": "Themes\n\ntips = sns.load_dataset(\"tips\")\np = (\n    so.Plot(tips, x=\"total_bill\", y=\"tip\", color=\"time\")\n    .add(so.Dot())\n)\np.theme({\"axes.facecolor\": \"white\", \n         \"axes.edgecolor\": \"0.8\", \n         'axes.spines.top': False,\n         'axes.spines.right': False})\n\n\n\n\n\n\n\n\nseaborn.axes_style\n\nfrom seaborn import axes_style\np.theme({**axes_style(\"whitegrid\")})\n\n\n\n\n\n\n\n\nSeaborn: controlling figure aesthetics\n\nfrom matplotlib import style\np.theme({**style.library[\"fivethirtyeight\"]})"
  },
  {
    "objectID": "contents/alt_plots.html",
    "href": "contents/alt_plots.html",
    "title": "Alternative plots",
    "section": "",
    "text": "alternatives: plotly, seaborn\n\n\n\nimport plotly.express as px\n\npx.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", trendline=\"lowess\")\n\n\n                                                \n\n\n다음과 같이 smoothing parameter를 지정할 수 있음\n자세한 옵션은 여기 참조: plotly linear fits\n\n(\n    px.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", \n               trendline=\"lowess\", trendline_options=dict(frac=0.3)) # smoothing parameter \n    .update_layout(width=600, height=500)\n)\n\n\n                                                \n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\n(\n    px.scatter(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\",\n               trendline=\"lowess\", trendline_options=dict(frac=0.5),\n               facet_col=\"island\", # faceting\n               opacity=0.5) # alpha\n    .update_layout(width=900, height=400)\n)\n\n\n                                                \n\n\n\n\n\n\n\nsns.lmplot(mpg, x=\"displ\", y=\"hwy\", hue=\"drv\", # color대신 hue\n           lowess=True, \n           scatter_kws={\"alpha\":.5, \"s\":20}, # s: point size\n           height=3, aspect=5/3) \nplt.show() # 생략해도 무방\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\nsns.lmplot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", \n           lowess=True, \n           col=\"sex\", # faceting: col, row\n           height=3, scatter_kws={\"alpha\":.5, \"s\":5})"
  },
  {
    "objectID": "contents/alt_plots.html#fitted-lines",
    "href": "contents/alt_plots.html#fitted-lines",
    "title": "Alternative plots",
    "section": "",
    "text": "alternatives: plotly, seaborn\n\n\n\nimport plotly.express as px\n\npx.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", trendline=\"lowess\")\n\n\n                                                \n\n\n다음과 같이 smoothing parameter를 지정할 수 있음\n자세한 옵션은 여기 참조: plotly linear fits\n\n(\n    px.scatter(mpg, x=\"displ\", y=\"hwy\", color=\"drv\", \n               trendline=\"lowess\", trendline_options=dict(frac=0.3)) # smoothing parameter \n    .update_layout(width=600, height=500)\n)\n\n\n                                                \n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\n(\n    px.scatter(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\",\n               trendline=\"lowess\", trendline_options=dict(frac=0.5),\n               facet_col=\"island\", # faceting\n               opacity=0.5) # alpha\n    .update_layout(width=900, height=400)\n)\n\n\n                                                \n\n\n\n\n\n\n\nsns.lmplot(mpg, x=\"displ\", y=\"hwy\", hue=\"drv\", # color대신 hue\n           lowess=True, \n           scatter_kws={\"alpha\":.5, \"s\":20}, # s: point size\n           height=3, aspect=5/3) \nplt.show() # 생략해도 무방\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\nsns.lmplot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", \n           lowess=True, \n           col=\"sex\", # faceting: col, row\n           height=3, scatter_kws={\"alpha\":.5, \"s\":5})"
  },
  {
    "objectID": "contents/alt_plots.html#box-plot",
    "href": "contents/alt_plots.html#box-plot",
    "title": "Alternative plots",
    "section": "Box plot",
    "text": "Box plot\n\npenguins = sns.load_dataset(\"penguins\")\n\n\nimport plotly.express as px\n\npx.box(penguins.dropna(subset=[\"sex\"]), x=\"species\", y=\"bill_length_mm\", color=\"island\",  facet_col=\"sex\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\npenguins = sns.load_dataset(\"penguins\")\n\nsns.catplot(\n    data=penguins, x=\"species\", y=\"bill_length_mm\", hue=\"sex\", col=\"island\",\n    kind=\"box\", height=4, aspect=.6,\n)\nplt.show()"
  },
  {
    "objectID": "contents/notice.html",
    "href": "contents/notice.html",
    "title": "Notice",
    "section": "",
    "text": "10.9(월) 수업전까지\n\nPlots 섹션 마지막에 있는 연습문제에서 tips나 houses 데이터 중 하나 혹은 섞어서 Plots 단원에서 다뤘던 시각화를 적용해보기\n.ipynb 파일로 eclass에 제출\n\n4.23(월) 수업 전까지\n\nTransforming I 연습문제\nA, B 파트 전부와 C 파트는 할 수 있는 만큼"
  },
  {
    "objectID": "contents/notice.html#과제",
    "href": "contents/notice.html#과제",
    "title": "Notice",
    "section": "",
    "text": "10.9(월) 수업전까지\n\nPlots 섹션 마지막에 있는 연습문제에서 tips나 houses 데이터 중 하나 혹은 섞어서 Plots 단원에서 다뤘던 시각화를 적용해보기\n.ipynb 파일로 eclass에 제출\n\n4.23(월) 수업 전까지\n\nTransforming I 연습문제\nA, B 파트 전부와 C 파트는 할 수 있는 만큼"
  },
  {
    "objectID": "contents/notice.html#중간고사",
    "href": "contents/notice.html#중간고사",
    "title": "Notice",
    "section": "중간고사",
    "text": "중간고사"
  },
  {
    "objectID": "contents/notice.html#기말고사",
    "href": "contents/notice.html#기말고사",
    "title": "Notice",
    "section": "기말고사",
    "text": "기말고사"
  },
  {
    "objectID": "contents/notice.html#개별-프로젝트",
    "href": "contents/notice.html#개별-프로젝트",
    "title": "Notice",
    "section": "개별 프로젝트",
    "text": "개별 프로젝트"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contents/intro.html#미래-데이터의-중요성",
    "href": "contents/intro.html#미래-데이터의-중요성",
    "title": "데이터 분석 및 시각화",
    "section": "미래 데이터의 중요성",
    "text": "미래 데이터의 중요성\n4차 산업혁명의 ‘원유’: 머신러닝, AI\n\n다양한 소스들로부터 데이터 생성: 전지구적 개인과 환경에 대한 상세한 정보 발생\n인터넷 & 통신 (SNS, 사진, 위치, 장소, 유동인구, 상품거래)\n사물인터넷 (IoT), CCTV\n스마트 팩토리, 파밍\n게놈프로젝트, 생체정보: 인류, 실시간\n의료서비스, 보건\n자율주행차량: 내부, 외부\n금융정보 및 흐름\n사회 지표, 설문 조사: 고용, 물류, 직업, 연봉, 만족도 조사, 우울\n\n\n\n\n\n\n유토피아 vs. 디스토피아?\n\n초연결성, 투명성\n완전한 감시와 통제\n\n\n\n\n\n개인정보의 가치\n\n정보의 주권, 매매, 웹3(Web3)"
  },
  {
    "objectID": "contents/intro.html#data-science",
    "href": "contents/intro.html#data-science",
    "title": "데이터 분석 및 시각화",
    "section": "Data Science",
    "text": "Data Science\n\n\n\n소프트웨어 개발\n데이터에 기반한 분석 위해 작동하도록 프로그래밍을 하여 운영되도록 하는 일\n주로 전통적인 컴퓨터 사이언스의 커리큘럼에 의해 트레이닝\n\n유튜브의 영상 추천\n페이스북의 친구 매칭\n스팸메일 필터링\n자율주행\n\n\n\n\n데이터 분석\n하나의 구체적인 질문에 답하고자 함\n다양한 소스의 정제되는 않은 데이터를 통합하거나 가공하는 기술이 요구\n\nDNA의 분석을 통해 특정 질병의 발병 인자를 탐색\n유동인구와 매출을 분석해 상권을 분석\n정책의 유효성을 분석해서 정책결정에 공헌\n교통 흐름의 지연이 어떻게 발생하는지를 분석, 해결책 제시\n\n\n\n\n대부분의 경우 양쪽 모두에 걸쳐있음."
  },
  {
    "objectID": "contents/intro.html#data-analysis",
    "href": "contents/intro.html#data-analysis",
    "title": "데이터 분석 및 시각화",
    "section": "Data Analysis",
    "text": "Data Analysis\n\n\n\n오랜동안 여러 분야에서 각자의 방식을 개발\nComputer Science\nStatistics\nBiostatistics\nEconomics\nEpidemiology\nPolitical Science\nEngineering\n\n\n\n서로 다른 용어를 쓰기도 하며, 그 분야에서 필요로하는 방식에 초점을 맞춤.\n\n서로 의사소통이 거의 없었음.\n\nData Science라는 이름하에 통합되어가는 과정 중\n\n\n\n\n\n컴퓨터 사이언스의 경우, 주로 분류나 예측을 위한 이론과 툴들이 개발되는 반면,\n\n사회과학자들은 예측에는 관심이 없으며, 변수들 간의 진정한 관계 혹은 인과관계를 탐구\n현재 이 둘은 소위 cross-fertilization을 지향하며 같이 발전, 통합되어가고 있음.\n\n\n  Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). Statistical science, 16(3), 199-231.\n\n\n본 강의에서는 분석의 기초를 적절한 밸런스를 갖춰 제시한 R for Data Science by Wickham & Grolemund의 전개 방식을 따르고자 함."
  },
  {
    "objectID": "contents/intro.html#데이터를-분석한다는-것은",
    "href": "contents/intro.html#데이터를-분석한다는-것은",
    "title": "데이터 분석 및 시각화",
    "section": "데이터를 분석한다는 것은?",
    "text": "데이터를 분석한다는 것은?\n예측 모델 vs. 관계/원인 분석\n\n\n\n\n\n예측 모델\n예측의 신속성과 정확성\nMachine Learning 강점\nAlgorithmic\n\n고양이인가 아닌가? 예측의 정확성\n개인화된 추천 목록: 유튜브, 넷플릭스\n시리의 답변\n비즈니스 분석\n\n\n\n\n\n관계/원인 분석\n현상 본질과 매커니즘 파악\nStatistical Models 강점\nParametric\n\nQ: 닭의 울음이 태양을 솟게 하는가?\n돈과 행복: 패턴 vs. 예외\n\n\n\n\n\n가난, 인종, 범죄\n임금 차별\n\n\n\n\n\n출산율의 감소\n\n\n\n\n\n\n\n\n\n\n\n심리적 관성/편견 주의\n분석가의 책임의식\n두 가지는 서로 상보 관계!"
  },
  {
    "objectID": "contents/intro.html#데이터를-분석한다는-것은-1",
    "href": "contents/intro.html#데이터를-분석한다는-것은-1",
    "title": "데이터 분석 및 시각화",
    "section": "데이터를 분석한다는 것은?",
    "text": "데이터를 분석한다는 것은?\n전통적인 분류\n\n\n\n\n탐색적 분석 vs. 가설 검증\nexploratory vs. confirmatory\n\n탐색적 분석\n\n통찰 혹은 가설의 기초 제공\n끼워 맞추기? 오류에 빠지기 쉬움\n\n가설 검증\n\n진위의 확률을 높임\n탐색적 분석으로부터 온 가설은 재테스트\n\n\n\n\n\n관찰 vs. 실험 데이터\nobservational vs. experimental\n\n당근과 시력?\n커피의 효과?\n남녀의 임금 차별?\n\n\n  \n\n기술적 vs. 추론적 분석\ndescriptive vs. inferential\n\n연봉과 삶의 만족도와 관계\n두통약의 효능"
  },
  {
    "objectID": "contents/intro.html#통계적-사고-i",
    "href": "contents/intro.html#통계적-사고-i",
    "title": "데이터 분석 및 시각화",
    "section": "통계적 사고 I",
    "text": "통계적 사고 I\n\n\n\n\n남녀 임금의 차이\n\n\n\n\n\n\n\nConfounding\n\n\n머리가 길면 우울증도 높다?\n초등생이 발이 크면 독해력도 높다?\n\n\n\n“Spurious!”\n\n\n\nCommon cause\n\n\n신발을 신고 잠든 다음날 두통이 생긴다면?\n\n\n\n\n\n\n\n\nSource: Introduction to Causal Inference (ICI) by Brady Neal"
  },
  {
    "objectID": "contents/intro.html#통계적-사고-ii",
    "href": "contents/intro.html#통계적-사고-ii",
    "title": "데이터 분석 및 시각화",
    "section": "통계적 사고 II",
    "text": "통계적 사고 II\n\n\n\n\nSimpson’s paradox\n운동을 하면 콜레스테롤 수치가 증가하는가?\n\n\n\n\n\n\nColider Bias\n운동능력이 뛰어나면 지능이 떨어지는가? \nSimpson’s paradox\nCOVID-27\n\n\n\n\n\n\nSource:\n- The book of why by Judea Pearl\n- Introduction to Causal Inference (ICI) by Brady Neal"
  },
  {
    "objectID": "contents/intro.html#통계적-사고-iii",
    "href": "contents/intro.html#통계적-사고-iii",
    "title": "데이터 분석 및 시각화",
    "section": "통계적 사고 III",
    "text": "통계적 사고 III\n\n\n\n\n레몬과 괴혈병\n\n남녀 연봉 차이의 원인?\n\n직업 특성, 부서, 직급, 연령, 출산, 출세욕\n\n\n\n\n\n\n\n\n수집된 데이터의 성격\nSelection Bias\n\n\n노인에 관한 데이터: 누가 사망했는가?\n설문 데이터: 누가 참여했는가?\n회사 내에서의 만족도 조사: 샘플 속성의 변화\n코호트/특정세대의 특성: 그들의 특성인가?"
  },
  {
    "objectID": "contents/intro.html#데이터-시각화",
    "href": "contents/intro.html#데이터-시각화",
    "title": "데이터 분석 및 시각화",
    "section": "데이터 시각화",
    "text": "데이터 시각화\nData Visualization \n\n\n분석도구: 현미경, 연장도구\n강점이자 약점\n\n\n\n\n\n\n\n효과적/미적인 정보 전달 수단\n효과적이고 임팩트있도록 infographics \n\n\nInteractive"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균 / sk.cho@snu.ac.kr\n면담 시간: 수업 후\n수업시간: 월, 수 3:00 ~ 4:50PM\nWebsite: dgdavs.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "index.html#강의-정보",
    "href": "index.html#강의-정보",
    "title": "Welcome",
    "section": "",
    "text": "강사: 조성균 / sk.cho@snu.ac.kr\n면담 시간: 수업 후\n수업시간: 월, 수 3:00 ~ 4:50PM\nWebsite: dgdavs.modellings.art\n과제: Notice\n질문: Communicate/Ask"
  },
  {
    "objectID": "index.html#강의-개요",
    "href": "index.html#강의-개요",
    "title": "Welcome",
    "section": "강의 개요",
    "text": "강의 개요\n본 강의에서는 인터넷과 기술의 발전으로 풍부한 데이터들이 양산됨에 따라 그 안에 숨겨진 패턴을 찾고 분석하여 실증적 사실과 원리를 파악하는데 요구되는 기술들을 계발하는데 도움을 주고자 합니다. 이를 위해서는 1) 데이터 분석 툴을 자유자재로 다룰 수 있는 기술, 2) 주어진 데이터에 적절한 툴을 선택할 수 있는 판단력, 3) 파악한 패턴으로부터 현상의 본질을 추론할 수 있는 인과관계 추론의 원리들이 함께 필요합니다.\n수업은 크게 5부분으로 나뉨\n\n탐색적 분석 (exploratory data analysis)과 그에 필요한 데이터 전처리 (data wrangling)\n데이터 시각화 (data visualization)\n기술적 분석 (descriptive analysis)\n모델링 (modelling)\n통계 (statistics)\n\n\n교재\n\n번역서: Pandas를 이용한 데이터 분석 실습 2/e\nHands-On Data Analysis with Pandas (2e) by Stefanie Molin: code in GitHub\nPython for Data Analysis (3e) by Wes McKinney: code in GitHub\n3판 번역서: 파이썬 라이브러리를 활용한 데이터 분석\nR for Data Science by Wickham & Grolemund; 2nd edition"
  },
  {
    "objectID": "index.html#수업-활동",
    "href": "index.html#수업-활동",
    "title": "Welcome",
    "section": "수업 활동",
    "text": "수업 활동\n출석 (5%), 일반과제 (25%), 중간고사 (25%), 기말고사 (25%), 개별 프로젝트 (20%)"
  },
  {
    "objectID": "contents/case1.html",
    "href": "contents/case1.html",
    "title": "Case study",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.mode.copy_on_write = True\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)"
  },
  {
    "objectID": "contents/case1.html#q1",
    "href": "contents/case1.html#q1",
    "title": "Case study",
    "section": "Q1",
    "text": "Q1\n각 도착지에 따른 비행거리와 도착지연시간과의 관계를 알아보고자 함.\n\nGroup flights by destination.\nSummarise to compute distance, average delay, and number of flights.\nFilter to remove noisy points and Honolulu airport, which is almost twice as far away as the next closest airport.\n\n\n# Load the nycflight13 dataset\nflights = sm.datasets.get_rdataset(\"flights\", \"nycflights13\").data.drop(columns=\"time_hour\")\n\n\n# grouping by destinations\nby_dest = flights.groupby(\"dest\")\n\n\ndelay = (by_dest\n         .agg(count=(\"distance\", \"count\"), \n              dist=(\"distance\", \"mean\"), \n              delays=(\"arr_delay\", \"mean\"))\n        .reset_index()\n)\n\n\ndelay.head()\n\n  dest  count    dist  delays\n0  ABQ    254 1826.00    4.38\n1  ACK    265  199.00    4.85\n2  ALB    439  143.00   14.40\n3  ANC      8 3370.00   -2.50\n4  ATL  17215  757.11   11.30\n\n\n\n(\n    so.Plot(delay, x=\"dist\", y=\"delays\")\n    .add(so.Dots(), pointsize=\"count\")\n    .add(so.Line(), so.PolyFit(5))\n    .scale(pointsize=(2, 20))\n)\n\n\n\n\n불필요한 자료를 제거하고 시각화하는 것이 유리\n\n# Filter to remove noisy points and Honolulu airport\ndelay_sub = delay.query('count &gt; 20 & dest != \"HNL\"')\n(\n    so.Plot(delay_sub, x=\"dist\", y=\"delays\")\n    .add(so.Dots(), pointsize=\"count\")\n    .add(so.Line(), so.PolyFit(5))\n    .scale(pointsize=(2, 20))\n)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n다음과 같이 제외되는 자료에 대해 label 혹은 True/False을 붙여 관리하는 것도 방법\nidx = (delay[\"count\"] &gt; 20) & (delay[\"dest\"] != \"HNL\")\ndelay[\"incl\"] = np.where(idx, \"out\", \"in\")  # idx가 True인 곳은 \"out\", False인 곳은 \"in\"\ndelay\n#   dest  count    dist  delay incl\n# 0  ABQ    254 1826.00   4.38  out\n# 1  ACK    265  199.00   4.85  out\n# 2  ALB    439  143.00  14.40  out\n# 3  ANC      8 3370.00  -2.50   in\n# 4  ATL  17215  757.11  11.30  out\n...\n\n# 제외되는 데이터를 같이 볼 수 있음\n(\n    so.Plot(delay, x=\"dist\", y=\"delay\", color=\"incl\")\n    .add(so.Dots(), pointsize=\"count\")\n    .add(so.Line(), so.PolyFit(5))\n    .scale(pointsize=(5, 20))\n)"
  },
  {
    "objectID": "contents/case1.html#q2",
    "href": "contents/case1.html#q2",
    "title": "Case study",
    "section": "Q2",
    "text": "Q2\n평균적으로 가장 연착시간이 큰 항공기(tail number로 구분)를 살펴보는데,\n우선, count()를 사용하여 샘플 수가 극히 작은 케이스들 혹은 극단치들을 제거해서 살펴보는 것이 유리함.\n\ndelays = flights.groupby(\"tailnum\")[[\"arr_delay\"]].mean() # as DataFrame\ndelays\n\n         arr_delay\ntailnum           \nD942DN       31.50\nN0EGMQ        9.98\nN10156       12.72\n...            ...\nN998DL       16.39\nN999DN       14.31\nN9EAMQ        9.24\n\n[4043 rows x 1 columns]\n\n\n\n(\n    so.Plot(delays, x=\"arr_delay\")\n    .add(so.Line(), so.Hist())\n)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\npandas DataFrame method\ndelays.hist(bins=100)\n\n\n300분이 넘는 delay도 있음을 보는데, 각 평균 delay값이 몇 개 항목의 평균인지 살펴보면 흥미로운 사실을 발견할 수 있음. 즉,\n\ndelays = (\n    flights\n    .groupby(\"tailnum\")[\"arr_delay\"]\n    .agg([(\"delay\", \"mean\"), (\"n\", \"count\")])\n)\ndelays\n\n         delay    n\ntailnum            \nD942DN   31.50    4\nN0EGMQ    9.98  352\nN10156   12.72  145\n...        ...  ...\nN998DL   16.39   76\nN999DN   14.31   61\nN9EAMQ    9.24  238\n\n[4043 rows x 2 columns]\n\n\n\n(\n    so.Plot(delays, x=\"n\", y=\"delay\")\n    .add(so.Dots(alpha=.1))\n)\n\n\n\n\n비행횟수가 작을수록 편차가 크게 나타나는데,\n일반적으로 샘플수가 클수록 평균들의 편차가 줄어드는 현상이 나타남.\n위와 같은 플랏을 볼 때, 샘플 수가 매우 작은 그룹들은 제외하고 살펴보는 것이 패턴을 파악하는데 종종 도움이 됨.\n간단하게, query() method를 이용하면 편리\n\n(\n    so.Plot(delays.query('n &gt; 25'), x=\"n\", y=\"delay\")\n    .add(so.Dots(alpha=.1))\n)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n연속적인 함수 적용시 .pipe method를 권장; method chaining\n(\n    delays\n    .query('n &gt; 25')\n    .pipe(so.Plot, x=\"n\", y=\"delay\")  # 함수 so.Plot의 첫 번째 인자로 DataFrame을 받음\n    .add(so.Dots(alpha=.1))\n)"
  },
  {
    "objectID": "contents/case1.html#q3",
    "href": "contents/case1.html#q3",
    "title": "Case study",
    "section": "Q3",
    "text": "Q3\n\n# Lahman's Baseball Database\nbatting = pd.read_csv(\"https://raw.githubusercontent.com/beanumber/baseball_R/master/data/Batting.csv\") \n\n\nbatting\n\n        playerID  yearID  stint teamID lgID    G  G_batting     AB     R  \\\n0      aardsda01    2004      1    SFN   NL   11         11   0.00  0.00   \n1      aardsda01    2006      1    CHN   NL   45         43   2.00  0.00   \n2      aardsda01    2007      1    CHA   AL   25          2   0.00  0.00   \n...          ...     ...    ...    ...  ...  ...        ...    ...   ...   \n95192  zwilldu01    1914      1    CHF   FL  154        154 592.00 91.00   \n95193  zwilldu01    1915      1    CHF   FL  150        150 548.00 65.00   \n95194  zwilldu01    1916      1    CHN   NL   35         35  53.00  4.00   \n\n           H  ...    SB   CS    BB    SO  IBB  HBP    SH   SF  GIDP  G_old  \n0       0.00  ...  0.00 0.00  0.00  0.00 0.00 0.00  0.00 0.00  0.00  11.00  \n1       0.00  ...  0.00 0.00  0.00  0.00 0.00 0.00  1.00 0.00  0.00  45.00  \n2       0.00  ...  0.00 0.00  0.00  0.00 0.00 0.00  0.00 0.00  0.00   2.00  \n...      ...  ...   ...  ...   ...   ...  ...  ...   ...  ...   ...    ...  \n95192 185.00  ... 21.00  NaN 46.00 68.00  NaN 1.00 10.00  NaN   NaN 154.00  \n95193 157.00  ... 24.00  NaN 67.00 65.00  NaN 2.00 18.00  NaN   NaN 150.00  \n95194   6.00  ...  0.00  NaN  4.00  6.00  NaN 0.00  2.00  NaN   NaN  35.00  \n\n[95195 rows x 24 columns]\n\n\n\n# AB: At Bats 타석에 나선 횟수, H: Hits; times reached base 출루한 횟수\nbatters = batting.groupby(\"playerID\")[[\"H\", \"AB\"]].sum()\nbatters = batters.assign(\n    BA = lambda x: x.H / x.AB   # BA: batting average 타율\n)\nbatters\n\n                H       AB   BA\nplayerID                       \naardsda01    0.00     3.00 0.00\naaronha01 3771.00 12364.00 0.30\naaronto01  216.00   944.00 0.23\n...           ...      ...  ...\nzuvelpa01  109.00   491.00 0.22\nzuverge01   21.00   142.00 0.15\nzwilldu01  364.00  1280.00 0.28\n\n[17661 rows x 3 columns]\n\n\n\n# filtering없이 보았을 때와 비교해서 어느 정도 제외할지 고민\n(\n    so.Plot(batters.query('AB &gt; 100'), x=\"AB\", y=\"BA\")\n    .add(so.Dots(alpha=.1))\n    .add(so.Line(color=\"orangered\"), so.PolyFit(5))\n)\n\n\n\n\n\n# 1번 기회를 얻은 타자... 타율 100%\nbatters.sort_values(\"BA\", ascending=False).head(10)\n\n             H   AB   BA\nplayerID                \npaciojo01 3.00 3.00 1.00\ngallaja01 1.00 1.00 1.00\nsellsda01 1.00 1.00 1.00\n...        ...  ...  ...\nkehnch01  2.00 2.00 1.00\ndevinha01 2.00 2.00 1.00\nliddeda01 1.00 1.00 1.00\n\n[10 rows x 3 columns]"
  },
  {
    "objectID": "contents/exercise_transform.html",
    "href": "contents/exercise_transform.html",
    "title": "Exercises",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.set_option(\"mode.copy_on_write\", True)\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\n# Load the nycflight13 dataset\nflights = sm.datasets.get_rdataset(\"flights\", \"nycflights13\").data.drop(columns=\"time_hour\")"
  },
  {
    "objectID": "contents/exercise_transform.html#a",
    "href": "contents/exercise_transform.html#a",
    "title": "Exercises",
    "section": "A",
    "text": "A\n다음 조건을 만족하는 항공편을 필터링 해보세요. (1~6)\n\nHad an arrival delay of two or more hours\nFlew to Houston (IAH or HOU)\nDeparted in summer (July, August, and September)\nArrived more than two hours late, but didn’t leave late\nWere delayed by at least an hour, but made up over 30 minutes in flight\n출발할 때 예정시간보다 1시간 이상 지연되어 출발하였으나 빠르게 비행하여 출발 지연된 시간보다 도착 지연이 30분이상 단축된 항공편들입니다. (예를 들어, 1시간 늦게 출발했는데, 도착은 28분 지연된 항공편)\nDeparted between midnight and 6am (inclusive)\n\n\n\nFind the fastest flights.\nSort flights to find the most delayed flights. Find the flights that left earliest (예정시간보다 가장 일찍 출발한).\nWhich flights travelled the farthest? Which travelled the shortest?\n각 도착지 별로, 뉴욕에서 출항한 항공편이 1년 중 몇 일 있었는가?\n뉴욕에서 1년 중 300일 이상 출항하는 도착지들을 구하면?"
  },
  {
    "objectID": "contents/exercise_transform.html#b",
    "href": "contents/exercise_transform.html#b",
    "title": "Exercises",
    "section": "B",
    "text": "B\n\nOur definition of cancelled flights (dep_delay or arr_delay is missing) is slightly suboptimal. Why? Which is the most important column?\n\n예를 들어, 출발지연은 missing이 아니나 도착지연은 missing인 것이 있음\n\nLook at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the (daily) average delay?\n\n취소되는 항공편들이 많은 것과 관계 있는 것은 무엇이 있을까…\n\nWhat time of day should you fly if you want to avoid delays as much as possible?\nFor each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.\nFind all destinations that are flown by at least two carriers. Use that information to rank the carriers.\n\n즉, 적어도 두 항공사가 출항하는 도착지들도 한정한 후,\n다양한 곳으로 출항할수록 높은 순위의 항공사라고 보고, 항공사들의 순위를 정해봄"
  },
  {
    "objectID": "contents/exercise_transform.html#c",
    "href": "contents/exercise_transform.html#c",
    "title": "Exercises",
    "section": "C",
    "text": "C\nChallenges:\n\nWhich carrier has the worst arrival delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not?\n\n항공사(carrier)마다 취항하는 곳에 차이가 날 수 있다면, 그건 그 노선 혹은 공항의 문제이지 항공사의 문제는 아닐 수도 있음을 암시하는 것임\n\nWhich plane (tailnum) has the worst on-time record?\n\non-time을 적절히 정의한 후에 진행; 여러 방식이 있을 수 있음\n예를 들어, 늦게 도착하지 않은 항공편의 “갯수”로 보거나\n도착지연의 평균값을 기준으로 볼 수도 있음\n\nLook at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error).\n\n빠르게 비행한 이유: 제트 기류? 정체가 심한 공항?…\n같은 루트를 비행하는 항공편들 안에서 특이점이라면 의심해 볼만함…\n서로 다른 루트를 비행하는 항공편들과의 비교는?\n빠르다는 것을 비교하려면 동일한 루트에서 비교해야 적절함\n다른 루트의 항공편들까지 같이 비교하려면 어떤 방식이 있겠는가?\n\nCompute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?\n\n“상대적”의 의미가 값의 차이로 볼지 비율의 차이로 볼지도 고려해 볼 것\n\n** For each plane, count the number of flights before the first delay of greater than 1 hour.\n\nnp.cumsum을 활용"
  },
  {
    "objectID": "contents/pandas.html",
    "href": "contents/pandas.html",
    "title": "NumPy and pandas",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\nNumpy & pandas\nPython 언어는 수치 계산을 위해 디자인되지 않았기 때문에, 데이터 분석에 대한 효율적이고 빠른 계산이 요구되면서 C/C++이라는 언어로 구현된 NumPy (Numerical Python)가 탄생하였고, Python 생태계 안에 통합되었음. 기본적으로 Python 언어 안에 새로운 언어라고 볼 수 있음. 데이터 사이언스에서의 대부분의 계산은 NumPy의 ndarray (n-dimensioal array)와 수학적 operator들을 통해 계산됨.\n데이터 사이언스가 발전함에 따라 단일한 floating-point number들을 성분으로하는 array들의 계산에서 벗어나 칼럼별로 다른 데이터 타입(string, integer, object..)을 포함하는 tabular형태의 데이터를 효율적으로 처리해야 할 필요성이 나타났고, 이를 다룰 수 있는 새로운 언어를 NumPy 위에 개발한 것이 pandas임. 이는 기본적으로 Wes Mckinney에 의해 독자적으로 개발이 시작되었으며, 디자인적으로 불만족스러운 점이 지적되고는 있으나 데이터 사이언스의 기본적인 언어가 되었음.\nNumPy와 pandas에 대한 자세한 내용은 Python for Data Analysis by Wes MacKinney 참고\n특히, NumPy는 Ch.4 & appendices"
  },
  {
    "objectID": "contents/pandas.html#numpy",
    "href": "contents/pandas.html#numpy",
    "title": "NumPy and pandas",
    "section": "NumPy",
    "text": "NumPy\n\n수학적 symbolic 연산에 대한 구현이라고 볼 수 있으며,\n행렬(matrix) 또는 벡터(vector)를 ndarray (n-dimensional array)이라는 이름으로 구현함.\n\n사실상 정수(int)나 실수(float)의 한가지 타입으로 이루어짐.\n\n고차원의 arrays 가능\n\nSource: Medium.com\n\n\n가령, 다음과 같은 행렬 연산이 있다면,\n\\(\\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\begin{bmatrix}2 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2 \\\\ 4 \\end{bmatrix}\\)\n\n\nA = np.array([[1, 2],\n              [3, 4],\n              [5, 6]]) # 3x2 matrix\nX = np.array([[2],\n              [-1]]) # 2x1 matrix\n\nA @ X  # A * X : matrix multiplication\n\narray([[0],\n       [2],\n       [4]])\n\n\n\nA.dot(X)\n\narray([[0],\n       [2],\n       [4]])\n\n\nVector vs. Matrix\n\nprint(np.array([0, 2, 4])) # 1-dim matrix: vector\nprint(np.array([0, 2, 4]).reshape(3, 1)) # 3x1 matrix\n\n[0 2 4]\n[[0]\n [2]\n [4]]\n\n\n\narr = np.array([0, 2, 4])\narr.reshape(3, -1).T\n\narray([[0, 2, 4]])\n\n\n\nX2 = np.array([2, -1])\nA @ X2  # same as A.dot(X2)\n\narray([0, 2, 4])\n\n\n\nprint(A.shape)\nprint(A.ndim)\nprint(A.dtype)\n\n(3, 2)\n2\nint64\n\n\n\nA + A # element-wise addition\n\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n\n\n\n2 * A - 1 # braodcasting\n\narray([[ 1,  3],\n       [ 5,  7],\n       [ 9, 11]])\n\n\n\nnp.exp(A) # element-wise\n\narray([[  2.72,   7.39],\n       [ 20.09,  54.6 ],\n       [148.41, 403.43]])\n\n\n\nPython vs. NumPy\n\na = 2**31 - 1\nprint(a)\nprint(a + 1)\n\n2147483647\n2147483648\n\n\n\na = np.array([2**31 - 1], dtype='int32')\nprint(a)\nprint(a + 1)\n\n[2147483647]\n[-2147483648]\n\n\n\nSource: Ch.4 in Python for Data Analysis (3e) by Wes McKinney"
  },
  {
    "objectID": "contents/pandas.html#pandas",
    "href": "contents/pandas.html#pandas",
    "title": "NumPy and pandas",
    "section": "pandas",
    "text": "pandas\nSeries & DataFrame\n\nSeries\n1개의 칼럼으로 이루어진 데이터 포멧: 1d numpy array에 labels을 부여한 것으로 볼 수 있음.\nDataFrame의 각 칼럼들을 Series로 이해할 수 있음.\n\nSource: Practical Data Science\n\n\nDataFrame\n각 칼럼들이 한 가지 데이터 타입으로 이루어진 tabular형태 (2차원)의 데이터 포맷\n\n각 칼럼은 기본적으로 한 가지 데이터 타입인 것이 이상적이나, 다른 타입이 섞여 있을 수 있음\nNumPy의 2차원 array의 각 칼럼에 labels을 부여한 것으로 볼 수도 있으나, 여러 다른 기능들이 추가됨\nNumPy의 경우 고차원의 array를 다룰 수 있음: ndarray\n\n고차원의 DataFrame과 비슷한 것은 xarray가 존재\n\nLabels와 index를 제외한 데이터 값은 거의 NumPy ndarray로 볼 수 있음\n(pandas.array 존재)\n\n\nSource: Practical Data Science\n\n\nndarray &lt;&gt; DataFrame\n\ndf = pd.DataFrame(A, columns=[\"A1\", \"A2\"])\ndf\n\n   A1  A2\n0   1   2\n1   3   4\n2   5   6\n\n\n\n# 데이터 값들은 NumPy array\ndf.values # 또는 df.to_numpy()\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\n\n\nColumns\nSeries로 추출\n\ns = df[\"A1\"] # A1 칼럼 선택\ns\n# DataFrame의 column 이름이 Series의 name으로 전환\n\n0    1\n1    3\n2    5\nName: A1, dtype: int64\n\n\n\ntype(s)\n\npandas.core.series.Series\n\n\n\ns.values # Series의 값은 1d array\n\narray([1, 3, 5])\n\n\n\n\n\n\n\n\nA DataFrame with a single column\n\n\n\n\n\ndf[[\"A1\"]] # double brackets\n\n\n\n\n\n\n\n\n\nIndex objects\n\nframe = pd.DataFrame(np.arange(6).reshape((2, 3)),\n                     index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n                     columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\nframe\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\n\n\n\nframe.index\n\nIndex(['Ohio', 'Colorado'], dtype='object', name='state')\n\n\n\nframe.columns # columns도 index object\n\nIndex(['one', 'two', 'three'], dtype='object', name='number')\n\n\n\n\n\n\n\n\nNote\n\n\n\n“number”: columns의 이름 “state”: index의 이름\nframe.columns.name #&gt; ‘number’\nframe.index.name #&gt; ‘state’\n\n\n\nMulti-Index object\nIndex는 여러 levels을 지닐 수 있음\n\nframe.stack() # stack()은 long form으로 변환\n# 2 levels의 index를 가진 Series\n\nstate     number\nOhio      one       0\n          two       1\n          three     2\nColorado  one       3\n          two       4\n          three     5\ndtype: int64\n\n\n\n# MultiIndex를 직접 구성\npd.DataFrame(np.arange(12).reshape((4, 3)),\n        index=pd.MultiIndex.from_arrays([[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]], names=[\"idx1\", \"idx2\"]),\n        columns=pd.MultiIndex.from_arrays([[\"Ohio\", \"Ohio\", \"Colorado\"], [\"Green\", \"Red\", \"Green\"]], names=[\"state\", \"color\"]))\n\nstate      Ohio     Colorado\ncolor     Green Red    Green\nidx1 idx2                   \na    1        0   1        2\n     2        3   4        5\nb    1        6   7        8\n     2        9  10       11\n\n\n\n\nTime Series\nIndex는 times series에 특화\n\nfb = pd.read_csv('data/fb_stock_prices_2018.csv', index_col='date', parse_dates=True)\nfb.head()\n\n             open   high    low  close    volume\ndate                                            \n2018-01-02 177.68 181.58 177.55 181.42  18151903\n2018-01-03 181.88 184.78 181.33 184.67  16886563\n2018-01-04 184.90 186.21 184.10 184.33  13880896\n2018-01-05 185.59 186.90 184.93 186.85  13574535\n2018-01-08 187.20 188.90 186.33 188.28  17994726\n\n\n\nfb.plot(kind='line', y=['high', 'low'], figsize=(7, 4), title='Facebook Stock 2018')\nplt.show()\n\n\n\n\nindex없이 분석 가능?\nindex의 활용은 강의 후반부에…\nIndex를 column으로 전환시켜 분석할 수 있음: .reset_index()\n\nfb.reset_index()\n\n          date   open   high    low  close    volume\n0   2018-01-02 177.68 181.58 177.55 181.42  18151903\n1   2018-01-03 181.88 184.78 181.33 184.67  16886563\n2   2018-01-04 184.90 186.21 184.10 184.33  13880896\n..         ...    ...    ...    ...    ...       ...\n248 2018-12-27 132.44 134.99 129.67 134.52  31202509\n249 2018-12-28 135.34 135.92 132.20 133.20  22627569\n250 2018-12-31 134.45 134.64 129.95 131.09  24625308\n\n[251 rows x 6 columns]\n\n\n반대로 column을 index로 전환: .set_index(\"column\")\n\nfb.reset_index().set_index(\"date\")\n\n             open   high    low  close    volume\ndate                                            \n2018-01-02 177.68 181.58 177.55 181.42  18151903\n2018-01-03 181.88 184.78 181.33 184.67  16886563\n2018-01-04 184.90 186.21 184.10 184.33  13880896\n...           ...    ...    ...    ...       ...\n2018-12-27 132.44 134.99 129.67 134.52  31202509\n2018-12-28 135.34 135.92 132.20 133.20  22627569\n2018-12-31 134.45 134.64 129.95 131.09  24625308\n\n[251 rows x 5 columns]\n\n\n\n\n\n\nDataFrame의 연산\nNumPy의 ndarray들이 연산되는 방식과 동일하게 series나 DataFrame들의 연산 가능함\n\ndf + 2 * df\n\n   A1  A2\n0   3   6\n1   9  12\n2  15  18\n\n\n\nnp.log(df)\n\n    A1   A2\n0 0.00 0.69\n1 1.10 1.39\n2 1.61 1.79\n\n\n사실 연산은 index를 align해서 시행됨\n\n\n\nnumber    one  two  three\nstate                    \nOhio        0    1      2\nColorado    3    4      5\n\n\nnumber  one  two  three\nstate                  \nOhio      0    2      4\nFloria    6    8     10\n\n\n\n\nframe1 + frame2\n\n\n\nnumber    one  two  three\nstate                    \nColorado  NaN  NaN    NaN\nFloria    NaN  NaN    NaN\nOhio     0.00 3.00   6.00\n\n\n\n\n\n(참고) Mixed Data Type\n\ns = pd.Series([1, 2, \"3\"])\n\n\ns.dtype\n\ndtype('O')\n\n\n\ns + s\n\n0     2\n1     4\n2    33\ndtype: object\n\n\n\ns_int = s.astype(\"int\")\ns_int + s_int\n\n0    2\n1    4\n2    6\ndtype: int64\n\n\n\ns2 = pd.Series([1, 2, 3.1])\ns2.dtype\n\ndtype('float64')\n\n\n\ns2.astype(\"int\")\n\n0    1\n1    2\n2    3\ndtype: int64"
  },
  {
    "objectID": "contents/pandas.html#missing",
    "href": "contents/pandas.html#missing",
    "title": "NumPy and pandas",
    "section": "Missing",
    "text": "Missing\nNaN, NA, None\npandas에서는 missing을 명명하는데 R의 컨벤션을 따라 NA (not available)라 부름.\n대부분의 경우에서 NumPy object NaN(np.nan)을 NA을 나타내는데 사용됨.\nnp.nan은 실제로 floating-point의 특정 값으로 float64 데이터 타입임. Integer 또는 string type에서 약간 이상하게 작동될 수 있음.\nPython object인 None은 pandas에서 NA로 인식함.\n현재 NA라는 새로운 pandas object 실험중임\nNA의 handling에 대해서는 교재 참고\n.dropna(), .fillna(), .isna(), .notna()\n\nMckinney’s: 7.1 Handling Missing Data,\n\nMollin’s: 3.5 Handling duplicate, missing, or invalid data\n\nWorking with missing data\n\n\ns = pd.Series([1, 2, np.nan])\ns\n\n0   1.00\n1   2.00\n2    NaN\ndtype: float64\n\n\n\ns.astype(\"Int64\") # &lt;NA&gt;\n\n0       1\n1       2\n2    &lt;NA&gt;\ndtype: Int64\n\n\n\ns = pd.Series([\"a\", \"b\", np.nan])\ns\n\n0      a\n1      b\n2    NaN\ndtype: object\n\n\n\ns.astype(\"string\") # &lt;NA&gt;\n\n0       a\n1       b\n2    &lt;NA&gt;\ndtype: string\n\n\n\ns = pd.Series([1, 2, np.nan, None])\ns\n\n0   1.00\n1   2.00\n2    NaN\n3    NaN\ndtype: float64\n\n\n\ns.isna() # or s.isnull()\n\n0    False\n1    False\n2     True\n3     True\ndtype: bool\n\n\n\ns.notna() # or s.notnull()\n\n0     True\n1     True\n2    False\n3    False\ndtype: bool\n\n\n\n\n\n\n\n\nNote\n\n\n\nPython object인 None의 경우\nNone == None\n#&gt; True\nNumPy object인 np.nan의 경우\nnp.nan == np.nan\n#&gt; False"
  },
  {
    "objectID": "contents/pandas.html#attributes",
    "href": "contents/pandas.html#attributes",
    "title": "NumPy and pandas",
    "section": "Attributes",
    "text": "Attributes\n자주 사용되는 attributes;\nSeries objects: name, dtype, shape, index, values\nIndex objects: name, dtype, shape, values, is_unique\nDataFrame objects: dtype, shape, index, columns, values"
  },
  {
    "objectID": "contents/pandas.html#creating-dataframes",
    "href": "contents/pandas.html#creating-dataframes",
    "title": "NumPy and pandas",
    "section": "Creating DataFrames",
    "text": "Creating DataFrames\nDataFrame을 만드는 방식에 대해서는\nMckinney’s: 5.1 Introduction to pandas Data Structures"
  },
  {
    "objectID": "contents/seaborn.html",
    "href": "contents/seaborn.html",
    "title": "The seaborn.objects interface",
    "section": "",
    "text": "The seaborn.objects interface\nThe grammer of graphics의 데이터 시각화 이론을 잘 반영하고 있으며 아직 발전 중\n기존 seaborn modules을 완전히 대체하지는 못하므로 필요시 병행하여 사용\n\nv0.12.0 (September 2022)\nIntroduction of the objects interface\nThis release debuts the seaborn.objects interface, an entirely new approach to making plots with seaborn. It is the product of several years of design and 16 months of implementation work. The interface aims to provide a more declarative, composable, and extensible API for making statistical graphics. It is inspired by Wilkinson’s grammar of graphics, offering a Pythonic API that is informed by the design of libraries such as ggplot2 and vega-lite along with lessons from the past 10 years of seaborn’s development.\n\n\n\n\n\n\n\nCaution\n\n\n\nThe objects interface is currently experimental and incomplete. It is stable enough for serious use, but there certainly are some rough edges and missing features.\n\n\n\nThe seaborn.objects interface tutorial\nAPI reference\n\n\n\n\n\n\n\nNote\n\n\n\n현재 pandas 2.1.0 (Aug 30, 2023)에서 seaborn 실행시 경고메세지가 많이 발생하므로, 수업에서는 pandas 2.0.3 버전을 사용\n# 버전 확인\nimport pandas as pd\npd.__version__\n\n#&gt; '2.0.3'\n다운그레이드 하려면, 쉘 환경에서\n#(myenv)&gt; conda install pandas=2.0.3"
  },
  {
    "objectID": "contents/subsetting.html",
    "href": "contents/subsetting.html",
    "title": "Subsetting",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\n\n# statistics\nimport statsmodels.api as sm\nOptions\n# pandas options\npd.options.display.float_format = '{:.2f}'.format  # pd.reset_option('display.float_format')\npd.options.display.max_rows = 7\n\n# Numpy options\nnp.set_printoptions(precision = 2, suppress=True)\nData: On-time data for all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013\n# import the dataset\nflights_data = sm.datasets.get_rdataset(\"flights\", \"nycflights13\")\nflights = flights_data.data\nflights = flights.drop(columns=\"time_hour\")  # drop the \"time_hour\" column\n# Description\nprint(flights_data.__doc__)\nflights\n\n        year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n0       2013      1    1    517.00             515       2.00    830.00   \n1       2013      1    1    533.00             529       4.00    850.00   \n2       2013      1    1    542.00             540       2.00    923.00   \n...      ...    ...  ...       ...             ...        ...       ...   \n336773  2013      9   30       NaN            1210        NaN       NaN   \n336774  2013      9   30       NaN            1159        NaN       NaN   \n336775  2013      9   30       NaN             840        NaN       NaN   \n\n        sched_arr_time  arr_delay carrier  flight tailnum origin dest  \\\n0                  819      11.00      UA    1545  N14228    EWR  IAH   \n1                  830      20.00      UA    1714  N24211    LGA  IAH   \n2                  850      33.00      AA    1141  N619AA    JFK  MIA   \n...                ...        ...     ...     ...     ...    ...  ...   \n336773            1330        NaN      MQ    3461  N535MQ    LGA  BNA   \n336774            1344        NaN      MQ    3572  N511MQ    LGA  CLE   \n336775            1020        NaN      MQ    3531  N839MQ    LGA  RDU   \n\n        air_time  distance  hour  minute  \n0         227.00      1400     5      15  \n1         227.00      1416     5      29  \n2         160.00      1089     5      40  \n...          ...       ...   ...     ...  \n336773       NaN       764    12      10  \n336774       NaN       419    11      59  \n336775       NaN       431     8      40  \n\n[336776 rows x 18 columns]\nSubsetting options"
  },
  {
    "objectID": "contents/subsetting.html#bracket",
    "href": "contents/subsetting.html#bracket",
    "title": "Subsetting",
    "section": "Bracket [ ]",
    "text": "Bracket [ ]\nBracket안에 labels이 있는 경우 columns을 select\n\nA single string: Series로 반환\n\nA list of a single string: DataFrame으로 반환\n\nA list of strings\n\n\nflights['dest']  # return as a Series\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object\n\n\n\nflights[['dest']]  # return as a DataFrame\n\n       dest\n0       IAH\n1       IAH\n2       MIA\n...     ...\n336773  BNA\n336774  CLE\n336775  RDU\n\n[336776 rows x 1 columns]\n\n\n\nflights[['origin', 'dest']]\n\n       origin dest\n0         EWR  IAH\n1         LGA  IAH\n2         JFK  MIA\n...       ...  ...\n336773    LGA  BNA\n336774    LGA  CLE\n336775    LGA  RDU\n\n[336776 rows x 2 columns]\n\n\nBracket안에 numbers가 있는 경우 rows를 select: position-based\n\nSlicing만 허용\nFirst index는 포함, last index는 제외\n[1, 5, 8]과 같이 특정 rows를 선택하는 것은 허용안됨\n\n\nflights[2:5]\n\n   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n2  2013      1    1    542.00             540       2.00    923.00   \n3  2013      1    1    544.00             545      -1.00   1004.00   \n4  2013      1    1    554.00             600      -6.00    812.00   \n\n   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n2             850      33.00      AA    1141  N619AA    JFK  MIA    160.00   \n3            1022     -18.00      B6     725  N804JB    JFK  BQN    183.00   \n4             837     -25.00      DL     461  N668DN    LGA  ATL    116.00   \n\n   distance  hour  minute  \n2      1089     5      40  \n3      1576     5      45  \n4       762     6       0  \n\n\n 만약, 아래와 같이 index가 number일 때 out of order가 된 경우에도 row position으로 적용됨\n\n\n   origin dest  arr_delay\n42    LGA  DFW      48.00\n2     JFK  MIA      33.00\n25    EWR  ORD      32.00\n14    LGA  DFW      31.00\n33    EWR  MSP      29.00\n\n\n\ndf_outoforder[2:4]\n\n   origin dest  arr_delay\n25    EWR  ORD      32.00\n14    LGA  DFW      31.00\n\n\n Chaining with brackets\n\nflights[['origin', 'dest']][2:5]\n# 순서 바꿔어도 동일: flights[2:5][['origin', 'dest']]\n\n  origin dest\n2    JFK  MIA\n3    JFK  BQN\n4    LGA  ATL"
  },
  {
    "objectID": "contents/subsetting.html#dot-notation-.",
    "href": "contents/subsetting.html#dot-notation-.",
    "title": "Subsetting",
    "section": "Dot notation .",
    "text": "Dot notation .\n편리하나 주의해서 사용할 필요가 있음\n\n\n\n\n\n\nNote\n\n\n\n\nspace 또는 . 이 있는 변수명 사용 불가\nmethods와 동일한 이름의 변수명 사용 불가: 예) 변수명이 count인 경우 df.count는 df의 method로 인식\n새로운 변수를 만들어 값을 assgin할 수 없음: 예) df.new_var = 1 불가; 대신 df[\"new_var\"] = 1\n만약, 다음과 같이 변수을 지정했을 때 vars_names=[\"origin\", \"dest\"],\n\ndf[vars_names]는 \"orign\"과 \"dest\" columns을 선택\ndf.vars_names는 vars_names이라는 이름의 column을 의미\n\n\n\n\n\nflights.dest  # flihgts[\"dest\"]와 동일\n\n0         IAH\n1         IAH\n2         MIA\n         ... \n336773    BNA\n336774    CLE\n336775    RDU\nName: dest, Length: 336776, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#loc-.iloc",
    "href": "contents/subsetting.html#loc-.iloc",
    "title": "Subsetting",
    "section": ".loc & .iloc",
    "text": ".loc & .iloc\n각각 location, integer location의 약자\ndf.(i)loc[row_indexer, column_indexer]\n\n.loc: label-based indexing\n\nIndex가 number인 경우도 label로 처리\nSlicing의 경우 first, last index 모두 inclusive\n\n\nflights.loc[2:5, ['origin', 'dest']]  # 2:5는 index의 label, not position\n\n  origin dest\n2    JFK  MIA\n3    JFK  BQN\n4    LGA  ATL\n5    EWR  ORD\n\n\n다음과 같이 index가 labels인 경우는 혼동의 염려 없음\n\n\n       origin dest\nred       JFK  MIA\nblue      JFK  BQN\ngreen     LGA  ATL\nyellow    EWR  ORD\n\n\n\ndf_labels.loc[\"blue\":\"green\", :]\n\n      origin dest\nblue     JFK  BQN\ngreen    LGA  ATL\n\n\n하지만, index가 number인 경우는 혼동이 있음\n앞서 본 예에서처럼 index가 out of order인 경우 loc은 다르게 작동\n\n\n   origin dest  arr_delay\n42    LGA  DFW      48.00\n2     JFK  MIA      33.00\n25    EWR  ORD      32.00\n14    LGA  DFW      31.00\n33    EWR  MSP      29.00\n\n\n\ndf_outoforder.loc[2:14, :]  # position 아님\n\n   origin dest  arr_delay\n2     JFK  MIA      33.00\n25    EWR  ORD      32.00\n14    LGA  DFW      31.00\n\n\n\ndf_outoforder.loc[[25, 33], :]  # slicing이 아닌 특정 index 선택\n\n   origin dest  arr_delay\n25    EWR  ORD      32.00\n33    EWR  MSP      29.00\n\n\n\nflights.loc[2:5, 'dest']  # returns as a Series\n\n2    MIA\n3    BQN\n4    ATL\n5    ORD\nName: dest, dtype: object\n\n\n\nflights.loc[2:5, ['dest']]  # return as a DataFrame\n\n  dest\n2  MIA\n3  BQN\n4  ATL\n5  ORD\n\n\n\n\n\n\n\n\nTip\n\n\n\n생략 표시\nflights.loc[2:5, :]  # ':' means all\nflights.loc[2:5]\nflights.loc[2:5, ]  # flights.loc[ , ['dest', 'origin']]은 에러\n\n\n\n# select a single row\nflights.loc[2, :]  # returns as a Series, column names as its index\n\nyear        2013\nmonth          1\nday            1\n            ... \ndistance    1089\nhour           5\nminute        40\nName: 2, Length: 18, dtype: object\n\n\n\n# select a single row\nflights.loc[[2], :]  # returns as a DataFrame\n\n   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n2  2013      1    1    542.00             540       2.00    923.00   \n\n   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n2             850      33.00      AA    1141  N619AA    JFK  MIA    160.00   \n\n   distance  hour  minute  \n2      1089     5      40  \n\n\n\n\n\n.iloc: position-based indexing\n\nSlicing의 경우 as usual: first index는 inclusive, last index는 exclusive\n\n\nflights.iloc[2:5, 12:14]  # 2:5는 index의 position, last index는 미포함\n\n  origin dest\n2    JFK  MIA\n3    JFK  BQN\n4    LGA  ATL\n\n\n\nflights.iloc[2:5, 12]  # return as a Series\n\n2    JFK\n3    JFK\n4    LGA\nName: origin, dtype: object\n\n\n\nflights.iloc[2:5, :]\n# 다음 모두 가능\n# flights.iloc[2:5]\n# flights.iloc[2:5, ]\n\n# flights.iloc[, 2:5]는 에러\n\n   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n2  2013      1    1    542.00             540       2.00    923.00   \n3  2013      1    1    544.00             545      -1.00   1004.00   \n4  2013      1    1    554.00             600      -6.00    812.00   \n\n   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n2             850      33.00      AA    1141  N619AA    JFK  MIA    160.00   \n3            1022     -18.00      B6     725  N804JB    JFK  BQN    183.00   \n4             837     -25.00      DL     461  N668DN    LGA  ATL    116.00   \n\n   distance  hour  minute  \n2      1089     5      40  \n3      1576     5      45  \n4       762     6       0  \n\n\n\nflights.iloc[2:5, [12]]  # return as a DataFrame\n\n  origin\n2    JFK\n3    JFK\n4    LGA\n\n\n\nflights.iloc[[2, 5, 7], 12:14]  # 특정 위치의 rows 선택\n\n  origin dest\n2    JFK  MIA\n5    EWR  ORD\n7    LGA  IAD\n\n\n\n\n\n\n\n\nNote\n\n\n\n단 하나의 scalar 값을 추출할 때, 빠른 처리를 하는 다음을 사용할 수 있음\n.at[i, j], .iat[i, j]"
  },
  {
    "objectID": "contents/subsetting.html#series의-indexing",
    "href": "contents/subsetting.html#series의-indexing",
    "title": "Subsetting",
    "section": "Series의 indexing",
    "text": "Series의 indexing\nDataFrame과 같은 방식으로 이해\nIndex가 numbers인 경우\n\n\n42    DFW\n2     MIA\n25    ORD\n14    DFW\n33    MSP\nName: dest, dtype: object\n\n\n\ns.loc[25:14]\n\n25    ORD\n14    DFW\nName: dest, dtype: object\n\n\n\ns.iloc[2:4]\n\n25    ORD\n14    DFW\nName: dest, dtype: object\n\n\n\ns[:3]\n\n42    DFW\n2     MIA\n25    ORD\nName: dest, dtype: object\n\n\n\n\n\n\n\n\nNote\n\n\n\n다음과 같은 경우 혼동스러움\ns[3] # 3번째? label 3?\n#&gt; errors occur\n\n\n Index가 lables인 경우 다음과 같이 편리하게 subsetting 가능\n\n\nred       MIA\nblue      BQN\ngreen     ATL\nyellow    ORD\nName: dest, dtype: object\n\n\n\ns[\"red\":\"green\"]\n\nred      MIA\nblue     BQN\ngreen    ATL\nName: dest, dtype: object\n\n\n\ns[[\"red\", \"green\"]]\n\nred      MIA\ngreen    ATL\nName: dest, dtype: object"
  },
  {
    "objectID": "contents/subsetting.html#boolean-indexing",
    "href": "contents/subsetting.html#boolean-indexing",
    "title": "Subsetting",
    "section": "Boolean indexing",
    "text": "Boolean indexing\n\nBracket [ ] 이나 loc을 이용\niloc은 적용 안됨\n\n\nBracket [ ]\n\nnp.random.seed(123)\nflights_6 = flights[:100][[\"dep_delay\", \"arr_delay\", \"origin\", \"dest\"]].sample(6)\nflights_6\n\n    dep_delay  arr_delay origin dest\n8       -3.00      -8.00    JFK  MCO\n70       9.00      20.00    LGA  ORD\n82      -1.00     -26.00    JFK  SFO\n28       0.00     -21.00    JFK  SJU\n63      -2.00       2.00    JFK  LAX\n0        2.00      11.00    EWR  IAH\n\n\n\nflights_6[flights_6[\"dep_delay\"] &lt; 0]\n\n    dep_delay  arr_delay origin dest\n8       -3.00      -8.00    JFK  MCO\n82      -1.00     -26.00    JFK  SFO\n63      -2.00       2.00    JFK  LAX\n\n\n\nidx = flights_6[\"dep_delay\"] &lt; 0\nidx # bool type의 Series\n\n8      True\n70    False\n82     True\n28    False\n63     True\n0     False\nName: dep_delay, dtype: bool\n\n\n\n# Select a column with the boolean indexing\nflights_6[idx][\"dest\"]\n\n8     MCO\n82    SFO\n63    LAX\nName: dest, dtype: object\n\n\n\n\n\n\n\n\nNote\n\n\n\n사실, boolean indexing을 할때, DataFrame/Series의 index와 match함\n대부분 염려하지 않아도 되나 다음과 같은 결과 참고\n# Reset index\nidx_reset = idx.reset_index(drop=True)\n# 0     True\n# 1    False\n# 2     True\n# 3    False\n# 4     True\n# 5    False\n# Name: dep_delay, dtype: bool\n\nflights_6[idx_reset][\"dest\"]\n#&gt; IndexingError: Unalignable boolean Series provided as indexer \n#&gt; (index of the boolean Series and of the indexed object do not match)\n\n# Index가 없는 numpy array로 boolean indexing을 하는 경우 문제없음\nflights_6[idx_reset.to_numpy()][\"dest\"]\n# 8     MCO\n# 82    SFO\n# 63    LAX\n# Name: dest, dtype: object\n\n\n\nbool_idx = flights_6[[\"dep_delay\", \"arr_delay\"]] &gt; 0\nbool_idx\n\n    dep_delay  arr_delay\n8       False      False\n70       True       True\n82      False      False\n28      False      False\n63      False       True\n0        True       True\n\n\n\nidx_any = bool_idx.any(axis=1)\nidx_any\n\n8     False\n70     True\n82    False\n28    False\n63     True\n0      True\ndtype: bool\n\n\n\nbool_idx.all(axis=1)\n\n8     False\n70     True\n82    False\n28    False\n63    False\n0      True\ndtype: bool\n\n\n\n\nnp.where() 활용\nnp.where(boolean condition, value if True, value if False)\n\nflights_6[\"delayed\"] = np.where(idx, \"delayed\", \"on-time\")\nflights_6\n\n    dep_delay  arr_delay origin dest  delayed\n8       -3.00      -8.00    JFK  MCO  delayed\n70       9.00      20.00    LGA  ORD  on-time\n82      -1.00     -26.00    JFK  SFO  delayed\n28       0.00     -21.00    JFK  SJU  on-time\n63      -2.00       2.00    JFK  LAX  delayed\n0        2.00      11.00    EWR  IAH  on-time\n\n\n\nnp.where(flights_6[\"dest\"].str.startswith(\"S\"), \"S\", \"T\")  # str method: \"S\"로 시작하는지 여부\n\narray(['T', 'T', 'S', 'S', 'T', 'T'], dtype='&lt;U1')\n\n\n\nflights_6[\"dest_S\"] = np.where(flights_6[\"dest\"].str.startswith(\"S\"), \"S\", \"T\")\nflights_6\n\n    dep_delay  arr_delay origin dest  delayed dest_S\n8       -3.00      -8.00    JFK  MCO  delayed      T\n70       9.00      20.00    LGA  ORD  on-time      T\n82      -1.00     -26.00    JFK  SFO  delayed      S\n28       0.00     -21.00    JFK  SJU  on-time      S\n63      -2.00       2.00    JFK  LAX  delayed      T\n0        2.00      11.00    EWR  IAH  on-time      T\n\n\n\n\nloc\n\nflights_6.loc[idx, \"dest\"]  # flights_6[idx][\"dest\"]과 동일\n\n8     MCO\n82    SFO\n63    LAX\nName: dest, dtype: object\n\n\n만약 column 이름에 “time”을 포함하는 columns만 선택하고자 하면\n\nSeries/Index object는 str method 존재\nstr.contains(), str.startswith(), str.endswith()\n자세한 사항은 7.4 String Manipulation/String Functions in pandas by Wes McKinney\n\n\ncols = flights.columns.str.contains(\"time\")  # str method: \"time\"을 포함하는지 여부\ncols\n\narray([False, False, False,  True,  True, False,  True,  True, False,\n       False, False, False, False, False,  True, False, False, False])\n\n\n\n# Columns 쪽으로 boolean indexing\nflights.loc[:, cols]\n\n        dep_time  sched_dep_time  arr_time  sched_arr_time  air_time\n0         517.00             515    830.00             819    227.00\n1         533.00             529    850.00             830    227.00\n2         542.00             540    923.00             850    160.00\n...          ...             ...       ...             ...       ...\n336773       NaN            1210       NaN            1330       NaN\n336774       NaN            1159       NaN            1344       NaN\n336775       NaN             840       NaN            1020       NaN\n\n[336776 rows x 5 columns]\n\n\n\n\n\n\n\n\nWarning\n\n\n\nChained indexing으로 값을 assign하는 경우 copy vs. view 경고 메세지\nflights[flights[\"arr_delay\"] &lt; 0][\"arr_delay\"] = 0\n/var/folders/mp/vcywncl97ml2q4c_5k2r573m0000gn/T/ipykernel_96692/3780864177.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n 경고가 제시하는데로 .loc을 이용하여 assign\nflights.loc[flights[\"arr_delay\"] &lt; 0, \"arr_delay\"] = 0"
  },
  {
    "objectID": "contents/subsetting.html#summary",
    "href": "contents/subsetting.html#summary",
    "title": "Subsetting",
    "section": "Summary",
    "text": "Summary\n\nBracket [ ]의 경우\n\n간단히 columns을 선택하고자 할때 column labels: df[[\"var1\", \"var2\"]]\n간단히 rows를 선택하고자 할때 numerical indexing: df[:10]\n\nDot-notation은\n\npandas의 methods와 중복된 이름을 피하고,\nassignment의 왼편에는 사용을 피할 것\n\n가능하면 분명한 loc 또는 iloc을 사용\n\nloc[:, [\"var1\", \"var2\"]]는 df[[\"var1\", \"var2\"]]과 동일\niloc[:10, :]은 df[:10]와 동일\nloc의 경우, index가 숫자라 할지라도 label로 처리됨\nloc은 iloc과는 다른게 slicing(:)에서 first, last index 모두 inclusive\n\nBoolean indexing의 경우\n\nBracket [ ]: df[bool_idx]\nloc: df.loc[bool_idx, :]\niloc 불가\n\nAssignment를 할때는,\n\nchained indexing을 피하고: df[:5][\"dest\"]\nloc or iloc 사용:\n\ndf.loc[:4, \"dest\"]: index가 0부터 정렬되어 있다고 가정했을 때, slicing에서 위치 하나 차이남\ndf.iloc[:5, 13]: “dest”의 column 위치 13\n\n\n한 개의 column 혹은 row을 선택하면 Series로 반환: df[\"var1\"] 또는 df.loc[2, :]\n\n\n\n\n\n\n\nNote\n\n\n\nNumpy의 indexing에 대해서는 교재 참고\nCh.4/Basic Indexing and Slicing in Python Data Analysis by Wes McKinney"
  },
  {
    "objectID": "contents/views.html",
    "href": "contents/views.html",
    "title": "Views and Copies",
    "section": "",
    "text": "Load Packages\n# numerical calculation & data frames\nimport numpy as np\nimport pandas as pd\nWhat’s new in 2.0.0 (April 3, 2023)\n아래와 같이 copy_on_write을 적용하여 쓰는 것을 추천"
  },
  {
    "objectID": "contents/views.html#numpy",
    "href": "contents/views.html#numpy",
    "title": "Views and Copies",
    "section": "NumPy",
    "text": "NumPy\nNumPy에서 subsetting을 하는 경우 view로 나타날 수 있음.\n속도와 메모리의 효율적 관리가 가능하나 혼동의 여지 있음.\n\narr = np.array([1, 2, 3, 4, 5])\narr\n\narray([1, 2, 3, 4, 5])\n\n\n\nsub_arr = arr[1:3]\nsub_arr # view\n\narray([2, 3])\n\n\nSubset을 수정하면\n\nsub_arr[0] = 99\n\n\nprint(arr)\nprint(sub_arr)\n\n[ 1 99  3  4  5]\n[99  3]\n\n\n반대로 “original” arr를 수정하도\n\narr[2] = -11\n\n\nprint(arr)\nprint(sub_arr)\n\n[  1  99 -11   4   5]\n[ 99 -11]\n\n\n사실, arr, sub_arr는 같은 메모리 주소를 reference함\n\n\n\n\n\n\nNote\n\n\n\nView가 되지 않고 copy로 되는 경우가 있음.\nSimple indexing을 제외하면 copy가 된다고 보면 됨\n즉, arr[2] 또는 arr[2:4] 같은 경우는 view로, 그 이외에 integer array로 subsetting을 하거나 (fancy indexing); arr[[2, 3]], 또는 boolean indexing; arr[arr &gt; 2]의 경우 copy가 됨\n\n\n\narr = np.array([1, 2, 3, 4, 5])\n\n\nsub_arr = arr[[2, 3]]  # copy\nsub_arr[0] = 99\n\n\nprint(arr)\nprint(sub_arr)\n\n[1 2 3 4 5]\n[99  4]\n\n\n\nsub_arr = arr[arr &gt; 2]  # copy\nsub_arr[0] = 99\n\n\nprint(arr)\nprint(sub_arr)\n\n[1 2 3 4 5]\n[99  4  5]\n\n\n\n\n\n\n\n\nNote\n\n\n\nAssign operator의 왼편에 [:] 없이, view에서 수정된 array를 assign하면 copy로 전달\n\n\n\narr = np.array([1, 2, 3, 4, 5])\n\n\nsub_arr = arr[1:4]     # view\nsub_arr = sub_arr * 2  # copy\n\n\nprint(arr)\nprint(sub_arr)\n\n[1 2 3 4 5]\n[4 6 8]\n\n\n\narr = np.array([1, 2, 3, 4, 5])\n\n\nsub_arr = arr[1:4]        # view\nsub_arr[:] = sub_arr * 2  # view\n\n\nprint(arr)\nprint(sub_arr)\n\n[1 4 6 8 5]\n[4 6 8]\n\n\n강제로 copy: sub_arr.copy()"
  },
  {
    "objectID": "contents/views.html#pandas",
    "href": "contents/views.html#pandas",
    "title": "Views and Copies",
    "section": "pandas",
    "text": "pandas\n훨씬 복잡함…\n데이터 타입도 데이터가 어떻게 만들어졌는지도 관계가 있음.\n\ndf = pd.DataFrame(np.arange(8).reshape(4, 2), columns=[\"one\", \"two\"])\ndf\n\n   one  two\n0    0    1\n1    2    3\n2    4    5\n3    6    7\n\n\n\nsub_df = df.iloc[1:3]  # view\nsub_df\n\n   one  two\n1    2    3\n2    4    5\n\n\n\ndf.iloc[1, 1] = 99\n\n\nprint(df)\nprint(sub_df)\n\n   one  two\n0    0    1\n1    2   99\n2    4    5\n3    6    7\n   one  two\n1    2   99\n2    4    5\n\n\n\n\n\n\n\n\nNote\n\n\n\ncopy_on_write = True (v2.0) 일 때는 copy가 되어\nprint(sub_df)\n#    one  two\n# 1    2    3\n# 2    4    5\n\n\n\ndf.iloc[1, 0] = 0.9  # copy; 컬럼의 데이터 타입이 int에서 float로 바뀌면서 copy됨)\n\n\nprint(df)\nprint(sub_df)\n\n   one  two\n0  0.0    1\n1  0.9   99\n2  4.0    5\n3  6.0    7\n   one  two\n1    2   99\n2    4    5\n\n\n\ndf.iloc[2, 1] = -99  # view\n\n\nprint(df)\nprint(sub_df)\n\n   one  two\n0  0.0    1\n1  0.9   99\n2  4.0  -99\n3  6.0    7\n   one  two\n1    2   99\n2    4  -99\n\n\n\nSettingWithCopyWarning\nSubsetting된 DataFrame을 수정하려할 때 경고를 내어주지만, 항상 믿을만 한 것은 아님.\n경고가 발생할 시, 앞 어디에선가 view나 copy가 이루어진 곳을 찾아 .copy()로 수정\n\ndf = pd.DataFrame(np.arange(12).reshape(4, 3), columns=[\"one\", \"two\", \"three\"])\ndf\n\n   one  two  three\n0    0    1      2\n1    3    4      5\n2    6    7      8\n3    9   10     11\n\n\n\ndf_cols = df[[\"two\", \"three\"]]  # copy\ndf_cols\n\n   two  three\n0    1      2\n1    4      5\n2    7      8\n3   10     11\n\n\n\ndf.iloc[0, 1] = -55\n\n\nprint(df)\nprint(df_cols)\n\n   one  two  three\n0    0  -55      2\n1    3    4      5\n2    6    7      8\n3    9   10     11\n   two  three\n0    1      2\n1    4      5\n2    7      8\n3   10     11\n\n\nSubset을 수정하려하면 warning message!\ncopy_on_save가 True일 때는 copy가 되면서 경고가 발생하지 않음 (v2.0)\n\ndf_cols.iloc[0, 1] = -99\n\n/var/folders/tv/fwb_421x50z8bj5v37vw680r0000gn/T/ipykernel_1691/2609376290.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_cols.iloc[0, 1] = -99\n\n\n\nprint(df_cols)\nprint(df)\n\n   two  three\n0    1    -99\n1    4      5\n2    7      8\n3   10     11\n   one  two  three\n0    0  -55      2\n1    3    4      5\n2    6    7      8\n3    9   10     11\n\n\n다음과 비교\n\ndf = pd.DataFrame(np.arange(12).reshape(4, 3), columns=[\"one\", \"two\", \"three\"])\ndf\n\n   one  two  three\n0    0    1      2\n1    3    4      5\n2    6    7      8\n3    9   10     11\n\n\n\ndf_cols_3 = df.loc[:, [\"two\", \"three\"]]  # copy\ndf_cols_3.iloc[0, 1] = -99\n\n# No warning\n\n\nprint(df_cols_3)\nprint(df)\n\n   two  three\n0    1    -99\n1    4      5\n2    7      8\n3   10     11\n   one  two  three\n0    0    1      2\n1    3    4      5\n2    6    7      8\n3    9   10     11\n\n\n\ndf = pd.DataFrame(np.arange(12).reshape(4, 3), columns=[\"one\", \"two\", \"three\"])\ndf\n\n   one  two  three\n0    0    1      2\n1    3    4      5\n2    6    7      8\n3    9   10     11\n\n\n\ndf_cols_2 = df.loc[:, \"two\":\"three\"]  # view\ndf_cols_2.iloc[0, 1] = -99\n\n/var/folders/tv/fwb_421x50z8bj5v37vw680r0000gn/T/ipykernel_1691/4245876664.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_cols_2.iloc[0, 1] = -99\n\n\n\nprint(df_cols_2)\nprint(df)\n\n   two  three\n0    1    -99\n1    4      5\n2    7      8\n3   10     11\n   one  two  three\n0    0    1    -99\n1    3    4      5\n2    6    7      8\n3    9   10     11\n\n\n\n\n\n\n\n\nNote\n\n\n\ncopy_on_save가 True일 때는 copy가 되면서 경고가 발생하지 않음 (v2.0)\nprint(df)\n#    one  two  three\n# 0    0    1      2\n# 1    3    4      5\n# 2    6    7      8\n# 3    9   10     11\n\n\n강제로 copy: df_cols.copy()\n\ndf_cols_4 = df[[\"two\", \"three\"]].copy()\ndf_cols_4.iloc[0, 1] = -99\n\n\n\n\n\n\n\nTip\n\n\n\nSubset을 만들고 바로 분석을 할 것이 아니라면, 안전하게 .copy()를 쓰는 것을 추천"
  }
]